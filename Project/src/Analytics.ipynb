{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c8a7cc-de53-4725-8ae6-8c128e581b8b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "    \n",
    "### <center> GITHUB ISSUES</center>\n",
    "### <center> ELASTICSEARCH - OPEN AI</center>\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "<br>\n",
    "    <br>\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ffddc3a-6993-4848-bea0-6e392ae30da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (1.53.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785c32c3-fdb5-4391-800f-38864eaaae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8da7f1d-cc25-452e-9aa1-f019edfd90c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /opt/anaconda3/lib/python3.12/site-packages (8.15.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.13 in /opt/anaconda3/lib/python3.12/site-packages (from elasticsearch) (8.15.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install elasticsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79588c-116b-4bc7-86df-e6ce16ce6f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7aee99d-0219-4469-9f8a-d1c32463ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import requests\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d15e9-bc44-4510-b3c5-40632ebc8299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13b0610-c0c9-4e04-9068-d332231b904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the headers\n",
    "headers = {\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "    \"access_token\": \"\",\n",
    "    \"Git_Username\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f3b1c-0863-40a0-b3e0-40e7b26ce0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efce5822-6d66-49b7-9523-ba0c3a074da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the owner and the repository\n",
    "owners = ['langchain-ai', 'langchain-ai', 'microsoft', 'openai', 'elastic', 'milvus-io']\n",
    "repos = ['langchain', 'langgraph', 'autogen', 'openai-cookbook', 'elasticsearch', 'pymilvus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f4a9c-94f6-43d5-8d64-e5521cea24d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decd06a3-5c46-4048-a22b-180bde820141",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "per_page = 100\n",
    "from_date = (dt.date.today() - dt.timedelta(days=60)).isoformat() #The duration for which we need the issues can be changed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "116343df-7e18-4c8b-b285-f4bf00534000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GitHub base URL\n",
    "base_url = \"https://api.github.com/repos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c0bc88-58d5-43ff-ad3c-9a8d3cb71e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that returns the base url\n",
    "def fetch_url(owner, repo):\n",
    "    return f\"https://\"+headers[\"Git_Username\"]+\":\"+headers[\"access_token\"]+f\"@api.github.com/repos/{owner}/{repo}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ace28-fedd-461a-92f8-76b870e673af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0321aca6-0c87-43f7-b887-60b85666bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching issues from: https://api.github.com/repos/langchain-ai/langchain/issues\n",
      "[{'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```\\r\\n'\n",
      "           '#----------------\\r\\n'\n",
      "           '# HuggingFace embedding  (no issue)\\r\\n'\n",
      "           'from langchain_huggingface import HuggingFaceEmbeddings\\r\\n'\n",
      "           'embeddings = '\n",
      "           'HuggingFaceEmbeddings(model=\"sentence-transformers/all-mpnet-base-v2\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '#----------------\\r\\n'\n",
      "           '# create langchain-chroma persistent client with collection name '\n",
      "           \"'example_collection;  (no issue)\\r\\n\"\n",
      "           'from langchain_chroma import Chroma\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'vector_store = Chroma(\\r\\n'\n",
      "           '    collection_name=\"example_collection\",   # collection is '\n",
      "           '\"table\" in vectore store \\r\\n'\n",
      "           '    embedding_function=hf,    # hf is huggingface embeddings '\n",
      "           'derived  from the previous step \\r\\n'\n",
      "           '    persist_directory=\"./vectorstore/chroma_langchain_db\",  # '\n",
      "           'Where to save data locally, remove if not necessary\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '#----------------\\r\\n'\n",
      "           '# add at least one document into  vector collection (no issue)\\r\\n'\n",
      "           'from uuid import uuid4\\r\\n'\n",
      "           'from langchain_core.documents import Document\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'document_1 = Document(\\r\\n'\n",
      "           '    page_content=\"I had chocolate chip pancakes and scrambled eggs '\n",
      "           'for breakfast this morning.\",\\r\\n'\n",
      "           '    metadata={\"source\": \"tweet\"},\\r\\n'\n",
      "           '    id=1,\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'documents = [\\r\\n'\n",
      "           '    document_1,\\r\\n'\n",
      "           ']\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'uuids = [str(uuid4()) for _ in range(len(documents))]\\r\\n'\n",
      "           'vector_store.add_documents(documents=documents, ids=uuids)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '#----------------  ERROR ENCOUNTERED when running get_by_ids \\r\\n'\n",
      "           '# attempt to run get_by_Ids yields NotImplementedError\\r\\n'\n",
      "           \"vector_store.get_by_ids(['6314982d-455f-47cc-bf97-6e5324f6af62'])\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '{\\r\\n'\n",
      "           '\\t\"name\": \"NotImplementedError\",\\r\\n'\n",
      "           '\\t\"message\": \"Chroma does not yet support get_by_ids.\",\\r\\n'\n",
      "           '\\t\"stack\": '\n",
      "           '\"---------------------------------------------------------------------------\\r\\n'\n",
      "           'NotImplementedError                       Traceback (most recent '\n",
      "           'call last)\\r\\n'\n",
      "           'Cell In[87], line 3\\r\\n'\n",
      "           '      1 # testing get the first two document ids\\r\\n'\n",
      "           \"      2 # ids = ['db1e5f74-f18d-4765-a193-d30eaed7552f', \"\n",
      "           \"'12861b34-df54-4e40-8e1e-ae9ea901d378']\\r\\n\"\n",
      "           '----> 3 '\n",
      "           \"vector_store.get_by_ids(['6314982d-455f-47cc-bf97-6e5324f6af62'])\\r\\n\"\n",
      "           '      5 # get_by_ids() functionality is not avaiable until '\n",
      "           'v0.2.11\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           '~/Documents/0_-_Python_Projects/05_Gen_AI/venv_3_11/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:164, '\n",
      "           'in VectorStore.get_by_ids(self, ids)\\r\\n'\n",
      "           '    140 \\\\\"\\\\\"\\\\\"Get documents by their IDs.\\r\\n'\n",
      "           '    141 \\r\\n'\n",
      "           '    142 The returned documents are expected to have the ID field '\n",
      "           'set to the ID of the\\r\\n'\n",
      "           '   (...)\\r\\n'\n",
      "           '    161 .. versionadded:: 0.2.11\\r\\n'\n",
      "           '    162 \\\\\"\\\\\"\\\\\"\\r\\n'\n",
      "           '    163 msg = f\\\\\"{self.__class__.__name__} does not yet support '\n",
      "           'get_by_ids.\\\\\"\\r\\n'\n",
      "           '--> 164 raise NotImplementedError(msg)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'NotImplementedError: Chroma does not yet support get_by_ids.\"\\r\\n'\n",
      "           '}\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           'I am just trying to run the vector_store method `get_by_ids`  - it '\n",
      "           'is listed as one of the available methods in '\n",
      "           '[here](https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html)\\r\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           '$ python -m langchain_core.sys_info\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'System Information\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> OS:  Darwin\\r\\n'\n",
      "           '> OS Version:  Darwin Kernel Version 23.6.0: Mon Jul 29 21:13:00 '\n",
      "           'PDT 2024; root:xnu-10063.141.2~1/RELEASE_X86_64\\r\\n'\n",
      "           '> Python Version:  3.11.10 (main, Nov 19 2024, 15:24:32) [Clang '\n",
      "           '12.0.0 (clang-1200.0.32.29)]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Package Information\\r\\n'\n",
      "           '-------------------\\r\\n'\n",
      "           '> langchain_core: 0.3.19\\r\\n'\n",
      "           '> langchain: 0.3.7\\r\\n'\n",
      "           '> langchain_community: 0.3.4\\r\\n'\n",
      "           '> langsmith: 0.1.143\\r\\n'\n",
      "           '> langchain_chroma: 0.1.4\\r\\n'\n",
      "           '> langchain_experimental: 0.3.3\\r\\n'\n",
      "           '> langchain_groq: 0.2.1\\r\\n'\n",
      "           '> langchain_huggingface: 0.1.2\\r\\n'\n",
      "           '> langchain_text_splitters: 0.3.2\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Optional packages not installed\\r\\n'\n",
      "           '-------------------------------\\r\\n'\n",
      "           '> langgraph\\r\\n'\n",
      "           '> langserve\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Other Dependencies\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> aiohttp: 3.11.6\\r\\n'\n",
      "           '> async-timeout: Installed. No version info available.\\r\\n'\n",
      "           '> chromadb: 0.5.20\\r\\n'\n",
      "           '> dataclasses-json: 0.6.7\\r\\n'\n",
      "           '> fastapi: 0.115.5\\r\\n'\n",
      "           '> groq: 0.12.0\\r\\n'\n",
      "           '> httpx: 0.27.2\\r\\n'\n",
      "           '> httpx-sse: 0.4.0\\r\\n'\n",
      "           '> huggingface-hub: 0.26.2\\r\\n'\n",
      "           '> jsonpatch: 1.33\\r\\n'\n",
      "           '> numpy: 1.26.4\\r\\n'\n",
      "           '> orjson: 3.10.11\\r\\n'\n",
      "           '> packaging: 24.2\\r\\n'\n",
      "           '> pydantic: 2.9.2\\r\\n'\n",
      "           '> pydantic-settings: 2.6.1\\r\\n'\n",
      "           '> PyYAML: 6.0.2\\r\\n'\n",
      "           '> requests: 2.32.3\\r\\n'\n",
      "           '> requests-toolbelt: 1.0.0\\r\\n'\n",
      "           '> sentence-transformers: 3.3.1\\r\\n'\n",
      "           '> SQLAlchemy: 2.0.36\\r\\n'\n",
      "           '> tenacity: 9.0.0\\r\\n'\n",
      "           '> tokenizers: 0.20.3\\r\\n'\n",
      "           '> transformers: 4.46.3\\r\\n'\n",
      "           '> typing-extensions: 4.12.2',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T01:13:50Z',\n",
      "  '_issueNumber': '28276',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'langchain-chroma== 0.1.4   method get_by_ids is listed in '\n",
      "            'documentation BUT I am getting NotImplementedError',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Thank you for contributing to LangChain!\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Ctrl+F to find instances of `langchain-databricks` and replace '\n",
      "           'with `databricks-langchain`. \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Additional guidelines:\\r\\n'\n",
      "           '- Make sure optional dependencies are imported within a '\n",
      "           'function.\\r\\n'\n",
      "           '- Please do not add dependencies to pyproject.toml files (even '\n",
      "           'optional ones) unless they are required for unit tests.\\r\\n'\n",
      "           '- Most PRs should not touch more than one package.\\r\\n'\n",
      "           '- Changes should be backwards compatible.\\r\\n'\n",
      "           '- If you are adding something to community, do not re-import it in '\n",
      "           'langchain.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'If no one reviews your PR within a few days, please @-mention one '\n",
      "           'of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T23:51:30Z',\n",
      "  '_issueNumber': '28274',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'docs: Update langchain docs to new Databricks package',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Ensure your VertexAI credentials are configured\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from langchain_google_vertexai import ChatVertexAI\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'model = ChatVertexAI(model=\"gemini-1.5-flash\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'model.invoke(\"Hello, world!\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '```python\\r\\n'\n",
      "           '---------------------------------------------------------------------------\\r\\n'\n",
      "           'NameError                                 Traceback (most recent '\n",
      "           'call last)\\r\\n'\n",
      "           'File '\n",
      "           '/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:815, '\n",
      "           'in GenerateSchema._resolve_forward_ref(self, obj)\\r\\n'\n",
      "           '    814 try:\\r\\n'\n",
      "           '--> 815     obj = _typing_extra.eval_type_backport(obj, '\n",
      "           '*self._types_namespace)\\r\\n'\n",
      "           '    816 except NameError as e:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           '/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_typing_extra.py:534, '\n",
      "           'in eval_type_backport(value, globalns, localns, type_params)\\r\\n'\n",
      "           '    533 try:\\r\\n'\n",
      "           '--> 534     return _eval_type_backport(value, globalns, localns, '\n",
      "           'type_params)\\r\\n'\n",
      "           '    535 except TypeError as e:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           '/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_typing_extra.py:558, '\n",
      "           'in _eval_type_backport(value, globalns, localns, type_params)\\r\\n'\n",
      "           '    557 try:\\r\\n'\n",
      "           '--> 558     return _eval_type(value, globalns, localns, '\n",
      "           'type_params)\\r\\n'\n",
      "           '    559 except TypeError as e:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           '/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_typing_extra.py:592, '\n",
      "           'in _eval_type(value, globalns, localns, type_params)\\r\\n'\n",
      "           '    591 else:\\r\\n'\n",
      "           '--> 592     return typing._eval_type(  # type: ignore\\r\\n'\n",
      "           '    593         value, globalns, localns\\r\\n'\n",
      "           '    594     )\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:327, in _eval_type(t, '\n",
      "           'globalns, localns, recursive_guard)\\r\\n'\n",
      "           '    326 if isinstance(t, ForwardRef):\\r\\n'\n",
      "           '--> 327     return t._evaluate(globalns, localns, '\n",
      "           'recursive_guard)\\r\\n'\n",
      "           '    328 if isinstance(t, (_GenericAlias, GenericAlias, '\n",
      "           'types.UnionType)):\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:699, in '\n",
      "           'ForwardRef._evaluate(self, globalns, localns, recursive_guard)\\r\\n'\n",
      "           '    693 type_ = _type_check(\\r\\n'\n",
      "           '    694     eval(self.__forward_code__, globalns, localns),\\r\\n'\n",
      "           '    695     \"Forward references must evaluate to types.\",\\r\\n'\n",
      "           '    696     is_argument=self.__forward_is_argument__,\\r\\n'\n",
      "           '    697     allow_special_forms=self.__forward_is_class__,\\r\\n'\n",
      "           '    698 )\\r\\n'\n",
      "           '--> 699 self.__forward_value__ = _eval_type(\\r\\n'\n",
      "           '    700     type_, globalns, localns, recursive_guard | '\n",
      "           '{self.__forward_arg__}\\r\\n'\n",
      "           '    701 )\\r\\n'\n",
      "           '    702 self.__forward_evaluated__ = True\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:329, in _eval_type(t, '\n",
      "           'globalns, localns, recursive_guard)\\r\\n'\n",
      "           '    328 if isinstance(t, (_GenericAlias, GenericAlias, '\n",
      "           'types.UnionType)):\\r\\n'\n",
      "           '--> 329     ev_args = tuple(_eval_type(a, globalns, localns, '\n",
      "           'recursive_guard) for a in t.__args__)\\r\\n'\n",
      "           '    330     if ev_args == t.__args__:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:329, in <genexpr>(.0)\\r\\n'\n",
      "           '    328 if isinstance(t, (_GenericAlias, GenericAlias, '\n",
      "           'types.UnionType)):\\r\\n'\n",
      "           '--> 329     ev_args = tuple(_eval_type(a, globalns, localns, '\n",
      "           'recursive_guard) for a in t.__args__)\\r\\n'\n",
      "           '    330     if ev_args == t.__args__:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:327, in _eval_type(t, '\n",
      "           'globalns, localns, recursive_guard)\\r\\n'\n",
      "           '    326 if isinstance(t, ForwardRef):\\r\\n'\n",
      "           '--> 327     return t._evaluate(globalns, localns, '\n",
      "           'recursive_guard)\\r\\n'\n",
      "           '    328 if isinstance(t, (_GenericAlias, GenericAlias, '\n",
      "           'types.UnionType)):\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:699, in '\n",
      "           'ForwardRef._evaluate(self, globalns, localns, recursive_guard)\\r\\n'\n",
      "           '    693 type_ = _type_check(\\r\\n'\n",
      "           '    694     eval(self.__forward_code__, globalns, localns),\\r\\n'\n",
      "           '    695     \"Forward references must evaluate to types.\",\\r\\n'\n",
      "           '    696     is_argument=self.__forward_is_argument__,\\r\\n'\n",
      "           '    697     allow_special_forms=self.__forward_is_class__,\\r\\n'\n",
      "           '    698 )\\r\\n'\n",
      "           '--> 699 self.__forward_value__ = _eval_type(\\r\\n'\n",
      "           '    700     type_, globalns, localns, recursive_guard | '\n",
      "           '{self.__forward_arg__}\\r\\n'\n",
      "           '    701 )\\r\\n'\n",
      "           '    702 self.__forward_evaluated__ = True\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:329, in _eval_type(t, '\n",
      "           'globalns, localns, recursive_guard)\\r\\n'\n",
      "           '    328 if isinstance(t, (_GenericAlias, GenericAlias, '\n",
      "           'types.UnionType)):\\r\\n'\n",
      "           '--> 329     ev_args = tuple(_eval_type(a, globalns, localns, '\n",
      "           'recursive_guard) for a in t.__args__)\\r\\n'\n",
      "           '    330     if ev_args == t.__args__:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:329, in <genexpr>(.0)\\r\\n'\n",
      "           '    328 if isinstance(t, (_GenericAlias, GenericAlias, '\n",
      "           'types.UnionType)):\\r\\n'\n",
      "           '--> 329     ev_args = tuple(_eval_type(a, globalns, localns, '\n",
      "           'recursive_guard) for a in t.__args__)\\r\\n'\n",
      "           '    330     if ev_args == t.__args__:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File /opt/conda/lib/python3.10/typing.py:329, in _eval_type(t, '\n",
      "           'globalns, localns, recursive_guard)\\r\\n'\n",
      "           '    328 if isinstance(t, (_GenericAlias, Generi',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T22:43:53Z',\n",
      "  '_issueNumber': '28271',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': \"PydanticUndefinedAnnotation: name 'SafetySetting' is not defined \"\n",
      "            'using ChatVertexAI',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- **Description:** Corrected the parameter name in the '\n",
      "           'HuggingFaceEmbeddings documentation under '\n",
      "           'integrations/text_embedding/ from model to model_name to align '\n",
      "           'with the actual code usage in the langchain_huggingface '\n",
      "           'package.\\r\\n'\n",
      "           '- **Issue:** Fixes #28231\\r\\n'\n",
      "           '- **Dependencies:** None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T22:12:02Z',\n",
      "  '_issueNumber': '28269',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'docs: correct HuggingFaceEmbeddings documentation model param',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'We have a test '\n",
      "           '[test_structured_few_shot_examples](https://github.com/langchain-ai/langchain/blob/ad4333ca032033097c663dfe818c5c892c368bd6/libs/standard-tests/langchain_tests/integration_tests/chat_models.py#L546) '\n",
      "           'in standard integration tests that implements a version of '\n",
      "           'tool-calling few shot examples that works with ~all tested '\n",
      "           'providers. The formulation supported by ~all providers is: `human '\n",
      "           'message, tool call, tool message, AI reponse`.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           ' Here we update '\n",
      "           '`langchain_core.utils.function_calling.tool_example_to_messages` '\n",
      "           'to support this formulation.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'The `tool_example_to_messages` util is undocumented outside of our '\n",
      "           'API reference. IMO, if we are testing that this function works '\n",
      "           'across all providers, it can be helpful to feature it in our '\n",
      "           'guides. The structured few-shot examples we document at the moment '\n",
      "           'require users to implement this function and can be simplified.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T20:47:32Z',\n",
      "  '_issueNumber': '28267',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'core[patch]: support final AIMessage responses in '\n",
      "            '`tool_example_to_messages`',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\r\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\r\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\r\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\r\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Example Code\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from langchain_community.chat_models import ChatCoze\\r\\n'\n",
      "           'from langchain_core.messages import SystemMessage, HumanMessage\\r\\n'\n",
      "           'import os\\r\\n'\n",
      "           'from config.config_llm import *\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'chat = ChatCoze(\\r\\n'\n",
      "           '    coze_api_key= coze_apikey,\\r\\n'\n",
      "           '    bot_id=\"*******\",\\r\\n'\n",
      "           '    user=\"*******\",\\r\\n'\n",
      "           '    streaming=True\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '#### test1：仅使用 HumanMessage\\r\\n'\n",
      "           'messages1 = [\\r\\n'\n",
      "           '    HumanMessage(content=\"Who are you?\")\\r\\n'\n",
      "           ']\\r\\n'\n",
      "           'response1 = chat(messages1)\\r\\n'\n",
      "           'print(\"Test 1 - Only HumanMessage:\", response1)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '##### test2：使用 SystemMessage + HumanMessage\\r\\n'\n",
      "           'messages2 = [\\r\\n'\n",
      "           '    SystemMessage(content=\"You are a helpful math tutor who speaks '\n",
      "           'like Shakespeare.\"),\\r\\n'\n",
      "           '    HumanMessage(content=\"What is 2+2?\")\\r\\n'\n",
      "           ']\\r\\n'\n",
      "           'response2 = chat(messages2)\\r\\n'\n",
      "           'print(\"Test 2 - With SystemMessage:\", response2)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '(i:\\\\Diting\\\\diting_backend\\\\.conda) PS '\n",
      "           'I:\\\\Diting\\\\diting_backend> python .\\\\test.py\\r\\n'\n",
      "           'I:\\\\Diting\\\\diting_backend\\\\test.py:17: '\n",
      "           'LangChainDeprecationWarning: The method `BaseChatModel.__call__` '\n",
      "           'was deprecated in langchain-core 0.1.7 and will be removed in 1.0. '\n",
      "           'Use :meth:`~invoke` instead.\\r\\n'\n",
      "           '  response1 = chat(messages1)\\r\\n'\n",
      "           'Test 1 - Only HumanMessage: content=\"I\\'m Claude_DITING. How can I '\n",
      "           'assist you today?\" additional_kwargs={} response_metadata={} '\n",
      "           \"id='run-996ef539-8e93-4318-ad80-6e9917ef3b99-0'\\r\\n\"\n",
      "           \"Test 2 - With SystemMessage: content='Verily, the sum of 2 and 2 \"\n",
      "           \"is 4.' additional_kwargs={} response_metadata={} \"\n",
      "           \"id='run-97b81d24-8c14-4aca-9739-62721a2ebbdf-0'\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '### Description\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'The system message in ChatCoze is not working\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### System Info\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'python 3.11\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'langchain                                0.3.7\\r\\n'\n",
      "           'langchain-anthropic                      0.3.0\\r\\n'\n",
      "           'langchain-chroma                         0.1.4\\r\\n'\n",
      "           'langchain-cohere                         0.3.2\\r\\n'\n",
      "           'langchain-community                      0.3.7\\r\\n'\n",
      "           'langchain-core                           0.3.19\\r\\n'\n",
      "           'langchain-experimental                   0.3.3\\r\\n'\n",
      "           'langchain-ollama                         0.2.0\\r\\n'\n",
      "           'langchain-openai                         0.2.9\\r\\n'\n",
      "           'langchain-text-splitters                 0.3.2\\r\\n'\n",
      "           'langchainhub                             0.1.21\\r\\n'\n",
      "           'langsmith                                0.1.144\\r\\n'\n",
      "           'lxml                                     5.3.0',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T15:25:52Z',\n",
      "  '_issueNumber': '28261',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'The system message in ChatCoze is not working',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '# What problem are we fixing?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Currently documents loaded using `O365BaseLoader` fetch source '\n",
      "           \"from `file.web_url` (where `file` is `<class 'O365.drive.File'>`). \"\n",
      "           'This works well for `.pdf` documents. Unfortunately office '\n",
      "           'documents (`.xlsx`, `.docx` ...) pass their `web_url` if following '\n",
      "           'format:\\r\\n'\n",
      "           '`https://sharepoint_address/sites/path/to/library/root/Doc.aspx?sourcedoc=%XXXXXXXX-1111-1111-XXXX-XXXXXXXXXX%7D&file=filename.xlsx&action=default&mobileredirect=true`\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This obfuscates the path to the file. This PR utilizes the parrent '\n",
      "           \"folder's path and file name to reconstruct the actual location of \"\n",
      "           \"the file. Knowing the file's location can be crucial for some RAG \"\n",
      "           \"applications (path to the file can carry information we don't want \"\n",
      "           'to loose).\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'If no one reviews your PR within a few days, please @-mention one '\n",
      "           'of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T14:36:29Z',\n",
      "  '_issueNumber': '28260',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'cummunity: [bugfix] fix source path for office files in O365',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## **Description:**\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Enable `ConfluenceLoader` to include labels with `include_labels` '\n",
      "           'option (`false` by default for backward compatibility). and the '\n",
      "           'labels are set to `metadata` in the `Document`. e.g. `{\"labels\": '\n",
      "           '[\"l1\", \"l2\"]}`\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Notes\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Confluence API supports to get labels by providing '\n",
      "           '`metadata.labels` to `expand` query parameter \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'All of the following functions support `expand` in the same '\n",
      "           'way:\\r\\n'\n",
      "           '- confluence.get_page_by_id\\r\\n'\n",
      "           '- confluence.get_all_pages_by_label\\r\\n'\n",
      "           '- confluence.get_all_pages_from_space\\r\\n'\n",
      "           '- cql (internally using '\n",
      "           '[/api/content/search](https://developer.atlassian.com/cloud/confluence/rest/v1/api-group-content/#api-wiki-rest-api-content-search-get))\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## **Issue:**\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'No issue related to this PR.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## **Dependencies:** \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'No changes.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## **Twitter handle:** \\r\\n'\n",
      "           '\\r\\n'\n",
      "           '[@gymnstcs](https://x.com/gymnstcs)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"- [x] **Add tests and docs**: If you're adding a new integration, \"\n",
      "           'please include\\r\\n'\n",
      "           '  1. a test for the integration, preferably unit tests that do not '\n",
      "           'rely on network access,\\r\\n'\n",
      "           '  2. an example notebook showing its use. It lives in '\n",
      "           '`docs/docs/integrations` directory.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x] **Lint and test**: Run `make format`, `make lint` and `make '\n",
      "           \"test` from the root of the package(s) you've modified. See \"\n",
      "           'contribution guidelines for more: '\n",
      "           'https://python.langchain.com/docs/contributing/\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T12:15:42Z',\n",
      "  '_issueNumber': '28259',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'community: add include_labels option to ConfluenceLoader',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```python\\r\\n'\n",
      "           'from langchain.memory import ConversationSummaryBufferMemory\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'memory = ConversationSummaryBufferMemory(\\r\\n'\n",
      "           '    llm=chat,\\r\\n'\n",
      "           '    input_key=\"input\",\\r\\n'\n",
      "           '    output_key=\"output\",\\r\\n'\n",
      "           '    max_token_limit=1024,\\r\\n'\n",
      "           '    memory_key=\"chat_history\",\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '{\\r\\n'\n",
      "           '\\t\"name\": \"PydanticUserError\",\\r\\n'\n",
      "           '\\t\"message\": \"`ConversationSummaryBufferMemory` is not fully '\n",
      "           'defined; you should define `BaseCache`, then call '\n",
      "           '`ConversationSummaryBufferMemory.model_rebuild()`.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'For further information visit '\n",
      "           'https://errors.pydantic.dev/2.10/u/class-not-fully-defined\",\\r\\n'\n",
      "           '\\t\"stack\": '\n",
      "           '\"---------------------------------------------------------------------------\\r\\n'\n",
      "           'PydanticUserError                         Traceback (most recent '\n",
      "           'call last)\\r\\n'\n",
      "           'Cell In[45], line 3\\r\\n'\n",
      "           '      1 from langchain.memory import '\n",
      "           'ConversationSummaryBufferMemory\\r\\n'\n",
      "           '----> 3 memory = ConversationSummaryBufferMemory(\\r\\n'\n",
      "           '      4     llm=chat,\\r\\n'\n",
      "           '      5     input_key=\\\\\"input\\\\\",\\r\\n'\n",
      "           '      6     output_key=\\\\\"output\\\\\",\\r\\n'\n",
      "           '      7     max_token_limit=1024,\\r\\n'\n",
      "           '      8     memory_key=\\\\\"chat_history\\\\\",\\r\\n'\n",
      "           '      9 )\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           'c:\\\\\\\\xxxx\\\\site-packages\\\\\\\\langchain_core\\\\\\\\_api\\\\\\\\deprecation.py:216, '\n",
      "           'in '\n",
      "           'deprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance(self, '\n",
      "           '*args, **kwargs)\\r\\n'\n",
      "           '    214     warned = True\\r\\n'\n",
      "           '    215     emit_warning()\\r\\n'\n",
      "           '--> 216 return wrapped(self, *args, **kwargs)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           'xxxx\\\\site-packages\\\\\\\\langchain_core\\\\\\\\_api\\\\\\\\deprecation.py:216, '\n",
      "           'in '\n",
      "           'deprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance(self, '\n",
      "           '*args, **kwargs)\\r\\n'\n",
      "           '    214     warned = True\\r\\n'\n",
      "           '    215     emit_warning()\\r\\n'\n",
      "           '--> 216 return wrapped(self, *args, **kwargs)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           'xxxx\\\\\\\\site-packages\\\\\\\\langchain_core\\\\\\\\_api\\\\\\\\deprecation.py:216, '\n",
      "           'in '\n",
      "           'deprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance(self, '\n",
      "           '*args, **kwargs)\\r\\n'\n",
      "           '    214     warned = True\\r\\n'\n",
      "           '    215     emit_warning()\\r\\n'\n",
      "           '--> 216 return wrapped(self, *args, **kwargs)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           'xxxx\\\\\\\\site-packages\\\\\\\\langchain_core\\\\\\\\load\\\\\\\\serializable.py:125, '\n",
      "           'in Serializable.__init__(self, *args, **kwargs)\\r\\n'\n",
      "           '    123 def __init__(self, *args: Any, **kwargs: Any) -> None:\\r\\n'\n",
      "           '    124     \\\\\"\\\\\"\\\\\"\\\\\"\\\\\"\\\\\"\\r\\n'\n",
      "           '--> 125     super().__init__(*args, **kwargs)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           'xxxx\\\\\\\\site-packages\\\\\\\\langchain_core\\\\\\\\_api\\\\\\\\deprecation.py:216, '\n",
      "           'in '\n",
      "           'deprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance(self, '\n",
      "           '*args, **kwargs)\\r\\n'\n",
      "           '    214     warned = True\\r\\n'\n",
      "           '    215     emit_warning()\\r\\n'\n",
      "           '--> 216 return wrapped(self, *args, **kwargs)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    [... skipping hidden 1 frame]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           'xxxx\\\\site-packages\\\\\\\\pydantic\\\\\\\\_internal\\\\\\\\_mock_val_ser.py:100, '\n",
      "           'in MockValSer.__getattr__(self, item)\\r\\n'\n",
      "           \"     98 # raise an AttributeError if `item` doesn't exist\\r\\n\"\n",
      "           '     99 getattr(self._val_or_ser, item)\\r\\n'\n",
      "           '--> 100 raise PydanticUserError(self._error_message, '\n",
      "           'code=self._code)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'PydanticUserError: `ConversationSummaryBufferMemory` is not fully '\n",
      "           'defined; you should define `BaseCache`, then call '\n",
      "           '`ConversationSummaryBufferMemory.model_rebuild()`.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'For further information visit '\n",
      "           'https://errors.pydantic.dev/2.10/u/class-not-fully-defined\"\\r\\n'\n",
      "           '}\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           \"I've upgrade my project's langchain package to latest, and when i \"\n",
      "           'create ConversationSummaryBufferMemory, encountered the '\n",
      "           'PydanticUserError \\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           'System Information\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> OS:  Windows\\r\\n'\n",
      "           '> OS Version:  10.0.22631\\r\\n'\n",
      "           '> Python Version:  3.11.10 | packaged by Anaconda, Inc. | (main, '\n",
      "           'Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Package Information\\r\\n'\n",
      "           '-------------------\\r\\n'\n",
      "           '> langchain_core: 0.3.19\\r\\n'\n",
      "           '> langchain: 0.3.7\\r\\n'\n",
      "           '> langchain_community: 0.3.7\\r\\n'\n",
      "           '> langsmith: 0.1.144\\r\\n'\n",
      "           '> langchain_openai: 0.2.9\\r\\n'\n",
      "           '> langchain_text_splitters: 0.3.2\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Optional packages not installed\\r\\n'\n",
      "           '-------------------------------\\r\\n'\n",
      "           '> langgraph\\r\\n'\n",
      "           '> langserve\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Other Dependencies\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> aiohttp: 3.11.6\\r\\n'\n",
      "           '> async-timeout: Installed. No version info available.\\r\\n'\n",
      "           '> dataclasses-json: 0.6.7\\r\\n'\n",
      "           '> httpx: 0.27.2\\r\\n'\n",
      "           '> httpx-sse: 0.4.0\\r\\n'\n",
      "           '> jsonpatch: 1.33\\r\\n'\n",
      "           '> numpy: 1.26.4\\r\\n'\n",
      "           '> openai: 1.55.0\\r\\n'\n",
      "           '> orjson: 3.10.11\\r\\n'\n",
      "           '> packaging: 24.2\\r\\n'\n",
      "           '> pydantic: 2.10.0\\r\\n'\n",
      "           '> pydantic-settings: 2.6.1\\r\\n'\n",
      "           '> PyYAML: 6.0.2\\r\\n'\n",
      "           '> requests: 2.32.3\\r\\n'\n",
      "           '> requests-toolbelt: 1.0.0\\r\\n'\n",
      "           '> SQLAlchemy: 2.0.35\\r\\n'\n",
      "           '> tenacity: 9.0.0\\r\\n'\n",
      "           '> tiktoken: 0.8.0\\r\\n'\n",
      "           '> typing-extensions: 4.12.2',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T11:18:25Z',\n",
      "  '_issueNumber': '28257',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'PydanticUserError: `ConversationSummaryBufferMemory` is not fully '\n",
      "            'defined; you should define `BaseCache`, then call '\n",
      "            '`ConversationSummaryBufferMemory.model_rebuild()`.',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### URL\\n'\n",
      "           '\\n'\n",
      "           'https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html#langchain_community.vectorstores.faiss.FAISS.get_by_ids\\n'\n",
      "           '\\n'\n",
      "           '### Checklist\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I included a link to the documentation page I am referring '\n",
      "           'to (if applicable).\\n'\n",
      "           '\\n'\n",
      "           '### Issue with current documentation:\\n'\n",
      "           '\\n'\n",
      "           \"Docs for FAISS describe get_by_id but it doesn't seem to be \"\n",
      "           'implemented as yet. \\n'\n",
      "           '\\n'\n",
      "           '### Idea or request for content:\\n'\n",
      "           '\\n'\n",
      "           'I suggest either implementing get_by_id or removing it from the '\n",
      "           'docs.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T10:41:14Z',\n",
      "  '_issueNumber': '28256',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': \"DOC: Docs describe FAISS get_by_id but it isn't implementd\",\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           'The following code straight from the docs fails already at the '\n",
      "           'import statement:\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'from typing import Optional\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from pydantic import BaseModel, Field\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from langchain_openai import ChatOpenAI\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'llm = ChatOpenAI(model=\"gpt-4o-mini\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Pydantic\\r\\n'\n",
      "           'class Joke(BaseModel):\\r\\n'\n",
      "           '    \"\"\"Joke to tell user.\"\"\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    setup: str = Field(description=\"The setup of the joke\")\\r\\n'\n",
      "           '    punchline: str = Field(description=\"The punchline to the '\n",
      "           'joke\")\\r\\n'\n",
      "           '    rating: Optional[int] = Field(default=None, description=\"How '\n",
      "           'funny the joke is, from 1 to 10\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'structured_llm = llm.with_structured_output(Joke)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'structured_llm.invoke(\"Tell me a joke about cats\")\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '```\\r\\n'\n",
      "           'C:\\\\Users\\\\Egor\\\\Dropbox\\\\Code\\\\langchain\\\\libs\\\\partners\\\\openai\\\\langchain_openai\\\\chat_models\\\\__init__.py:1: '\n",
      "           'LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain '\n",
      "           'uses pydantic v2 internally. The langchain_core.pydantic_v1 module '\n",
      "           'was a compatibility shim for pydantic v1, and should no longer be '\n",
      "           'used. Please update the code to import from Pydantic directly.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'C:\\\\Users\\\\Egor\\\\Dropbox\\\\Code\\\\langchain\\\\libs\\\\partners\\\\openai\\\\langchain_openai\\\\chat_models\\\\__init__.py:1: '\n",
      "           'LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain '\n",
      "           'uses pydantic v2 internally. The langchain_core.pydantic_v1 module '\n",
      "           'was a compatibility shim for pydantic v1, and should no longer be '\n",
      "           'used. Please update the code to import from Pydantic directly.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'For example, replace imports like: `from '\n",
      "           'langchain_core.pydantic_v1 import BaseModel`\\r\\n'\n",
      "           'with: `from pydantic import BaseModel`\\r\\n'\n",
      "           'or the v1 compatibility namespace if you are working in a code '\n",
      "           'base that has not been fully upgraded to pydantic 2 yet. \\tfrom '\n",
      "           'pydantic.v1 import BaseModel\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '  from langchain_openai.chat_models.azure import '\n",
      "           'AzureChatOpenAI\\r\\n'\n",
      "           'C:\\\\Users\\\\Egor\\\\.conda\\\\envs\\\\motleycrew3.11\\\\Lib\\\\site-packages\\\\pydantic\\\\_internal\\\\_config.py:345: '\n",
      "           'UserWarning: Valid config keys have changed in V2:\\r\\n'\n",
      "           \"* 'allow_population_by_field_name' has been renamed to \"\n",
      "           \"'populate_by_name'\\r\\n\"\n",
      "           '  warnings.warn(message, UserWarning)\\r\\n'\n",
      "           'Traceback (most recent call last):\\r\\n'\n",
      "           '  File \"<frozen importlib._bootstrap>\", line 1176, in '\n",
      "           '_find_and_load\\r\\n'\n",
      "           '  File \"<frozen importlib._bootstrap>\", line 1147, in '\n",
      "           '_find_and_load_unlocked\\r\\n'\n",
      "           '  File \"<frozen importlib._bootstrap>\", line 690, in '\n",
      "           '_load_unlocked\\r\\n'\n",
      "           '  File \"<frozen importlib._bootstrap_external>\", line 940, in '\n",
      "           'exec_module\\r\\n'\n",
      "           '  File \"<frozen importlib._bootstrap>\", line 241, in '\n",
      "           '_call_with_frames_removed\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\Dropbox\\\\Code\\\\langchain\\\\libs\\\\partners\\\\openai\\\\langchain_openai\\\\__init__.py\", '\n",
      "           'line 1, in <module>\\r\\n'\n",
      "           '    from langchain_openai.chat_models import AzureChatOpenAI, '\n",
      "           'ChatOpenAI\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\Dropbox\\\\Code\\\\langchain\\\\libs\\\\partners\\\\openai\\\\langchain_openai\\\\chat_models\\\\__init__.py\", '\n",
      "           'line 1, in <module>\\r\\n'\n",
      "           '    from langchain_openai.chat_models.azure import '\n",
      "           'AzureChatOpenAI\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\Dropbox\\\\Code\\\\langchain\\\\libs\\\\partners\\\\openai\\\\langchain_openai\\\\chat_models\\\\azure.py\", '\n",
      "           'line 41, in <module>\\r\\n'\n",
      "           '    from langchain_openai.chat_models.base import '\n",
      "           'BaseChatOpenAI\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\Dropbox\\\\Code\\\\langchain\\\\libs\\\\partners\\\\openai\\\\langchain_openai\\\\chat_models\\\\base.py\", '\n",
      "           'line 353, in <module>\\r\\n'\n",
      "           '    class BaseChatOpenAI(BaseChatModel):\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\.conda\\\\envs\\\\motleycrew3.11\\\\Lib\\\\site-packages\\\\pydantic\\\\_internal\\\\_model_construction.py\", '\n",
      "           'line 226, in __new__\\r\\n'\n",
      "           '    complete_model_class(\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\.conda\\\\envs\\\\motleycrew3.11\\\\Lib\\\\site-packages\\\\pydantic\\\\_internal\\\\_model_construction.py\", '\n",
      "           'line 658, in complete_model_class\\r\\n'\n",
      "           '    schema = cls.__get_pydantic_core_schema__(cls, handler)\\r\\n'\n",
      "           '             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\.conda\\\\envs\\\\motleycrew3.11\\\\Lib\\\\site-packages\\\\pydantic\\\\main.py\", '\n",
      "           'line 697, in __get_pydantic_core_schema__\\r\\n'\n",
      "           '    return handler(source)\\r\\n'\n",
      "           '           ^^^^^^^^^^^^^^^\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\.conda\\\\envs\\\\motleycrew3.11\\\\Lib\\\\site-packages\\\\pydantic\\\\_internal\\\\_schema_generation_shared.py\", '\n",
      "           'line 84, in __call__\\r\\n'\n",
      "           '    schema = self._handler(source_type)\\r\\n'\n",
      "           '             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\.conda\\\\envs\\\\motleycrew3.11\\\\Lib\\\\site-packages\\\\pydantic\\\\_internal\\\\_generate_schema.py\", '\n",
      "           'line 612, in generate_schema\\r\\n'\n",
      "           '    schema = self._generate_schema_inner(obj)\\r\\n'\n",
      "           '             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n'\n",
      "           '  File '\n",
      "           '\"C:\\\\Users\\\\Egor\\\\.conda\\\\envs\\\\motleycrew3.11\\\\Lib\\\\site-packages\\\\pydantic\\\\_internal\\\\_generate_schema.py\", '\n",
      "           'line 881, in _generate_schema_inner\\r\\n'\n",
      "           '    return self._model_schema(obj)\\r\\n'\n",
      "           '           ^^^^^^^^^^^^^^^^^^^^^^^\\r\\n'\n",
      "           '  File \"C:\\\\Users\\\\Egor\\\\.conda\\\\envs\\\\motleycrew3.11\\\\',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T10:40:40Z',\n",
      "  '_issueNumber': '28255',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': \"Can't import ChatOpenAI: The `__modify_schema__` method is not \"\n",
      "            'supported in Pydantic v2. ',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- **Description:**  Support for new Pinecone class '\n",
      "           'PineconeVectorStore in PebbloRetrievalQA.\\r\\n'\n",
      "           '- **Issue:** NA\\r\\n'\n",
      "           '- **Dependencies:** NA\\r\\n'\n",
      "           '- **Tests:** -\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T09:29:50Z',\n",
      "  '_issueNumber': '28253',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'community[minor] Pebblo: Support for new Pinecone class '\n",
      "            'PineconeVectorStore',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### URL\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Checklist\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I included a link to the documentation page I am referring '\n",
      "           'to (if applicable).\\n'\n",
      "           '\\n'\n",
      "           '### Issue with current documentation:\\n'\n",
      "           '\\n'\n",
      "           'I need to know on the maximum chunk size that can be return from '\n",
      "           'SemanticChunker.split_documents() for large documents.\\r\\n'\n",
      "           'Can it be more than 8k token as i need to send the chunk for '\n",
      "           'embedding, chunk with more than 8k token will fail with Azure '\n",
      "           'embedding model.\\r\\n'\n",
      "           'Need Help!!\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Idea or request for content:\\n'\n",
      "           '\\n'\n",
      "           'Documentation should cleary explain this',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T06:50:49Z',\n",
      "  '_issueNumber': '28250',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'DOC: What is the maximum chunk size returned from '\n",
      "            'SemanticChunker.split_documents()',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- Description: Azure AI takes an issue with the safe_mode '\n",
      "           'parameter being set to False instead of None. Therefore, this PR '\n",
      "           'changes the default value of safe_mode from False to None. This '\n",
      "           'results in it being filtered out before the request is sent - '\n",
      "           'avoind the extra-parameter issue described below.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- Issue: #26029\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- Dependencies: /',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T16:41:12Z',\n",
      "  '_issueNumber': '28233',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'partners: fix of issue #26029',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'The `FewShotSQLTool` gets some SQL query examples from a '\n",
      "           '`BaseExampleSelector` for a given question.\\r\\n'\n",
      "           'This is useful to provide [few-shot '\n",
      "           'examples](https://python.langchain.com/docs/how_to/sql_prompting/#few-shot-examples) '\n",
      "           'capability to an SQL agent.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Example usage:\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'from langchain.agents.agent_toolkits.sql.prompt import '\n",
      "           'SQL_PREFIX\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'embeddings = OpenAIEmbeddings()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'example_selector = '\n",
      "           'SemanticSimilarityExampleSelector.from_examples(\\r\\n'\n",
      "           '    examples,\\r\\n'\n",
      "           '    embeddings,\\r\\n'\n",
      "           '    AstraDB,\\r\\n'\n",
      "           '    k=5,\\r\\n'\n",
      "           '    input_keys=[\"input\"],\\r\\n'\n",
      "           '    collection_name=\"lc_few_shots\",\\r\\n'\n",
      "           '    token=ASTRA_DB_APPLICATION_TOKEN,\\r\\n'\n",
      "           '    api_endpoint=ASTRA_DB_API_ENDPOINT,\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'few_shot_sql_tool = FewShotSQLTool(\\r\\n'\n",
      "           '    example_selector=example_selector,\\r\\n'\n",
      "           '    description=\"Input to this tool is the input question, output '\n",
      "           'is a few SQL query examples related to the input question. Always '\n",
      "           'use this tool before checking the query with '\n",
      "           'sql_db_query_checker!\"\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'agent = create_sql_agent(\\r\\n'\n",
      "           '    llm=llm, \\r\\n'\n",
      "           '    db=db, \\r\\n'\n",
      "           '    prefix=SQL_PREFIX + \"\\\\nYou MUST get some example queries '\n",
      "           'before creating the query.\", \\r\\n'\n",
      "           '    extra_tools=[few_shot_sql_tool]\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'result = agent.invoke({\"input\": \"How many artists are there?\"})\\r\\n'\n",
      "           '```\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T15:48:10Z',\n",
      "  '_issueNumber': '28232',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'community: Add FewShotSQLTool',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### URL\\n'\n",
      "           '\\n'\n",
      "           'https://python.langchain.com/docs/integrations/text_embedding/\\n'\n",
      "           '\\n'\n",
      "           '### Checklist\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I included a link to the documentation page I am referring '\n",
      "           'to (if applicable).\\n'\n",
      "           '\\n'\n",
      "           '### Issue with current documentation:\\n'\n",
      "           '\\n'\n",
      "           'Currently the code snippet for the hugging face model is \\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'from langchain_huggingface import HuggingFaceEmbeddings\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'embeddings = '\n",
      "           'HuggingFaceEmbeddings(model=\"sentence-transformers/all-mpnet-base-v2\")\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'The `model` param should be `model_name` instead as per the '\n",
      "           'langchain_huggingface '\n",
      "           '[docs](https://python.langchain.com/api_reference/huggingface/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html#langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings) \\n'\n",
      "           '\\n'\n",
      "           '### Idea or request for content:\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T14:45:29Z',\n",
      "  '_issueNumber': '28231',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'DOC: Incorrect Code Sample for Hugging Face Embeddings',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```\\r\\n'\n",
      "           'chat_prompt = ...\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'model = ChatPerplexity(\\r\\n'\n",
      "           '    pplx_api_key=PERPLEXITY_API_KEY,\\r\\n'\n",
      "           '    model=\"llama-3.1-sonar-small-128k-online\",\\r\\n'\n",
      "           '    temperature=0.1,\\r\\n'\n",
      "           '    max_tokens=200,\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'chain = chat_prompt | model\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'response = chain.invoke(...)\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           '[Perplexity Docs Example : '\n",
      "           '](https://docs.perplexity.ai/api-reference/chat-completions)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'import requests\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'url = \"https://api.perplexity.ai/chat/completions\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'payload = {\\r\\n'\n",
      "           '    \"max_tokens\": 100,\\r\\n'\n",
      "           '    \"model\": \"llama-3.1-sonar-small-128k-online\",\\r\\n'\n",
      "           '    \"messages\": [\\r\\n'\n",
      "           '        {\\r\\n'\n",
      "           '            \"content\": \"read me a long fairy tale\",\\r\\n'\n",
      "           '            \"role\": \"user\"\\r\\n'\n",
      "           '        }\\r\\n'\n",
      "           '    ]\\r\\n'\n",
      "           '}\\r\\n'\n",
      "           'headers = {\\r\\n'\n",
      "           '    \"Authorization\": ...,\\r\\n'\n",
      "           '    \"Content-Type\": \"application/json\"\\r\\n'\n",
      "           '}\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Langchain’s Current Implementation :\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'https://github.com/langchain-ai/langchain/blob/16918842bf86de1b493229310b0f6fc593d7a686/libs/community/langchain_community/chat_models/perplexity.py#L147-L156\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'https://github.com/langchain-ai/langchain/blob/16918842bf86de1b493229310b0f6fc593d7a686/libs/community/langchain_community/chat_models/perplexity.py#L267-L275\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Suggestion :\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           ' @property \\r\\n'\n",
      "           ' def _default_params(self) -> Dict[str, Any]: \\r\\n'\n",
      "           '     \"\"\"Get the default parameters for calling PerplexityChat '\n",
      "           'API.\"\"\" \\r\\n'\n",
      "           '     return { \\r\\n'\n",
      "           '         \"request_timeout\": self.request_timeout, \\r\\n'\n",
      "           '         \"stream\": self.streaming, \\r\\n'\n",
      "           '         \"temperature\": self.temperature, \\r\\n'\n",
      "           '         **self.model_kwargs, \\r\\n'\n",
      "           '     } \\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           ' @property \\r\\n'\n",
      "           ' def _invocation_params(self) -> Mapping[str, Any]: \\r\\n'\n",
      "           '     \"\"\"Get the parameters used to invoke the model.\"\"\" \\r\\n'\n",
      "           '     pplx_creds: Dict[str, Any] = { \\r\\n'\n",
      "           '         \"api_key\": self.pplx_api_key, \\r\\n'\n",
      "           '         \"api_base\": \"https://api.perplexity.ai\", \\r\\n'\n",
      "           '         \"model\": self.model, \\r\\n'\n",
      "           '         \"max_tokens\": self.max_tokens,\\r\\n'\n",
      "           '     } \\r\\n'\n",
      "           '     return {**pplx_creds, **self._default_params} \\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           'System Information\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> OS:  Darwin\\r\\n'\n",
      "           '> OS Version:  Darwin Kernel Version 24.1.0: Thu Oct 10 22:08:48 '\n",
      "           'PDT 2024; root:xnu-11215.41.3~5/RELEASE_ARM64_T6000\\r\\n'\n",
      "           '> Python Version:  3.10.14 (main, Mar 19 2024, 21:46:16) [Clang '\n",
      "           '15.0.0 (clang-1500.3.9.4)]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Package Information\\r\\n'\n",
      "           '-------------------\\r\\n'\n",
      "           '> langchain_core: 0.3.17\\r\\n'\n",
      "           '> langchain: 0.2.15\\r\\n'\n",
      "           '> langchain_community: 0.2.14\\r\\n'\n",
      "           '> langsmith: 0.1.128\\r\\n'\n",
      "           '> langchain_anthropic: 0.3.0\\r\\n'\n",
      "           '> langchain_experimental: 0.0.57\\r\\n'\n",
      "           '> langchain_google_genai: 2.0.4\\r\\n'\n",
      "           '> langchain_google_vertexai: 1.0.4\\r\\n'\n",
      "           '> langchain_mongodb: 0.2.0\\r\\n'\n",
      "           '> langchain_openai: 0.0.5\\r\\n'\n",
      "           '> langchain_text_splitters: 0.2.2\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Optional packages not installed\\r\\n'\n",
      "           '-------------------------------\\r\\n'\n",
      "           '> langgraph\\r\\n'\n",
      "           '> langserve\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Other Dependencies\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> aiohttp: 3.9.3\\r\\n'\n",
      "           '> anthropic: 0.39.0\\r\\n'\n",
      "           '> anthropic[vertexai]: Installed. No version info available.\\r\\n'\n",
      "           '> async-timeout: 4.0.3\\r\\n'\n",
      "           '> dataclasses-json: 0.6.7\\r\\n'\n",
      "           '> defusedxml: 0.7.1\\r\\n'\n",
      "           '> faker: Installed. No version info available.\\r\\n'\n",
      "           '> google-cloud-aiplatform: 1.51.0\\r\\n'\n",
      "           '> google-cloud-storage: 2.16.0\\r\\n'\n",
      "           '> google-generativeai: 0.8.3\\r\\n'\n",
      "           '> httpx: 0.27.2\\r\\n'\n",
      "           '> jinja2: 3.1.2\\r\\n'\n",
      "           '> jsonpatch: 1.33\\r\\n'\n",
      "           '> numpy: 1.23.1\\r\\n'\n",
      "           '> openai: 1.10.0\\r\\n'\n",
      "           '> orjson: 3.10.2\\r\\n'\n",
      "           '> packaging: 23.2\\r\\n'\n",
      "           '> pandas: 2.2.0\\r\\n'\n",
      "           '> pillow: 10.1.0\\r\\n'\n",
      "           '> presidio-analyzer: Installed. No version info available.\\r\\n'\n",
      "           '> presidio-anonymizer: Installed. No version info available.\\r\\n'\n",
      "           '> pydantic: 2.9.2\\r\\n'\n",
      "           '> pymongo: 4.8.0\\r\\n'\n",
      "           '> PyYAML: 6.0.1\\r\\n'\n",
      "           '> requests: 2.31.0\\r\\n'\n",
      "           '> sentence-transformers: Installed. No version info available.\\r\\n'\n",
      "           '> SQLAlchemy: 2.0.25\\r\\n'\n",
      "           '> tabulate: 0.9.0\\r\\n'\n",
      "           '> tenacity: 8.2.3\\r\\n'\n",
      "           '> tiktoken: 0.5.2\\r\\n'\n",
      "           '> typing-extensions: 4.9.0\\r\\n'\n",
      "           '> vowpal-wabbit-next: Installed. No version info available.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T08:21:54Z',\n",
      "  '_issueNumber': '28229',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': '`max_tokens` param not work in ChatPerplexity model',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           'Snippet\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'from langchain.chat_models import init_chat_model\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'llm = init_chat_model(\\r\\n'\n",
      "           '    model=\"microsoft/Phi-3-mini-4k-instruct\",\\r\\n'\n",
      "           '    model_provider=\"huggingface\",\\r\\n'\n",
      "           '    temperature=0,\\r\\n'\n",
      "           '    max_tokens=1024,\\r\\n'\n",
      "           '    timeout=None,\\r\\n'\n",
      "           '    max_retries=2,\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '```bash\\r\\n'\n",
      "           'Traceback (most recent call last):\\r\\n'\n",
      "           '  File \"/Users/sauravmaheshkar/dev/papersai/mre.py\", line 4, in '\n",
      "           '<module>\\r\\n'\n",
      "           '    llm = init_chat_model(\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/sauravmaheshkar/dev/papersai/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py\", '\n",
      "           'line 304, in init_chat_model\\r\\n'\n",
      "           '    return _init_chat_model_helper(\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/sauravmaheshkar/dev/papersai/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py\", '\n",
      "           'line 393, in _init_chat_model_helper\\r\\n'\n",
      "           '    return ChatHuggingFace(model_id=model, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/sauravmaheshkar/dev/papersai/.venv/lib/python3.10/site-packages/langchain_huggingface/chat_models/huggingface.py\", '\n",
      "           'line 317, in __init__\\r\\n'\n",
      "           '    super().__init__(**kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/sauravmaheshkar/dev/papersai/.venv/lib/python3.10/site-packages/langchain_core/load/serializable.py\", '\n",
      "           'line 125, in __init__\\r\\n'\n",
      "           '    super().__init__(*args, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/sauravmaheshkar/dev/papersai/.venv/lib/python3.10/site-packages/pydantic/main.py\", '\n",
      "           'line 212, in __init__\\r\\n'\n",
      "           '    validated_self = '\n",
      "           'self.__pydantic_validator__.validate_python(data, '\n",
      "           'self_instance=self)\\r\\n'\n",
      "           'pydantic_core._pydantic_core.ValidationError: 1 validation error '\n",
      "           'for ChatHuggingFace\\r\\n'\n",
      "           'llm\\r\\n'\n",
      "           \"  Field required [type=missing, input_value={'model_id': \"\n",
      "           \"'microsoft/P... None, 'max_retries': 2}, input_type=dict]\\r\\n\"\n",
      "           '    For further information visit '\n",
      "           'https://errors.pydantic.dev/2.9/v/missing\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           \"* I'm trying to use the \"\n",
      "           '[`init_chat_model`](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html) '\n",
      "           'function to instantiate a model from the huggingface hub.\\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           'System Information\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> OS:  Darwin\\r\\n'\n",
      "           '> OS Version:  Darwin Kernel Version 24.0.0: Tue Sep 24 23:36:26 '\n",
      "           'PDT 2024; root:xnu-11215.1.12~1/RELEASE_ARM64_T8103\\r\\n'\n",
      "           '> Python Version:  3.10.15 (main, Sep  9 2024, 22:43:48) [Clang '\n",
      "           '18.1.8 ]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Package Information\\r\\n'\n",
      "           '-------------------\\r\\n'\n",
      "           '> langchain_core: 0.3.19\\r\\n'\n",
      "           '> langchain: 0.3.7\\r\\n'\n",
      "           '> langsmith: 0.1.143\\r\\n'\n",
      "           '> langchain_anthropic: 0.2.3\\r\\n'\n",
      "           '> langchain_huggingface: 0.1.2\\r\\n'\n",
      "           '> langchain_text_splitters: 0.3.2\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Optional packages not installed\\r\\n'\n",
      "           '-------------------------------\\r\\n'\n",
      "           '> langgraph\\r\\n'\n",
      "           '> langserve\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Other Dependencies\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> aiohttp: 3.11.6\\r\\n'\n",
      "           '> anthropic: 0.36.2\\r\\n'\n",
      "           '> async-timeout: 4.0.3\\r\\n'\n",
      "           '> defusedxml: 0.7.1\\r\\n'\n",
      "           '> httpx: 0.27.2\\r\\n'\n",
      "           '> huggingface-hub: 0.26.2\\r\\n'\n",
      "           '> jsonpatch: 1.33\\r\\n'\n",
      "           '> numpy: 1.26.4\\r\\n'\n",
      "           '> orjson: 3.10.11\\r\\n'\n",
      "           '> packaging: 24.2\\r\\n'\n",
      "           '> pydantic: 2.9.2\\r\\n'\n",
      "           '> PyYAML: 6.0.2\\r\\n'\n",
      "           '> requests: 2.32.3\\r\\n'\n",
      "           '> requests-toolbelt: 1.0.0\\r\\n'\n",
      "           '> sentence-transformers: 3.3.1\\r\\n'\n",
      "           '> SQLAlchemy: 2.0.36\\r\\n'\n",
      "           '> tenacity: 9.0.0\\r\\n'\n",
      "           '> tokenizers: 0.20.3\\r\\n'\n",
      "           '> transformers: 4.46.3\\r\\n'\n",
      "           '> typing-extensions: 4.12.2',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T03:01:49Z',\n",
      "  '_issueNumber': '28226',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': \"bug: `init_chat_model` doesn't work with 🤗 huggingface models\",\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Description\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This PR addresses the following:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Fixes Issue #25343:**\\r\\n'\n",
      "           '- Adds additional logic to parse shallowly nested JSON-encoded '\n",
      "           'strings in tool call arguments, allowing for proper parsing of '\n",
      "           'responses like that of Llama3.1 and 3.2 with nested schemas.\\r\\n'\n",
      "           ' \\r\\n'\n",
      "           '**Adds Integration Test for Fix:**\\r\\n'\n",
      "           '- Adds a Ollama specific integration test to ensure the issue is '\n",
      "           'resolved and to prevent regressions in the future.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Fixes Failing Integration Tests:**\\r\\n'\n",
      "           '- Fixes failing integration tests (even prior to changes) caused '\n",
      "           'by `llama3-groq-tool-use` model. Previously, '\n",
      "           'tests`test_structured_output_async` and '\n",
      "           '`test_structured_output_optional_param` failed due to the model '\n",
      "           'not issuing a tool call in the response. Resolved by switching to '\n",
      "           '`llama3.1`.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Issue\\r\\n'\n",
      "           'Fixes #25343.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Dependencies\\r\\n'\n",
      "           'No dependencies.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '____\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Done in collaboration with @ishaan-upadhyay @mirajismail '\n",
      "           '@ZackSteine.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T02:18:55Z',\n",
      "  '_issueNumber': '28225',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'partners/ollama: fix tool calling with nested schemas',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T17:23:12Z',\n",
      "  '_issueNumber': '28219',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'docs: update tutorials',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```\\r\\n'\n",
      "           'from langchain_community.chat_models.azureml_endpoint import '\n",
      "           'AzureMLChatOnlineEndpoint\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'llm = AzureMLChatOnlineEndpoint(#AzureMLOnlineEndpoint(\\r\\n'\n",
      "           '    endpoint_url=\"https://your-endpoint\",\\r\\n'\n",
      "           '    endpoint_api_type=AzureMLEndpointApiType.dedicated,\\r\\n'\n",
      "           '    endpoint_api_key=\"\",\\r\\n'\n",
      "           '    model_kwargs={\"temperature\": 0.3, \"max_new_tokens\": 400},\\r\\n'\n",
      "           '        content_formatter=CustomOpenAIChatContentFormatter(),\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           'llm_with_tools = llm.bind_tools(tools)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '---------------------------------------------------------------------------\\r\\n'\n",
      "           'NotImplementedError                       Traceback (most recent '\n",
      "           'call last)\\r\\n'\n",
      "           'Cell In[17], line 1\\r\\n'\n",
      "           '----> 1 llm_with_tools = llm.bind_tools(tools)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'File '\n",
      "           '[~\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\llm\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\chat_models.py:1115]\\r\\n'\n",
      "           '/anaconda3/envs/llm/Lib/site-packages/langchain_core/language_models/chat_models.py#line=1114), '\n",
      "           'in BaseChatModel.bind_tools(self, tools, **kwargs)\\r\\n'\n",
      "           '   1108 def bind_tools(\\r\\n'\n",
      "           '   1109     self,\\r\\n'\n",
      "           '   1110     tools: Sequence[\\r\\n'\n",
      "           '   (...)\\r\\n'\n",
      "           '   1113     **kwargs: Any,\\r\\n'\n",
      "           '   1114 ) -> Runnable[LanguageModelInput, BaseMessage]:\\r\\n'\n",
      "           '-> 1115     raise NotImplementedError\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'NotImplementedError:\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           'The function should support bind_tool since it is a chat model but '\n",
      "           'got the error as above.\\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           'Name: langchain-core\\r\\n'\n",
      "           'Version: 0.3.19\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Name: langchain\\r\\n'\n",
      "           'Version: 0.3.7',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T09:31:06Z',\n",
      "  '_issueNumber': '28214',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'bind_tools function fails with AzureMLChatOnlineEndpoint',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- **Description:** The multimodal(tongyi) response format '\n",
      "           '\"message\": {\"role\": \"assistant\", \"content\": [{\"text\": \"图像\"}]}}]} '\n",
      "           'is not compatible with LangChain.\\r\\n'\n",
      "           '- **Dependencies:** No',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T07:52:13Z',\n",
      "  '_issueNumber': '28212',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'community: tongyi multimodal response format fix to support '\n",
      "            'langchain',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Description\\r\\n'\n",
      "           'We are submitting as a team of four for a project. Other team '\n",
      "           'members are @RuofanChen03, @LikeWang10067, @TANYAL77.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This pull requests expands the filtering capabilities of the FAISS '\n",
      "           'vectorstore by adding MongoDB-style query operators indicated as '\n",
      "           'follows, while including comprehensive testing for the added '\n",
      "           'functionality.\\r\\n'\n",
      "           '- $eq (equals)\\r\\n'\n",
      "           '- $neq (not equals)\\r\\n'\n",
      "           '- $gt (greater than)\\r\\n'\n",
      "           '- $lt (less than)\\r\\n'\n",
      "           '- $gte (greater than or equal)\\r\\n'\n",
      "           '- $lte (less than or equal)\\r\\n'\n",
      "           '- $in (membership in list)\\r\\n'\n",
      "           '- $nin (not in list)\\r\\n'\n",
      "           '- $and (all conditions must match)\\r\\n'\n",
      "           '- $or (any condition must match)\\r\\n'\n",
      "           '- $not (negation of condition)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Issue\\r\\n'\n",
      "           'This closes '\n",
      "           'https://github.com/langchain-ai/langchain/issues/26379.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Sample Usage\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'import faiss\\r\\n'\n",
      "           'import asyncio\\r\\n'\n",
      "           'from langchain_community.vectorstores import FAISS\\r\\n'\n",
      "           'from langchain.schema import Document\\r\\n'\n",
      "           'from langchain_huggingface import HuggingFaceEmbeddings\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'embeddings = '\n",
      "           'HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\\r\\n'\n",
      "           'documents = [\\r\\n'\n",
      "           '    Document(page_content=\"Process customer refund request\", '\n",
      "           'metadata={\"schema_type\": \"financial\", \"handler_type\": '\n",
      "           '\"refund\",}),\\r\\n'\n",
      "           '    Document(page_content=\"Update customer shipping address\", '\n",
      "           'metadata={\"schema_type\": \"customer\", \"handler_type\": '\n",
      "           '\"update\",}),\\r\\n'\n",
      "           '    Document(page_content=\"Process payment transaction\", '\n",
      "           'metadata={\"schema_type\": \"financial\", \"handler_type\": '\n",
      "           '\"payment\",}),\\r\\n'\n",
      "           '    Document(page_content=\"Handle customer complaint\", '\n",
      "           'metadata={\"schema_type\": \"customer\",\"handler_type\": '\n",
      "           '\"complaint\",}),\\r\\n'\n",
      "           '    Document(page_content=\"Process invoice payment\", '\n",
      "           'metadata={\"schema_type\": \"financial\",\"handler_type\": '\n",
      "           '\"payment\",})\\r\\n'\n",
      "           ']\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'async def search(vectorstore, query, schema_type, handler_type, '\n",
      "           'k=2):\\r\\n'\n",
      "           '    schema_filter = {\"schema_type\": {\"$eq\": schema_type}}\\r\\n'\n",
      "           '    handler_filter = {\"handler_type\": {\"$eq\": handler_type}}\\r\\n'\n",
      "           '    combined_filter = {\\r\\n'\n",
      "           '        \"$and\": [\\r\\n'\n",
      "           '            schema_filter,\\r\\n'\n",
      "           '            handler_filter,\\r\\n'\n",
      "           '        ]\\r\\n'\n",
      "           '    }\\r\\n'\n",
      "           '    base_retriever = vectorstore.as_retriever(\\r\\n'\n",
      "           '        search_kwargs={\"k\":k, \"filter\":combined_filter}\\r\\n'\n",
      "           '    )\\r\\n'\n",
      "           '    return await base_retriever.ainvoke(query)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'async def main():\\r\\n'\n",
      "           '    vectorstore = FAISS.from_texts(\\r\\n'\n",
      "           '        texts=[doc.page_content for doc in documents],\\r\\n'\n",
      "           '        embedding=embeddings,\\r\\n'\n",
      "           '        metadatas=[doc.metadata for doc in documents]\\r\\n'\n",
      "           '    )\\r\\n'\n",
      "           '    \\r\\n'\n",
      "           '    def printt(title, documents):\\r\\n'\n",
      "           '        print(title)\\r\\n'\n",
      "           '        if not documents:\\r\\n'\n",
      "           '            print(\"\\\\tNo documents found.\")\\r\\n'\n",
      "           '            return\\r\\n'\n",
      "           '        for doc in documents:\\r\\n'\n",
      "           '            print(f\"\\\\t{doc.page_content}. {doc.metadata}\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    printt(\"Documents:\", documents)\\r\\n'\n",
      "           '    printt(\\'\\\\nquery=\"process payment\", schema_type=\"financial\", '\n",
      "           'handler_type=\"payment\":\\', await search(vectorstore, '\n",
      "           'query=\"process payment\", schema_type=\"financial\", '\n",
      "           'handler_type=\"payment\", k=2))\\r\\n'\n",
      "           '    printt(\\'\\\\nquery=\"customer update\", schema_type=\"customer\", '\n",
      "           'handler_type=\"update\":\\', await search(vectorstore, '\n",
      "           'query=\"customer update\", schema_type=\"customer\", '\n",
      "           'handler_type=\"update\", k=2))\\r\\n'\n",
      "           '    printt(\\'\\\\nquery=\"refund process\", schema_type=\"financial\", '\n",
      "           'handler_type=\"refund\":\\', await search(vectorstore, query=\"refund '\n",
      "           'process\", schema_type=\"financial\", handler_type=\"refund\", k=2))\\r\\n'\n",
      "           '    printt(\\'\\\\nquery=\"refund process\", schema_type=\"financial\", '\n",
      "           'handler_type=\"foobar\":\\', await search(vectorstore, query=\"refund '\n",
      "           'process\", schema_type=\"financial\", handler_type=\"foobar\", k=2))\\r\\n'\n",
      "           '    print()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'if __name__ == \"__main__\":asyncio.run(main())\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Output\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'Documents:\\r\\n'\n",
      "           \"\\tProcess customer refund request. {'schema_type': 'financial', \"\n",
      "           \"'handler_type': 'refund'}\\r\\n\"\n",
      "           \"\\tUpdate customer shipping address. {'schema_type': 'customer', \"\n",
      "           \"'handler_type': 'update'}\\r\\n\"\n",
      "           \"\\tProcess payment transaction. {'schema_type': 'financial', \"\n",
      "           \"'handler_type': 'payment'}\\r\\n\"\n",
      "           \"\\tHandle customer complaint. {'schema_type': 'customer', \"\n",
      "           \"'handler_type': 'complaint'}\\r\\n\"\n",
      "           \"\\tProcess invoice payment. {'schema_type': 'financial', \"\n",
      "           \"'handler_type': 'payment'}\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           'query=\"process payment\", schema_type=\"financial\", '\n",
      "           'handler_type=\"payment\":\\r\\n'\n",
      "           \"\\tProcess payment transaction. {'schema_type': 'financial', \"\n",
      "           \"'handler_type': 'payment'}\\r\\n\"\n",
      "           \"\\tProcess invoice payment. {'schema_type': 'financial', \"\n",
      "           \"'handler_type': 'payment'}\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           'query=\"customer update\", schema_type=\"customer\", '\n",
      "           'handler_type=\"update\":\\r\\n'\n",
      "           \"\\tUpdate customer shipping address. {'schema_type': 'customer', \"\n",
      "           \"'handler_type': 'update'}\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           'query=\"refund process\", schema_type=\"financial\", '\n",
      "           'handler_type=\"refund\":\\r\\n'\n",
      "           \"\\tProcess customer refund request. {'schema_type': 'financial', \"\n",
      "           \"'handler_type': 'refund'}\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           'query=\"refund process\", schema_type=\"financial\", '\n",
      "           'handler_type=\"foobar\":\\r\\n'\n",
      "           '\\tNo documents found.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T06:53:04Z',\n",
      "  '_issueNumber': '28207',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Community: FAISS Filter Function Enhancement with Advanced Query '\n",
      "            'Operators',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- [x] **PR title**: \"community: add LindormVector to vectorstores; '\n",
      "           'add Lindorm chat/embeeding/rerank\"\\r\\n'\n",
      "           '- [x] **PR message**:\\r\\n'\n",
      "           '    - **Description:** Lindorm is a multi-model cloud-native '\n",
      "           'database, supporting full-text search, vector-search. It also has '\n",
      "           'AI engine , which could be used to import model or pre-train model '\n",
      "           'inside Lindorm database.\\r\\n'\n",
      "           '   \\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x] **Add tests and docs**:\\r\\n'\n",
      "           '  1. a test for the integration, preferably unit tests that do not '\n",
      "           'rely on network access,\\r\\n'\n",
      "           '  2. an example notebook showing its use. It lives in '\n",
      "           '`docs/docs/integrations` directory.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x] **Lint and test**: Run `make format`, `make lint` and `make '\n",
      "           \"test` from the root of the package(s) you've modified. See \"\n",
      "           'contribution guidelines for more: '\n",
      "           'https://python.langchain.com/docs/contributing/\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T06:44:41Z',\n",
      "  '_issueNumber': '28206',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'community: add LindormVector to vectorstores; also add Lindorm '\n",
      "            'chat/embedding/rerank to '\n",
      "            'chat_model/embedding/document_compressors',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '\\r\\n'\n",
      "           '- **Description:** Invalid `tool_choice` is given to `ChatLiteLLM` '\n",
      "           \"to `bind_tools` due to it's parent's class default value being \"\n",
      "           'pass through `with_structured_output`.\\r\\n'\n",
      "           '- **Issue:** #28176\\r\\n'\n",
      "           '\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T00:14:27Z',\n",
      "  '_issueNumber': '28198',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Invalid `tool_choice` being passed to `ChatLiteLLM`',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '# Description\\r\\n'\n",
      "           'This submission is a part of a school project from our team of 4 '\n",
      "           '@EminGul @williamzhu54 @annay54 @donttouch22.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Our pull request fixes the issue with RunnableParallel scheme '\n",
      "           'being empty by returning the correct schema output when children '\n",
      "           'runnable input schemas use TypedDicts.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Issue\\r\\n'\n",
      "           'This submission fixes the issue: [#24326 '\n",
      "           '](https://github.com/langchain-ai/langchain/issues/24326).\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Dependencies\\r\\n'\n",
      "           'No extra dependencies required for this fix.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Feedback\\r\\n'\n",
      "           'Any feedback and advice is gladly welcomed. Please feel free to '\n",
      "           'let us know what we can change or improve upon regarding this '\n",
      "           'issue.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T22:07:50Z',\n",
      "  '_issueNumber': '28196',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'core: fix issue with runnable parallel schema being empty when '\n",
      "            \"children runnable input schemas use TypedDict's\",\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Update all Poetry versions to the current latest, 1.8.4 .\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I was checking how lock files are managed and found out that even '\n",
      "           'though the files are generated - updated with the current latest '\n",
      "           'version of Poetry, the version used in CI and Dockerfile was '\n",
      "           'outdated.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '* '\n",
      "           'https://github.com/langchain-ai/langchain/pull/28061/files#diff-e00422d37a73d07c174e7838ad7c30f642d06305aff8f9d71e1e84c6897efbffL1\\r\\n'\n",
      "           '* '\n",
      "           'https://github.com/langchain-ai/langchain/pull/28070/files#diff-55267c883e58892916d5316bc029725fdeeba5a77e2557cf7667793823d9d9c6L1\\r\\n'\n",
      "           '* '\n",
      "           'https://github.com/langchain-ai/langchain/pull/27991/files#diff-9f96b8fd39133c3f1d737e013c9042b065b42ae04b3da76902304f30cec136d8R1\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- If no one reviews your PR within a few days, please @-mention '\n",
      "           'one of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17. '\n",
      "           '-->\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T21:02:45Z',\n",
      "  '_issueNumber': '28194',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Update Poetry version, to current latest (1.8.4)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Follows on from #27991, updates the langchain-community package to '\n",
      "           'support numpy 2 versions',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T15:55:54Z',\n",
      "  '_issueNumber': '28184',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'community[patch]: support numpy2',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Follows on from #27991, updates the langchain package to support '\n",
      "           'numpy 2 versions',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T15:53:30Z',\n",
      "  '_issueNumber': '28183',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': 'langchain[patch]: support numpy 2',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the LangChain documentation with the integrated '\n",
      "           'search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "           'code.\\n'\n",
      "           '- [X] The bug is not resolved by updating to the latest stable '\n",
      "           'version of LangChain (or the specific integration package).\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           ' code：\\r\\n'\n",
      "           'from langchain_core.prompts import PromptTemplate\\r\\n'\n",
      "           'from langchain_openai import ChatOpenAI\\r\\n'\n",
      "           'from langchain.schema import HumanMessage\\r\\n'\n",
      "           'import os\\r\\n'\n",
      "           'from langchain_experimental.graph_transformers import '\n",
      "           'LLMGraphTransformer\\r\\n'\n",
      "           'from langchain_core.documents import Document\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from langchain_community.graphs import Neo4jGraph\\r\\n'\n",
      "           '# 初始化模型\\r\\n'\n",
      "           'llm = ChatOpenAI(\\r\\n'\n",
      "           '    streaming=True,\\r\\n'\n",
      "           '    verbose=True,\\r\\n'\n",
      "           '    openai_api_key=\"none\",  # 根据实际情况配置\\r\\n'\n",
      "           '    openai_api_base=\"http://192.168.3.188:8080/v1\",  # 根据实际情况配置\\r\\n'\n",
      "           '    model_name=\"glm-4-9b-chat\",\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           'os.environ[\"NEO4J_URI\"] = \"bolt://192.168.3.188:7687\"\\r\\n'\n",
      "           'os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\\r\\n'\n",
      "           'os.environ[\"NEO4J_PASSWORD\"] = \"123456\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'graph = Neo4jGraph()\\r\\n'\n",
      "           'llm_transformer = LLMGraphTransformer(llm=llm)\\r\\n'\n",
      "           'from langchain_core.documents import Document\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'text = \"\"\"\\r\\n'\n",
      "           'Marie Curie, born in 1867, was a Polish and naturalised-French '\n",
      "           'physicist and chemist who conducted pioneering research on '\n",
      "           'radioactivity.\\r\\n'\n",
      "           'She was the first woman to win a Nobel Prize, the first person to '\n",
      "           'win a Nobel Prize twice, and the only person to win a Nobel Prize '\n",
      "           'in two scientific fields.\\r\\n'\n",
      "           'Her husband, Pierre Curie, was a co-winner of her first Nobel '\n",
      "           'Prize, making them the first-ever married couple to win the Nobel '\n",
      "           'Prize and launching the Curie family legacy of five Nobel '\n",
      "           'Prizes.\\r\\n'\n",
      "           'She was, in 1906, the first woman to become a professor at the '\n",
      "           'University of Paris.\\r\\n'\n",
      "           '\"\"\"\\r\\n'\n",
      "           'documents = [Document(page_content=text)]\\r\\n'\n",
      "           'graph_documents = '\n",
      "           'llm_transformer.convert_to_graph_documents(documents)\\r\\n'\n",
      "           'print(f\"Nodes:{graph_documents[0].nodes}\")\\r\\n'\n",
      "           'print(f\"Relationships:{graph_documents[0].relationships}\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'response：\\r\\n'\n",
      "           'Nodes:[]\\r\\n'\n",
      "           'Relationships:[]\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '1\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           'help me！ According to the official example, when creating a '\n",
      "           'knowledge graph using the local large model glm-4-9b-chat, the '\n",
      "           'generated nodes and relationships in the graph are empty.\\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           '11',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T13:43:52Z',\n",
      "  '_issueNumber': '28182',\n",
      "  '_repo': 'langchain',\n",
      "  '_state': 'open',\n",
      "  '_title': ' According to the official example, when creating a knowledge '\n",
      "            'graph using the local large model glm-4-9b-chat, the generated '\n",
      "            'nodes and relationships in the graph are empty.',\n",
      "  '_type': 'issue'}]\n",
      "Fetching issues from: https://api.github.com/repos/langchain-ai/langgraph/issues\n",
      "[{'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T02:19:13Z',\n",
      "  '_issueNumber': '2507',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': '[CLI] [Unit-test] Update the expected exception when a file does '\n",
      "            'not exist',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the '\n",
      "           '[LangGraph](https://langchain-ai.github.io/langgraph/)/LangChain '\n",
      "           'documentation with the integrated search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangGraph/LangChain rather '\n",
      "           'than my code.\\n'\n",
      "           '- [X] I am sure this is better as an issue [rather than a GitHub '\n",
      "           'discussion](https://github.com/langchain-ai/langgraph/discussions/new/choose), '\n",
      "           'since this is a LangGraph bug and not a design question.\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```python\\n'\n",
      "           'from operator import add\\r\\n'\n",
      "           'from typing import TypedDict, Annotated\\r\\n'\n",
      "           'from langgraph.graph import StateGraph, START, END\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class PersonState(TypedDict):\\r\\n'\n",
      "           '    name: str\\r\\n'\n",
      "           '    money: Annotated[int, add]\\r\\n'\n",
      "           '    \\r\\n'\n",
      "           'class PurchasesState(TypedDict):\\r\\n'\n",
      "           '    purchases: Annotated[list[str], add]\\r\\n'\n",
      "           '    total_cost: Annotated[int, add]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class OverallState(PersonState, PurchasesState):\\r\\n'\n",
      "           '    pass\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# node_1 operation. \\r\\n'\n",
      "           'def pay_salary(state: PersonState) -> OverallState:\\r\\n'\n",
      "           '    print(f\"Node 1: {state}\")\\r\\n'\n",
      "           '    return {\"money\": 1000}\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# node_2 operation. \\r\\n'\n",
      "           'def subtract_expenses(state: PurchasesState) -> OverallState:\\r\\n'\n",
      "           '    print(f\"Node 2: {state}\")\\r\\n'\n",
      "           '    return {\\'money\\': -100, \"purchases\": [\"new iphone\"], '\n",
      "           \"'total_cost': 100}\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '# node_3 operation. \\r\\n'\n",
      "           'def add_assistance(state: OverallState) -> OverallState:\\r\\n'\n",
      "           '    print(f\"Node 3: {state}\")\\r\\n'\n",
      "           '    return {\"money\": 100}\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Routing Function. \\r\\n'\n",
      "           'def check_if_poor(state: OverallState):\\r\\n'\n",
      "           '    print(f\"Routing function: {state}\")\\r\\n'\n",
      "           '    # if poor, add asssitance\\r\\n'\n",
      "           '    if (state[\\'money\\'] < 100): return \"node_3\"\\r\\n'\n",
      "           '    else: return END\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'graph = StateGraph(OverallState, input = PersonState)\\r\\n'\n",
      "           \"graph.add_edge(START, 'node_1')\\r\\n\"\n",
      "           \"graph.add_node('node_1', pay_salary)\\r\\n\"\n",
      "           \"graph.add_edge('node_1', 'node_2')\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           \"graph.add_node('node_2', subtract_expenses)\\r\\n\"\n",
      "           \"graph.add_conditional_edges('node_2', check_if_poor)\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           \"graph.add_node('node_3', add_assistance)\\r\\n\"\n",
      "           'graph.add_edge(\"node_3\", END)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'workflow = graph.compile()\\r\\n'\n",
      "           'output_dict = workflow.invoke({\"name\": \"Ahmed\"})\\r\\n'\n",
      "           'print(f\"Final output: {output_dict}\")\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '```shell\\n'\n",
      "           '(No exception, but inaccurate console output)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'CONSOLE OUTPUT:\\r\\n'\n",
      "           \"Node 1: {'name': 'Ahmed', 'money': 0}\\r\\n\"\n",
      "           \"Node 2: {'purchases': [], 'total_cost': 0}\\r\\n\"\n",
      "           \"Routing function: {'money': -100, 'purchases': ['new iphone'], \"\n",
      "           \"'total_cost': 100}\\r\\n\"\n",
      "           \"Node 3: {'name': 'Ahmed', 'money': 900, 'purchases': ['new \"\n",
      "           \"iphone'], 'total_cost': 100}\\r\\n\"\n",
      "           \"Final output: {'name': 'Ahmed', 'money': 1000, 'purchases': ['new \"\n",
      "           \"iphone'], 'total_cost': 100}\\n\"\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           '(Derived from Discussion Post #2197 , please see discussion post '\n",
      "           'for detailed description)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## The Console Output line that is inaccurate:\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           \"Routing function: {'money': -100, 'purchases': ['new iphone'], \"\n",
      "           \"'total_cost': 100}\\r\\n\"\n",
      "           '```\\r\\n'\n",
      "           'How does `money` have a value of -100? In the method `pay_salary`, '\n",
      "           'the `money` attribute is set to 1000. Then, in the '\n",
      "           '`subtract_expenses` method, I subtract 100 from it. So, the '\n",
      "           '`money` attribute should have a value of 900, not -100.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## The line that is causing the weird output (after debugging)\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'def subtract_expenses(state: PurchasesState) -> OverallState:\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## How is it causing the issue?\\r\\n'\n",
      "           'When I change the inputted state from `PurchasesState` to '\n",
      "           '`OverallState`, it works as expected, i.e. the output printed in '\n",
      "           'the routing function `check_if_poor` is: \\r\\n'\n",
      "           '```\\r\\n'\n",
      "           \"Routing function: {'money': 900, 'purchases': ['new iphone'], \"\n",
      "           \"'total_cost': 100, 'name': 'Ahmed'}\\r\\n\"\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"## What's my question?\\r\\n\"\n",
      "           'Why does changing the type of the inputted state in the function '\n",
      "           '`subtract_expenses` lead me to receive different values for the '\n",
      "           '`money` attribute in the routing function `check_if_poor`?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Thanks in advance!\\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           'System Information\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> OS:  Windows\\r\\n'\n",
      "           '> OS Version:  10.0.19045\\r\\n'\n",
      "           '> Python Version:  3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, '\n",
      "           '20:11:23) [MSC v.1940 64 bit (AMD64)]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Package Information\\r\\n'\n",
      "           '-------------------\\r\\n'\n",
      "           '> langchain_core: 0.3.19\\r\\n'\n",
      "           '> langchain: 0.3.7\\r\\n'\n",
      "           '> langchain_community: 0.3.7\\r\\n'\n",
      "           '> langsmith: 0.1.144\\r\\n'\n",
      "           '> langchain_openai: 0.2.9\\r\\n'\n",
      "           '> langchain_text_splitters: 0.3.2\\r\\n'\n",
      "           '> langgraph: 0.2.53\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Optional packages not installed\\r\\n'\n",
      "           '-------------------------------\\r\\n'\n",
      "           '> langserve\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Other Dependencies\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> aiohttp: 3.11.7\\r\\n'\n",
      "           '> async-timeout: Installed. No version info available.\\r\\n'\n",
      "           '> dataclasses-json: 0.6.7\\r\\n'\n",
      "           '> httpx: 0.27.2\\r\\n'\n",
      "           '> httpx-sse: 0.4.0\\r\\n'\n",
      "           '> jsonpatch: 1.33\\r\\n'\n",
      "           '> langgraph-checkpoint: 2.0.5\\r\\n'\n",
      "           '> langgraph-sdk: 0.1.36\\r\\n'\n",
      "           '> numpy: 1.26.4\\r\\n'\n",
      "           '> openai: 1.55.0\\r\\n'\n",
      "           '> orjson: 3.10.11\\r\\n'\n",
      "           '> packaging: 24.2\\r\\n'\n",
      "           '> pydantic: 2.10.0\\r\\n'\n",
      "           '> pydantic-settings: 2.6.1\\r\\n'\n",
      "           '> PyYAML: 6.0.2\\r\\n'\n",
      "           '> requests: 2.32.3\\r\\n'\n",
      "           '> requests-toolbelt: 1.0.0\\r\\n'\n",
      "           '> SQLAlchemy: 2.0.35\\r\\n'\n",
      "           '> tenacity: 9.0.0\\r\\n'\n",
      "           '> tiktoken: 0.8.0\\r\\n'\n",
      "           '> typing-extensions: 4.12.2',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T23:17:13Z',\n",
      "  '_issueNumber': '2504',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'When Using Multiple States, Changing the Input State of a Node '\n",
      "            'can Affect the State Fields Received by the Routing Function',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T20:50:56Z',\n",
      "  '_issueNumber': '2502',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'langgraph: fix issue w/ type annotations in tools_condition',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T01:35:11Z',\n",
      "  '_issueNumber': '2495',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': '[CLI] Windows testing ',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T00:58:14Z',\n",
      "  '_issueNumber': '2494',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'donotmerge',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This change introduces few building blocks for multi-agent:\\r\\n'\n",
      "           '* `make_agent_node` - a wrapper around `create_react_agent` that '\n",
      "           'returns a graph node function\\r\\n'\n",
      "           '  * allows users to define custom input/output processing '\n",
      "           'functions (handle what information is passed to/from agent as well '\n",
      "           'as handle different state schemas). by default all of the message '\n",
      "           'history is shared by all of the agents via `messages` (each agent '\n",
      "           'receives full message history and and adds its internal history to '\n",
      "           'the full history). TBD if this is the best default\\r\\n'\n",
      "           '  * handles handoff tools that return `GraphCommand.goto` and '\n",
      "           'returns a `GraphCommand.goto` to dynamically route to a different '\n",
      "           'node (agent)\\r\\n'\n",
      "           '  * handles state updates from tools when a tool in subgraph agent '\n",
      "           'wants to update parent state\\r\\n'\n",
      "           '* `AgentRouterState` (TBD on name, would love to improve) -- react '\n",
      "           'agent state + active node (`node`) for routing on follow-up '\n",
      "           'interactions\\r\\n'\n",
      "           '* `add_entrypoint_router` - helper that adds the agent nodes to '\n",
      "           'the `StateGraph` and adds a top-level entrypoint router based on '\n",
      "           'the active node in the state. TBD if this can be replaced with '\n",
      "           'human-in-the-loop\\r\\n'\n",
      "           '* `ToolNode` is now aware of tools returning `GraphCommand` and '\n",
      "           'can apply state updates from `GraphCommand.update`. this allows '\n",
      "           'general support for tools that can update state (only internal to '\n",
      "           'the graph)\\r\\n'\n",
      "           '* `handoff` - a shorthand that helps create tools that return '\n",
      "           '`GraphCommand` with `goto` and `update`\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Basic usage:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'from langgraph.prebuilt.handoff import handoff\\r\\n'\n",
      "           'from langgraph.graph import StateGraph, GraphCommand, START, '\n",
      "           'END\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# define handoff tools\\r\\n'\n",
      "           'bob_tool = handoff(goto=\"bob\", tool_message=\"Transferred to Bob\", '\n",
      "           'name=\"transfer_to_bob\", description=\"Transfer to Bob\")\\r\\n'\n",
      "           'alice_tool = handoff(goto=\"alice\", tool_message=\"Transferred to '\n",
      "           'Alice\", name=\"transfer_to_alice\", description=\"Transfer to '\n",
      "           'Alice\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# define agent nodes\\r\\n'\n",
      "           'alice = make_agent_node(model, [add, bob_tool], '\n",
      "           'state_schema=AgentRouterState, state_modifier=\"You\\'re Alice.\", '\n",
      "           'output_processor=keep_last_message_as_human)\\r\\n'\n",
      "           'bob = make_agent_node(model, [multiply, alice_tool], '\n",
      "           'state_schema=AgentRouterState, state_modifier=\"You\\'re Bob.\", '\n",
      "           'output_processor=keep_last_message_as_human)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# define graph\\r\\n'\n",
      "           'builder = StateGraph(AgentRouterState)\\r\\n'\n",
      "           'add_entrypoint_router(builder, route_to=[(\"alice\", alice), (\"bob\", '\n",
      "           'bob)], default_start_node=\"alice\")\\r\\n'\n",
      "           'memory = MemorySaver()\\r\\n'\n",
      "           'graph = builder.compile(checkpointer=memory)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# pass control between the agents\\r\\n'\n",
      "           'config = {\"configurable\": {\"thread_id\": \"1\"}}\\r\\n'\n",
      "           'for chunk in graph.stream({\"messages\": [(\"user\", \"hi! transfer me '\n",
      "           'to bob\")]}, config):\\r\\n'\n",
      "           '    ...\\r\\n'\n",
      "           'for chunk in graph.stream({\"messages\": [(\"user\", \"back to alice '\n",
      "           'please\")]}, config):\\r\\n'\n",
      "           '    ...\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Here are some usage examples:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '* basic usage examples: '\n",
      "           'https://github.com/langchain-ai/langgraph/blob/vb/prebuilt-agent-components/examples/multi_agent/experimental/simple_multi_agent_examples.ipynb\\r\\n'\n",
      "           '* hierarchical agent tutorial: '\n",
      "           'https://github.com/langchain-ai/langgraph/blob/vb/prebuilt-agent-components/examples/multi_agent/experimental/hierarchical_agent_teams.ipynb\\r\\n'\n",
      "           '* customer support example: '\n",
      "           'https://github.com/langchain-ai/langgraph/blob/vb/prebuilt-agent-components/examples/multi_agent/experimental/customer_support.ipynb',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T02:31:51Z',\n",
      "  '_issueNumber': '2477',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': '[rfc] langgraph: add agent node wrapper and handoff tools',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '🚧 🚧 🚧 \\r\\n'\n",
      "           'I would like some guidance on how to update the tests here - the '\n",
      "           'PostgresSaver does not use mocks and has a check for the type of '\n",
      "           'connection. When I copied this code for the PostgresStore its '\n",
      "           'causing test failures. Adding the mocks as accepted classes does '\n",
      "           'not seem correct.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '-----\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This PR is in reference to '\n",
      "           'https://github.com/langchain-ai/langgraph/discussions/2457\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I went ahead and coded an implementation for accepting '\n",
      "           'ConnectionPool when creating a PostgresStore. I copied the '\n",
      "           'PostgresSaver implementation for guideance.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'One question I have - for the batch code it was trying to execute '\n",
      "           'all cursors and then collect all the results after all cursors '\n",
      "           'have been executed. In order to use the context management block I '\n",
      "           'had to switch the implementation to execute each cursors '\n",
      "           'sequentially. Is this an unacceptable implementation?',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T19:28:52Z',\n",
      "  '_issueNumber': '2475',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Adding connection pool support to the PostgresStore',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'As per:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'https://github.com/langchain-ai/langgraph/discussions/2159\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'and\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'https://langchaincommunity.slack.com/archives/C07ERHD5WCA/p1730470212037069\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Here is a PR with the changes which allow a CompiledGraph to be '\n",
      "           'displayed inline in Jupyter with a bit more ease. Happy to get '\n",
      "           'feedback on this, the contributing.md indicates there is a form '\n",
      "           \"somewhere to fill in when creating PRs, but I don't see where that \"\n",
      "           'is.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T16:26:23Z',\n",
      "  '_issueNumber': '2468',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'feat: Make CompiledGraph displayable in Jupyter with display()',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Fixes #2207 \\r\\n'\n",
      "           'Missing docstring for aupdate_state method\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Description\\r\\n'\n",
      "           'Added proper docstring documentation for the aupdate_state method '\n",
      "           'in the Pregel class. This enables mkdocstrings to properly '\n",
      "           'generate API reference documentation.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Changes\\r\\n'\n",
      "           '- Added Google-style docstring for aupdate_state method\\r\\n'\n",
      "           '- Includes complete description, args, returns, raises sections\\r\\n'\n",
      "           '- Matches style of other async method docstrings\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Testing\\r\\n'\n",
      "           '- No code changes, only documentation\\r\\n'\n",
      "           '- Documentation builds correctly with mkdocs\\r\\n'\n",
      "           '- API reference now shows aupdate_state method documentation',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-16T12:39:19Z',\n",
      "  '_issueNumber': '2435',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'docs: missing docstring for aupdate_state method',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T22:01:29Z',\n",
      "  '_issueNumber': '2430',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'WIP: Handle commands for subgraphs',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- experimental: add handoff tool support\\n'\n",
      "           '- example\\n'\n",
      "           '- update\\n'\n",
      "           '- qxqx\\n'\n",
      "           '- x\\n'\n",
      "           '- qxqx\\n'\n",
      "           '- x\\n'\n",
      "           '- x\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-14T20:05:25Z',\n",
      "  '_issueNumber': '2419',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'testing out routing',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This PR relaxes the assumptions of the _search_where() function of '\n",
      "           'the BasePostgresSaver class such that a thread_id is no longer '\n",
      "           'required. This enables searches like \"Show me all checkpoints with '\n",
      "           'a given user_id in the metadata\", which would have an empty '\n",
      "           'configurable and only rely on filters.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Implements discussion #2396.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-13T20:03:49Z',\n",
      "  '_issueNumber': '2409',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Relax BasePostgresSaver _search_where assumption (implements '\n",
      "            'discussion 2396)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'The PR content was generated automatically using '\n",
      "           '[cover-agent](https://github.com/Codium-ai/cover-agent)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Methodology\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Cover-agent automatically scans a repository to detect existing '\n",
      "           'unit test files. It gathers relevant context for each file, then '\n",
      "           'triggers an AI-based workflow to enhance these tests by adding new '\n",
      "           'cases that increase code coverage and address uncovered '\n",
      "           'behaviors.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Reliability \\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"But it's AI-generated code. How can we know it's reliable ? How \"\n",
      "           \"can we know it's effective ?\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           'Answer:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'All AI-generated tests have met these four essential criteria:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '1. Execute successfully\\r\\n'\n",
      "           '2. Pass all assertions\\r\\n'\n",
      "           '3. Increase overall code coverage\\r\\n'\n",
      "           '4. Test previously uncovered behaviors (as specified in the LLM '\n",
      "           'prompt)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Increased coverage\\r\\n'\n",
      "           'Code coverage comparison  of the relevant source files before and '\n",
      "           'after these changes:\\r\\n'\n",
      "           '<img width=\"1248\" alt=\"image\" '\n",
      "           'src=\"https://github.com/user-attachments/assets/d313c97e-f183-4657-b940-e5da641a054d\">\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'In total, 129 new lines were covered with the tests added in this '\n",
      "           'PR\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Appendix: unit tests - what are they good for?\\r\\n'\n",
      "           '<details><summary>Answer:</summary>\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Personal opinion - writing unit testing is not fun. It becomes '\n",
      "           'even less appealing as your codebase grows and maintaining tests '\n",
      "           'becomes a time-consuming chore.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'However, the benefits of comprehensive unit tests are real: \\r\\n'\n",
      "           '- Reliability: They create a more reliable codebase where '\n",
      "           'developers can make changes confidently\\r\\n'\n",
      "           '- Speed: Teams can move quickly without fear of breaking existing '\n",
      "           'functionality\\r\\n'\n",
      "           '- Safe Refactoring: Code improvements and restructuring become '\n",
      "           'significantly safer when backed by thorough tests\\r\\n'\n",
      "           '- Living Documentation: Tests serve as clear documentation of your '\n",
      "           \"code's behavior:\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '  - They show exactly what happens for each input\\r\\n'\n",
      "           '  - They present changes in a human-readable format: \"for this '\n",
      "           'input → expect this output\"\\r\\n'\n",
      "           '  - They run quickly and are easy to execute\\r\\n'\n",
      "           '  - This immediate feedback loop is beneficial during '\n",
      "           'development\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '</details>',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-13T18:45:31Z',\n",
      "  '_issueNumber': '2408',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Extend existing unit tests using cover-agent',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-11T20:16:20Z',\n",
      "  '_issueNumber': '2390',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'docs: update multi-agent tutorials to use Control',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the '\n",
      "           '[LangGraph](https://langchain-ai.github.io/langgraph/)/LangChain '\n",
      "           'documentation with the integrated search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangGraph/LangChain rather '\n",
      "           'than my code.\\n'\n",
      "           '- [X] I am sure this is better as an issue [rather than a GitHub '\n",
      "           'discussion](https://github.com/langchain-ai/langgraph/discussions/new/choose), '\n",
      "           'since this is a LangGraph bug and not a design question.\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```python\\n'\n",
      "           '# langgraph.json\\r\\n'\n",
      "           '{\\r\\n'\n",
      "           '  \"docker_compose_file\": \"configs/default.docker-compose.yml\",\\r\\n'\n",
      "           '  \"graphs\": {\\r\\n'\n",
      "           '    \"chat_response\": \"./app/graphs/chat_response.py:graph\",\\r\\n'\n",
      "           '  },\\r\\n'\n",
      "           '  \"env\": \".env\",\\r\\n'\n",
      "           '  \"python_version\": \"3.12\",\\r\\n'\n",
      "           '  \"dependencies\": [\".\"]\\r\\n'\n",
      "           '}\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           \"Hey, Apologies if you don't consider this a bug, it's in that grey \"\n",
      "           'area where devex performance issues cause degredation that could '\n",
      "           'be considered either. But sorry if this is in the wrong place!\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"We're encountering an issue when using `langgraph up --watch` with \"\n",
      "           'the above `langgraph.json`.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Essentially the compiled dockerfile lines produced by the CLI in '\n",
      "           '[this '\n",
      "           'region](https://github.com/langchain-ai/langgraph/blob/main/libs/cli/langgraph_cli/config.py#L214-L286) '\n",
      "           'create an uncacheable layer in `faux_pkgs_str`, meaning that the '\n",
      "           \"subsequent `pip install`s can't use the docker build cache. That \"\n",
      "           'then means that if you are repetitively saving, you can easily '\n",
      "           \"balloon the HD space usage dramatically. I've had quite a few \"\n",
      "           \"instances where it's exhausted the 50GB volume assigned to my \"\n",
      "           'docker VM and the postgres sidecar no longer inserts records. I '\n",
      "           'ended up tearing down regularly and using `docker builder prune` '\n",
      "           'about once a day on my development machine, meaning we lost traces '\n",
      "           'etc.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"In our instance, we've resorted to creating a static \"\n",
      "           '`pyproject.toml` file and a static `docker-compose.yml` using what '\n",
      "           'the CLI creates; however this is a potential maintenance headache '\n",
      "           'long-term.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"It appears that the package name isn't used for anything outside \"\n",
      "           \"the install and is the only dynamic content; as such I'd suggest \"\n",
      "           'swapping to a static `pyproject.toml` file that can be added to '\n",
      "           'the container, so that docker can cache it.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Very happy to open a PR if it would help, but wanted to make the '\n",
      "           'observation/issue report first to gather your thoughts!\\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           '❯ python -m langchain_core.sys_info\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'System Information\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> OS:  Darwin\\r\\n'\n",
      "           '> OS Version:  Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:30 '\n",
      "           'PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T6030\\r\\n'\n",
      "           '> Python Version:  3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, '\n",
      "           '08:18:47) [Clang 13.0.0 (clang-1300.0.29.30)]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Package Information\\r\\n'\n",
      "           '-------------------\\r\\n'\n",
      "           '> langchain_core: 0.3.8\\r\\n'\n",
      "           '> langchain: 0.3.1\\r\\n'\n",
      "           '> langchain_community: 0.3.1\\r\\n'\n",
      "           '> langsmith: 0.1.130\\r\\n'\n",
      "           '> langchain_anthropic: 0.2.1\\r\\n'\n",
      "           '> langchain_aws: 0.2.1\\r\\n'\n",
      "           '> langchain_groq: 0.2.0\\r\\n'\n",
      "           '> langchain_openai: 0.2.1\\r\\n'\n",
      "           '> langchain_text_splitters: 0.3.0\\r\\n'\n",
      "           '> langgraph: 0.2.34\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Optional packages not installed\\r\\n'\n",
      "           '-------------------------------\\r\\n'\n",
      "           '> langserve\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Other Dependencies\\r\\n'\n",
      "           '------------------\\r\\n'\n",
      "           '> aiohttp: 3.10.8\\r\\n'\n",
      "           '> anthropic: 0.34.2\\r\\n'\n",
      "           '> async-timeout: Installed. No version info available.\\r\\n'\n",
      "           '> boto3: 1.35.32\\r\\n'\n",
      "           '> dataclasses-json: 0.6.7\\r\\n'\n",
      "           '> defusedxml: 0.7.1\\r\\n'\n",
      "           '> groq: 0.11.0\\r\\n'\n",
      "           '> httpx: 0.27.2\\r\\n'\n",
      "           '> jsonpatch: 1.33\\r\\n'\n",
      "           '> langgraph-checkpoint: 2.0.0\\r\\n'\n",
      "           '> numpy: 1.26.4\\r\\n'\n",
      "           '> openai: 1.51.0\\r\\n'\n",
      "           '> orjson: 3.10.7\\r\\n'\n",
      "           '> packaging: 24.1\\r\\n'\n",
      "           '> pydantic: 2.9.2\\r\\n'\n",
      "           '> pydantic-settings: 2.5.2\\r\\n'\n",
      "           '> PyYAML: 6.0.2\\r\\n'\n",
      "           '> requests: 2.32.3\\r\\n'\n",
      "           '> requests-toolbelt: 1.0.0\\r\\n'\n",
      "           '> SQLAlchemy: 2.0.35\\r\\n'\n",
      "           '> tenacity: 8.5.0\\r\\n'\n",
      "           '> tiktoken: 0.7.0\\r\\n'\n",
      "           '> typing-extensions: 4.12.2',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-11T17:41:24Z',\n",
      "  '_issueNumber': '2387',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Orphaned Docker Layers in CLI with docker-compose',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the '\n",
      "           '[LangGraph](https://langchain-ai.github.io/langgraph/)/LangChain '\n",
      "           'documentation with the integrated search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangGraph/LangChain rather '\n",
      "           'than my code.\\n'\n",
      "           '- [X] I am sure this is better as an issue [rather than a GitHub '\n",
      "           'discussion](https://github.com/langchain-ai/langgraph/discussions/new/choose), '\n",
      "           'since this is a LangGraph bug and not a design question.\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```python\\n'\n",
      "           '############################ Graph flow/src/graph.py\\r\\n'\n",
      "           'from langgraph.prebuilt import ToolNode, tools_condition\\r\\n'\n",
      "           'from langgraph.store.memory import InMemoryStore\\r\\n'\n",
      "           'from langgraph.graph.message import add_messages\\r\\n'\n",
      "           'from langgraph.graph import StateGraph\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from langchain_core.messages import SystemMessage, HumanMessage, '\n",
      "           'ToolMessage, AIMessage\\r\\n'\n",
      "           'from langchain_openai import AzureChatOpenAI\\r\\n'\n",
      "           'from langchain_core.tools import tool\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from typing_extensions import Annotated, TypedDict\\r\\n'\n",
      "           'import random\\r\\n'\n",
      "           'import os\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '############# Graph #############\\r\\n'\n",
      "           'class ConfigSchema(TypedDict):\\r\\n'\n",
      "           '    \"\"\"Define the schema for the config object.\"\"\"\\r\\n'\n",
      "           '    thread_id: str\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class StateSchema(TypedDict):\\r\\n'\n",
      "           '    \"\"\"Define the schema for the state object.\"\"\"\\r\\n'\n",
      "           '    prompt: str\\r\\n'\n",
      "           '    messages: Annotated[list, add_messages] = []\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '############# Tools #############\\r\\n'\n",
      "           '@tool\\r\\n'\n",
      "           'def get_city_population(city:str) -> int:\\r\\n'\n",
      "           '    \"\"\"Get the population of a city\"\"\"\\r\\n'\n",
      "           '    return random.randint(1000, 1000000)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'tools = [get_city_population]\\r\\n'\n",
      "           '############# Nodes #############\\r\\n'\n",
      "           'class Agent():\\r\\n'\n",
      "           '    name: str = \"Agent\"\\r\\n'\n",
      "           '    agent: AzureChatOpenAI = None\\r\\n'\n",
      "           '    tools: list = []\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def __init__(self, tools: list = [], name: str = \"Agent\"):\\r\\n'\n",
      "           '        self.name = name\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        self.agent = AzureChatOpenAI(\\r\\n'\n",
      "           \"            azure_deployment=os.getenv('MODEL', 'gpt-4o-mini'),\\r\\n\"\n",
      "           \"            azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\\r\\n\"\n",
      "           \"            openai_api_key=os.getenv('AZURE_OPENAI_API_KEY'),\\r\\n\"\n",
      "           '            openai_api_version = '\n",
      "           'os.getenv(\"OPENAI_API_VERSION\"),\\r\\n'\n",
      "           '            model_kwargs = {\\r\\n'\n",
      "           '                \"response_format\": {\"type\": \"json_object\"}\\r\\n'\n",
      "           '            }\\r\\n'\n",
      "           '        )\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        # Bind tools to the agent if they are provided\\r\\n'\n",
      "           '        if len(tools) > 0:\\r\\n'\n",
      "           '            self.tools = tools\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        # Bind tools to the agent if they are already set\\r\\n'\n",
      "           '        if len(self.tools) > 0:\\r\\n'\n",
      "           '            self.agent = self.agent.bind_tools(tools)\\r\\n'\n",
      "           '            # self.agent = self.agent.bind_tools(tools, strict = '\n",
      "           'True)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        # Disabling this line as it seems not having any '\n",
      "           'effect        \\r\\n'\n",
      "           '        # self.agent.bind(response_format={\"type\": '\n",
      "           '\"json_object\"})\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def run(self, state: dict, config: dict) -> dict:\\r\\n'\n",
      "           \"        existing_messages = state.get('messages', [])\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '        new_messages = []\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        if not existing_messages:\\r\\n'\n",
      "           '            new_messages = [\\r\\n'\n",
      "           '                SystemMessage(\"Your task is to find the population '\n",
      "           'of a city requested by the user. Your response should be a JSON '\n",
      "           'object with the city name and the population. '\n",
      "           '{\\'<city>\\':\\'<population>\\'}\"),\\r\\n'\n",
      "           \"                HumanMessage(state.get('prompt')),\\r\\n\"\n",
      "           '            ]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        response = self.agent.invoke(existing_messages + '\n",
      "           'new_messages)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        new_messages.append(response)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        return {\\r\\n'\n",
      "           '            \"messages\": new_messages\\r\\n'\n",
      "           '        }\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'graph_builder = StateGraph(StateSchema, ConfigSchema)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'agent_node = Agent(tools=tools)\\r\\n'\n",
      "           'tools_node = ToolNode(tools=tools)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Add the nodes to the graph\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'graph_builder.add_node(agent_node.name, agent_node.run)\\r\\n'\n",
      "           'graph_builder.add_node(tools_node.name, tools_node)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'graph_builder.add_conditional_edges(\\r\\n'\n",
      "           '    agent_node.name,\\r\\n'\n",
      "           '    tools_condition\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           'graph_builder.add_edge(tools_node.name, agent_node.name)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Configure the graph\\r\\n'\n",
      "           'graph_builder.set_entry_point(agent_node.name)\\r\\n'\n",
      "           'graph_builder.set_finish_point(agent_node.name)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'in_memory_store = InMemoryStore()\\r\\n'\n",
      "           'graph = graph_builder.compile(store = in_memory_store)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '############################ FastAPI api.py\\r\\n'\n",
      "           'from fastapi import FastAPI, Body\\r\\n'\n",
      "           'from pydantic import BaseModel\\r\\n'\n",
      "           'from flow.src.graph import graph as graph_module\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'app = FastAPI()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class GraphInput(BaseModel):\\r\\n'\n",
      "           '    prompt: str\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '@app.post(\"/graph\")\\r\\n'\n",
      "           'async def create_graph(input: GraphInput):\\r\\n'\n",
      "           '    return graph_module.invoke({\"prompt\": input.prompt})\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '```shell\\n'\n",
      "           'ERROR:    Exception in ASGI application\\r\\n'\n",
      "           ' Traceback (most recent call last):\\r\\n'\n",
      "           '   File '\n",
      "           '\"/usr/local/lib/python3.11/site-packages/uvicorn-0.32.0-py3.11.egg/uvicorn/protocols/http/h11_impl.py\", '\n",
      "           'line 406, in run_asgi\\r\\n'\n",
      "           '     result = await app(  # type: ignore[func-returns-value]\\r\\n'\n",
      "           '              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n'\n",
      "           '   File '\n",
      "           '\"/usr/local/lib/python3.11/site-packages/uvicorn-0.32.0-py3.11.egg/uvicorn/middleware/proxy_headers.py\", '\n",
      "           'line 60, in __call__\\r\\n'\n",
      "           '     return await self.app(scope, receive, send)\\r\\n'\n",
      "           '            ^^^^^^^^^^^^^^',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-11T12:55:14Z',\n",
      "  '_issueNumber': '2386',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Agent Tools: ValueError: `<function_name>` is not strict. Only '\n",
      "            '`strict` function tools can be auto-parsed',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- Whereas `Send` is for fire-and-forget type of calls, new `call` '\n",
      "           'and `acall` functions are for flows where you want to wait for the '\n",
      "           'node to finish before doing something else\\r\\n'\n",
      "           '- Because we return regular python future objects '\n",
      "           '(concurrent.futures.Future or asyncio.Future) all the python '\n",
      "           'primitives for working with futures work, eg. wait, gather, etc\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```py\\r\\n'\n",
      "           '    @task()\\r\\n'\n",
      "           '    def mapper(input: str) -> str:\\r\\n'\n",
      "           '        print(f\"mapper {input}\")\\r\\n'\n",
      "           '        return input * 2\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    @imp(checkpointer=checkpointer)\\r\\n'\n",
      "           '    def graph(input: list[str]) -> list[str]:\\r\\n'\n",
      "           '        futures = [mapper(i) for i in input]\\r\\n'\n",
      "           '        mapped = [f.result() for f in futures]\\r\\n'\n",
      "           '        return mapped\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    thread1 = {\"configurable\": {\"thread_id\": \"1\"}}\\r\\n'\n",
      "           '    assert graph.invoke([\"0\", \"1\"], thread1) == [\"00\", \"11\"]\\r\\n'\n",
      "           '```',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-08T21:06:09Z',\n",
      "  '_issueNumber': '2378',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Imperative API',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the '\n",
      "           '[LangGraph](https://langchain-ai.github.io/langgraph/)/LangChain '\n",
      "           'documentation with the integrated search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangGraph/LangChain rather '\n",
      "           'than my code.\\n'\n",
      "           '- [X] I am sure this is better as an issue [rather than a GitHub '\n",
      "           'discussion](https://github.com/langchain-ai/langgraph/discussions/new/choose), '\n",
      "           'since this is a LangGraph bug and not a design question.\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```python\\n'\n",
      "           'cannot have code here due to security issue\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           'I have a graph A streaming LLM tokens, I tested it and can confirm '\n",
      "           'I get updates as streaming. Then I have another graph B which is '\n",
      "           'invoked by B.astream_events, then invoke A.astream, I can only get '\n",
      "           'values of every GraphState, no matter I set stream_mode to \"value\" '\n",
      "           'or \"update\"\\n'\n",
      "           '\\n'\n",
      "           '### System Info\\n'\n",
      "           '\\n'\n",
      "           'latest langgraph\\r\\n'\n",
      "           'mac\\r\\n'\n",
      "           'python 3.12',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-06T06:13:41Z',\n",
      "  '_issueNumber': '2351',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': \"Calling .astream inside of another graph's .astream_events will \"\n",
      "            'set stream_mode=\"value\" regardless of config',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-05T14:34:41Z',\n",
      "  '_issueNumber': '2339',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': '[rfc] langgraph: allow tools / ToolNode to modify state',\n",
      "  '_type': 'issue'},\n",
      " {'_body': \"I think reflection don't need code generation, and it will work \"\n",
      "           'better.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-02T09:38:42Z',\n",
      "  '_issueNumber': '2313',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Update reflection function in langgraph_code_assistant.ipynb',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-02T09:35:29Z',\n",
      "  '_issueNumber': '2312',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'feat(langgraph): Add tags and run name to message stream output',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Updates the default model used in documentation to '\n",
      "           'claude-3-5-sonnet-20241022\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'https://docs.anthropic.com/en/docs/about-claude/models',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-01T07:27:59Z',\n",
      "  '_issueNumber': '2289',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'docs: update usage of claude-3-5-sonnet-2024062 to '\n",
      "            'claude-3-5-sonnet-20241022',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\r\\n'\n",
      "           '- [X] I searched the '\n",
      "           '[LangGraph](https://langchain-ai.github.io/langgraph/)/LangChain '\n",
      "           'documentation with the integrated search.\\r\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\r\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangGraph/LangChain rather '\n",
      "           'than my code.\\r\\n'\n",
      "           '- [X] I am sure this is better as an issue [rather than a GitHub '\n",
      "           'discussion](https://github.com/langchain-ai/langgraph/discussions/new/choose), '\n",
      "           'since this is a LangGraph bug and not a design question.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Example Code\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'langgraph.json\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '{\\r\\n'\n",
      "           '  \"dependencies\": [\\r\\n'\n",
      "           '    \".\"\\r\\n'\n",
      "           '  ],\\r\\n'\n",
      "           '  \"graphs\": {\\r\\n'\n",
      "           '    \"example_graph\": \"./example_graph.py:example_graph\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '  },\\r\\n'\n",
      "           '  \"env\": \"./.env\",\\r\\n'\n",
      "           '  \"dockerfile_lines\": [\\r\\n'\n",
      "           '  ],\\r\\n'\n",
      "           '  \"python_version\": \"3.12\"\\r\\n'\n",
      "           '}\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'example_graph.py\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'from typing import Annotated, Any, NotRequired, Sequence, '\n",
      "           'TypedDict\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from langchain_core.messages import AIMessage, BaseMessage\\r\\n'\n",
      "           'from langgraph.graph import StateGraph, add_messages\\r\\n'\n",
      "           'from langgraph.graph.graph import CompiledGraph\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class AgentState(TypedDict):\\r\\n'\n",
      "           '    messages: Annotated[Sequence[BaseMessage], add_messages]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'def node1(state: AgentState) -> AgentState:\\r\\n'\n",
      "           '    return {\"messages\": [AIMessage(\"Hello 1\")]}\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'async def node2(state: AgentState) -> AgentState:\\r\\n'\n",
      "           '    return {\"messages\": [AIMessage(\"Hello 2\")]}\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'def make_graph() -> CompiledGraph:\\r\\n'\n",
      "           '    state_graph = StateGraph(state_schema=AgentState)\\r\\n'\n",
      "           '    state_graph.add_node(\"node1\", node1)\\r\\n'\n",
      "           '    state_graph.add_node(\"node2\", node2)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    state_graph.set_entry_point(\"node1\")\\r\\n'\n",
      "           '    state_graph.add_edge(\"node1\", \"node2\")\\r\\n'\n",
      "           '    state_graph.set_finish_point(\"node2\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    return state_graph.compile()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'example_graph = make_graph()\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'devcontainer.json\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '{\\r\\n'\n",
      "           '\\t\"name\": \"file_not_found_issue\",\\r\\n'\n",
      "           '\\t\"image\": '\n",
      "           '\"mcr.microsoft.com/devcontainers/python:1-3.12-bullseye\",\\r\\n'\n",
      "           '\\t\"features\": {\\r\\n'\n",
      "           '\\t\\t\"ghcr.io/devcontainers/features/docker-in-docker:2\": {\\r\\n'\n",
      "           '\\t\\t\\t\"moby\": true,\\r\\n'\n",
      "           '\\t\\t\\t\"azureDnsAutoDetection\": true,\\r\\n'\n",
      "           '\\t\\t\\t\"installDockerBuildx\": true,\\r\\n'\n",
      "           '\\t\\t\\t\"installDockerComposeSwitch\": true,\\r\\n'\n",
      "           '\\t\\t\\t\"version\": \"27.0\"\\r\\n'\n",
      "           '\\t\\t}\\r\\n'\n",
      "           '\\t},\\r\\n'\n",
      "           '\\t\"postCreateCommand\": \"pip install langgraph-cli && langgraph '\n",
      "           'up\"\\r\\n'\n",
      "           '}\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```shell\\r\\n'\n",
      "           '`langgraph up`\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Starting LangGraph API server...\\r\\n'\n",
      "           'For local dev, requires env var LANGSMITH_API_KEY with access to '\n",
      "           'LangGraph Cloud closed beta.\\r\\n'\n",
      "           'For production use, requires a license key in env var '\n",
      "           'LANGGRAPH_CLOUD_LICENSE_KEY.\\r\\n'\n",
      "           '\\\\ Building...open /workspaces/temp_no_such_file_issue/-: no such '\n",
      "           'file or directory\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Description\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"I don't know where the issue lies between langgraph, docker, \"\n",
      "           \"devcontainer... I don't see issues raised in the docker or \"\n",
      "           'devcontainer repos related to this yet, which makes me think it '\n",
      "           'could be some strange interaction with langgraph. Feel free to '\n",
      "           'close if this is not relevant enough. Just wanted to post in case '\n",
      "           'others have noticed the same issue.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This issue just started happening today, and I cannot understand '\n",
      "           'where it comes from. \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Using the extremely minimal example of a langgraph app provided '\n",
      "           '(also with a `.env` file that contains a valid api key), I am able '\n",
      "           'to run `langgraph up` no problem from wsl2. But trying to do the '\n",
      "           'same from within a devcontainer, I keeep getting the error, `no '\n",
      "           'such file or directory` with directory name ending with a `-`. \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Things I have tried:\\r\\n'\n",
      "           '- Using docker-in-docker devcontainer feature with docker engine '\n",
      "           \"versions 26.1, 27.0 (and older, 27.1/2 don't seem to exist)\\r\\n\"\n",
      "           '- Using docker-out-of-docker devcontainer feature\\r\\n'\n",
      "           '- Using langgraph-cli==0.1.50 (and 51 and 52)\\r\\n'\n",
      "           '- Using langgraph==0.2.37 (and 38 and 39)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"So, it's not due to a very new release of langgraph, \"\n",
      "           'langgraph-cli, or docker engines.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Also, my external (wsl2) docker version is 27.2\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I first noticed this issue in my CI workflow today. Re-running a '\n",
      "           'successful one from yesterday still works (but I think my '\n",
      "           'devcontainer build is cached). \\r\\n'\n",
      "           \"I don't usually use the devcontainer locally, but once my CI \"\n",
      "           'failed, I tried locally and it failed the same way. However, even '\n",
      "           'going back to the same git commit from yesterday does not work '\n",
      "           'locally. \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Mostly wanted to post this in case anyone else comes across the '\n",
      "           'same issue. \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Also, deploying to langgraph-cloud still works.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### System Info\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'pip freeze output\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'click==8.1.7\\r\\n'\n",
      "           'gitdb==4.0.11\\r\\n'\n",
      "           'GitPython==3.1.41\\r\\n'\n",
      "           'langgraph-cli==0.1.52\\r\\n'\n",
      "           'setuptools==69.0.3\\r\\n'\n",
      "           'smmap==5.0.1\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'docker version output (from in the devcontainer)\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'Server:\\r\\n'\n",
      "           ' Engine:\\r\\n'\n",
      "           '  Version:          26.1.5-1\\r\\n'\n",
      "           '  API version:      1.45 (minimum version 1.24)\\r\\n'\n",
      "           '  Go version:       go1.21.12\\r\\n'\n",
      "           '  Git commit:       411e817ddf710ff8e08fa193da80cb78af708191\\r\\n'\n",
      "           '  Built:            Tue Jul 23 19:36:28 2024\\r\\n'\n",
      "           '  OS/Arch:          linux/amd64\\r\\n'\n",
      "           '  Experimental:     false\\r\\n'\n",
      "           ' containerd:\\r\\n'\n",
      "           '  Version:          1.6.36-1\\r\\n'\n",
      "           '  GitCommit:        88c3d9bc5b5a193f40b7c14fa996d23532d6f956\\r\\n'\n",
      "           ' runc:\\r\\n'\n",
      "           '  Version:          1.1.15-1\\r\\n'\n",
      "           '  GitCommit:        bc20cb4497af9af01bea',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-29T20:57:12Z',\n",
      "  '_issueNumber': '2222',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'No such file error on `langgraph up`  within devcontainer '\n",
      "            '(`.../app_dir/-`)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Issue with current documentation:\\n'\n",
      "           '\\n'\n",
      "           '<img width=\"1540\" alt=\"image\" '\n",
      "           'src=\"https://github.com/user-attachments/assets/a1743431-e7f6-4e28-9767-7c23d54bc07a\">\\r\\n'\n",
      "           ' Checking the github pages I can not find the method '\n",
      "           'aupdate_state. Nevertheless the library has implemented this '\n",
      "           'method\\n'\n",
      "           '\\n'\n",
      "           '### Idea or request for content:\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-29T00:05:27Z',\n",
      "  '_issueNumber': '2207',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'DOC: In the github pages the aupdate_state is not documented',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Add `format` flag to `add_messages` which allows you to specify if '\n",
      "           'the contents of messages in state should be formatted in a '\n",
      "           'particular way. PR only adds support for OpenAI style contents. '\n",
      "           \"Helpful if you're using different models at different nodes and \"\n",
      "           'want a unified messages format to interact with when you manually '\n",
      "           'update messages.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-27T19:54:48Z',\n",
      "  '_issueNumber': '2199',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'langgraph[patch]: format messages in state',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\n'\n",
      "           '\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\n'\n",
      "           '- [X] I searched the '\n",
      "           '[LangGraph](https://langchain-ai.github.io/langgraph/)/LangChain '\n",
      "           'documentation with the integrated search.\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangGraph/LangChain rather '\n",
      "           'than my code.\\n'\n",
      "           '- [X] I am sure this is better as an issue [rather than a GitHub '\n",
      "           'discussion](https://github.com/langchain-ai/langgraph/discussions/new/choose), '\n",
      "           'since this is a LangGraph bug and not a design question.\\n'\n",
      "           '\\n'\n",
      "           '### Example Code\\n'\n",
      "           '\\n'\n",
      "           '```python\\n'\n",
      "           'from typing import TypedDict\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from langchain_core.callbacks.base import BaseCallbackHandler\\r\\n'\n",
      "           'from langchain_core.runnables.config import RunnableConfig\\r\\n'\n",
      "           'from langgraph.graph import END, StateGraph\\r\\n'\n",
      "           'from langgraph.graph.graph import START\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class CustomCallbackHandler(BaseCallbackHandler):\\r\\n'\n",
      "           '    def on_chain_end(self, _outputs, **kwargs):\\r\\n'\n",
      "           '        print(\"on_chain_end\", _outputs)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class OutputType(TypedDict):\\r\\n'\n",
      "           '    a: int\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class State(TypedDict):\\r\\n'\n",
      "           '    a: int\\r\\n'\n",
      "           '    b: int\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'graph = StateGraph(State, output=OutputType)\\r\\n'\n",
      "           'graph.add_node(\"node_a\", lambda state: {\"a\": state[\"a\"] + 1})\\r\\n'\n",
      "           'graph.add_node(\"node_b\", lambda state: {\"b\": state[\"b\"] + 1})\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'graph.add_edge(START, \"node_a\")\\r\\n'\n",
      "           'graph.add_edge(\"node_a\", \"node_b\")\\r\\n'\n",
      "           'graph.add_edge(\"node_b\", END)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'input = {\"a\": 0, \"b\": 0}\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'config = RunnableConfig(callbacks=[CustomCallbackHandler()])\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'compiled_graph = graph.compile()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'invoke_result = compiled_graph.invoke(input, config)\\r\\n'\n",
      "           'print(\"invoke result: \", invoke_result)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'print(\"**************\")\\r\\n'\n",
      "           'print(\"graph without output keys defined\")\\r\\n'\n",
      "           'print(\"**************\")\\r\\n'\n",
      "           'graph_without_output_keys_results = []\\r\\n'\n",
      "           'for stream_output in compiled_graph.stream(input, config):\\r\\n'\n",
      "           '    graph_without_output_keys_results.append(stream_output)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'print(\"*** stream outputs ***\")\\r\\n'\n",
      "           'for stream_output in graph_without_output_keys_results:\\r\\n'\n",
      "           '    print(stream_output)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'print(\"**************\")\\r\\n'\n",
      "           'print(\"graph with output keys (a) defined\")\\r\\n'\n",
      "           'print(\"**************\")\\r\\n'\n",
      "           'graph_with_output_keys_results = []\\r\\n'\n",
      "           'for stream_output in compiled_graph.stream(input, config, '\n",
      "           'output_keys=[\"a\"]):\\r\\n'\n",
      "           '    graph_with_output_keys_results.append(stream_output)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'print(\"*** stream outputs ***\")\\r\\n'\n",
      "           'for stream_output in graph_with_output_keys_results:\\r\\n'\n",
      "           '    print(stream_output)\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Error Message and Stack Trace (if applicable)\\n'\n",
      "           '\\n'\n",
      "           '```shell\\n'\n",
      "           '[Annotated result]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"on_chain_end {'a': 0, 'b': 0}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1}\\r\\n\"\n",
      "           \"on_chain_end {'b': 1}\\r\\n\"\n",
      "           \"on_chain_end {'b': 1}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1} <--- This is the graph's final callback that \"\n",
      "           'I am tracing\\r\\n'\n",
      "           \"invoke result:  {'a': 1}\\r\\n\"\n",
      "           '**************\\r\\n'\n",
      "           'graph without output keys defined\\r\\n'\n",
      "           '**************\\r\\n'\n",
      "           \"on_chain_end {'a': 0, 'b': 0}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1}\\r\\n\"\n",
      "           \"on_chain_end {'b': 1}\\r\\n\"\n",
      "           \"on_chain_end {'b': 1}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1, 'b': 1} <-- This is the graph's final \"\n",
      "           'callback result when using stream\\r\\n'\n",
      "           '*** stream outputs ***\\r\\n'\n",
      "           \"{'node_a': {'a': 1}}\\r\\n\"\n",
      "           \"{'node_b': {'b': 1}}\\r\\n\"\n",
      "           '**************\\r\\n'\n",
      "           'graph with output keys (a) defined\\r\\n'\n",
      "           '**************\\r\\n'\n",
      "           \"on_chain_end {'a': 0, 'b': 0}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1}\\r\\n\"\n",
      "           \"on_chain_end {'b': 1}\\r\\n\"\n",
      "           \"on_chain_end {'b': 1}\\r\\n\"\n",
      "           \"on_chain_end {'a': 1} <-- This is the graph's final callback \"\n",
      "           'result when using stream with output_keys\\r\\n'\n",
      "           '*** stream outputs ***\\r\\n'\n",
      "           \"{'node_a': {'a': 1}}\\r\\n\"\n",
      "           \"{'node_b': None} <-- I expect this not to be None, as I want to \"\n",
      "           'stream content, that is not necessarily returned from the graph in '\n",
      "           'the end\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Description\\n'\n",
      "           '\\n'\n",
      "           'Here is a minimal repo to show the encountered inconsistency: '\n",
      "           'https://github.com/kaiwend/langgraph-streaming-inconsistency\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I have been working with langgraph for a while now, mostly '\n",
      "           'invoking my graph using `.invoke`. Now after some time, I wanted '\n",
      "           'to introduce streaming into my app. The overall goal is to get '\n",
      "           'some internals from the graph execution out earlier to the user '\n",
      "           'and not just after the whole invocation is done, e.g. logging and '\n",
      "           'streaming the output to the user. While doing that, I noticed some '\n",
      "           'inconsistencies on how the streaming behaves in combination with '\n",
      "           'callbacks. I am using tracing that uses the callbacks to collect '\n",
      "           'traces. I am working with quite large amounts of data, so limiting '\n",
      "           'what is coming in and out of nodes is crucial for the task at '\n",
      "           'hand. However when using streaming, I noticed the following '\n",
      "           'difference to the non-streamed version:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- I have an output TypedDict, which I assign to my graph '\n",
      "           '`StateGraph(State, output=OutputType)`. When using `.invoke`, the '\n",
      "           \"output type is used and I only get what's defined in `OutputType`. \"\n",
      "           'This also leads to the last callback also being triggered with '\n",
      "           'OutputType.\\r\\n'\n",
      "           '- When using streaming on the other hand, the last callback from '\n",
      "           'the graph get my whole state, which is a problem in regards to the '\n",
      "           \"sheer size of my state's contents\\r\\n\"\n",
      "           '- I tried adding `output_keys=` (keys from my OutputType) to my '\n",
      "           '`graph.stream` call. This lead to the last callback being '\n",
      "           'triggered correctly, with only returning OutputType. ',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-24T10:05:45Z',\n",
      "  '_issueNumber': '2169',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': \"Inconsistency .invoke and .stream for graph's last callback and \"\n",
      "            'output_keys affecting streamed values',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-23T04:21:46Z',\n",
      "  '_issueNumber': '2162',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'WIP: deploy docs',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This PR removes the use of `from typing import Literal` since it '\n",
      "           'is not being used in the code implementation',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-21T08:32:46Z',\n",
      "  '_issueNumber': '2149',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'docs: remove Literal as it is not being used',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Checked other resources\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [X] I added a very descriptive title to this issue.\\r\\n'\n",
      "           '- [X] I searched the '\n",
      "           '[LangGraph](https://langchain-ai.github.io/langgraph/)/LangChain '\n",
      "           'documentation with the integrated search.\\r\\n'\n",
      "           '- [X] I used the GitHub search to find a similar question and '\n",
      "           \"didn't find it.\\r\\n\"\n",
      "           '- [X] I am sure that this is a bug in LangGraph/LangChain rather '\n",
      "           'than my code.\\r\\n'\n",
      "           '- [X] I am sure this is better as an issue [rather than a GitHub '\n",
      "           'discussion](https://github.com/langchain-ai/langgraph/discussions/new/choose), '\n",
      "           'since this is a LangGraph bug and not a design question.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Example Code\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'Subgraph class:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'import functools\\r\\n'\n",
      "           'from typing import Annotated, Sequence, TypedDict, Literal\\r\\n'\n",
      "           'from common.schema import  ResearchSchema\\r\\n'\n",
      "           'from langchain_core.messages import (\\r\\n'\n",
      "           '    BaseMessage,\\r\\n'\n",
      "           '    HumanMessage,\\r\\n'\n",
      "           '    AIMessage\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           'from common.constants import RESEARCH_COLLECTION\\r\\n'\n",
      "           'from common.firestore_db import update_research_chat, get_doc\\r\\n'\n",
      "           'from langgraph.checkpoint.postgres import PostgresSaver\\r\\n'\n",
      "           'from psycopg_pool import ConnectionPool\\r\\n'\n",
      "           'import os\\r\\n'\n",
      "           'from langchain_core.prompts import ChatPromptTemplate, '\n",
      "           'MessagesPlaceholder, PromptTemplate\\r\\n'\n",
      "           'from langgraph.graph import END, StateGraph, START, add_messages, '\n",
      "           'MessagesState\\r\\n'\n",
      "           'from langgraph.prebuilt import ToolNode\\r\\n'\n",
      "           'from common.utils import convert_message_to_dict\\r\\n'\n",
      "           'from tools import ToolSaveHandler\\r\\n'\n",
      "           'from uuid import uuid4\\r\\n'\n",
      "           'import ast\\r\\n'\n",
      "           'from common.firestore_db import update_multiagent_research_chat\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class NeoState(MessagesState):\\r\\n'\n",
      "           '    sender: str\\r\\n'\n",
      "           '    limit:int\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class Agent:\\r\\n'\n",
      "           '    def __init__(self, llm, tools, inputs, history, '\n",
      "           'feedback_limit, user_query ,system_message: str,simple = False, '\n",
      "           'agent_type = True):\\r\\n'\n",
      "           '        self.llm = llm\\r\\n'\n",
      "           '        self.tools = tools\\r\\n'\n",
      "           '        self.system_message = system_message\\r\\n'\n",
      "           '        self.simple = simple\\r\\n'\n",
      "           '        self.inputs=inputs\\r\\n'\n",
      "           '        self.user_query = user_query\\r\\n'\n",
      "           '        self.history=history\\r\\n'\n",
      "           '        self.feedback_limit = feedback_limit\\r\\n'\n",
      "           '        self.agent=self.create_reviewer_agent()\\r\\n'\n",
      "           '        if agent_type:\\r\\n'\n",
      "           '            self.agent = self.create_generator_agent()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def create_reviewer_agent(self):\\r\\n'\n",
      "           '        \"\"\"Create an agent.\"\"\"\\r\\n'\n",
      "           '        prompt = ChatPromptTemplate.from_messages(\\r\\n'\n",
      "           '            [\\r\\n'\n",
      "           '                (\\r\\n'\n",
      "           '                    \"system\",\\r\\n'\n",
      "           '                    \"\"\"\\r\\n'\n",
      "           '1. Follow Instructions:\\r\\n'\n",
      "           '- Adhere to any specific instructions provided by the user, below '\n",
      "           'are user instructions that are essential for producing the correct '\n",
      "           'feedback or critique response.:\\r\\n'\n",
      "           '```{system_message}``` \\r\\n'\n",
      "           \"- To ensure the output aligns with the user's requirements. These \"\n",
      "           'guidelines are essential for producing the correct feedback or '\n",
      "           'critique response.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Your primary goal is to ensure that the final answer is accurate, '\n",
      "           'well-supported, and complete. Collaborate efficiently with the '\n",
      "           'other assistants, provide valuable critiques, and guide the team '\n",
      "           'toward the best possible outcome.\\r\\n'\n",
      "           '                    \"\"\",\\r\\n'\n",
      "           '                ),\\r\\n'\n",
      "           '                \\r\\n'\n",
      "           '                MessagesPlaceholder(variable_name=\"messages\"),\\r\\n'\n",
      "           '            ]\\r\\n'\n",
      "           '        )\\r\\n'\n",
      "           '        prompt = prompt.partial(tool_names=\", \".join([tool.name '\n",
      "           'for tool in self.tools]))\\r\\n'\n",
      "           '        return prompt | self.llm.bind_tools(self.tools)\\r\\n'\n",
      "           '        \\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def create_generator_agent(self):\\r\\n'\n",
      "           '        \"\"\"Create an agent.\"\"\"\\r\\n'\n",
      "           '        if self.simple:\\r\\n'\n",
      "           '            prompt = ChatPromptTemplate.from_messages(\\r\\n'\n",
      "           '                [\\r\\n'\n",
      "           '                    (\\r\\n'\n",
      "           '                        \"system\",\\r\\n'\n",
      "           '                        self.system_message\\r\\n'\n",
      "           '                    ),\\r\\n'\n",
      "           '                    '\n",
      "           'MessagesPlaceholder(variable_name=\"history\"),\\r\\n'\n",
      "           '                    '\n",
      "           'MessagesPlaceholder(variable_name=\"messages\"),\\r\\n'\n",
      "           '                ]\\r\\n'\n",
      "           '            )\\r\\n'\n",
      "           '            prompt = prompt.partial(history=self.history)\\r\\n'\n",
      "           '            prompt = '\n",
      "           'prompt.partial(system_message=self.system_message)\\r\\n'\n",
      "           '            prompt = prompt.partial(tool_names=\", '\n",
      "           '\".join([tool.name for tool in self.tools]))\\r\\n'\n",
      "           '            return prompt | self.llm.bind_tools(self.tools)\\r\\n'\n",
      "           '        else:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '            prompt = ChatPromptTemplate.from_messages(\\r\\n'\n",
      "           '                [\\r\\n'\n",
      "           '                    (\\r\\n'\n",
      "           '                        \"system\",\\r\\n'\n",
      "           '                        \"\"\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**1. Follow Instructions:**\\r\\n'\n",
      "           '- Adhere to any specific instructions provided by the user, below '\n",
      "           'are user instructions that are essential for producing the correct '\n",
      "           'response.:\\r\\n'\n",
      "           '```{system_message}``` \\r\\n'\n",
      "           \"- To ensure the output aligns with the user's requirements. These \"\n",
      "           'guidelines are essential for producing the correct response.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Your sole purpose is to generate effective, accurate, and '\n",
      "           \"well-constructed responses based on the user's query and always do \"\n",
      "           'the work according to the instructions, whether using tools or '\n",
      "           'relying on knowledge. Stay within your role, continue generating '\n",
      "           'content, and contribute toward the final solution.\\r\\n'\n",
      "           '                        \"\"\",\\r\\n'\n",
      "           '                    ),\\r\\n'\n",
      "           '                    '\n",
      "           'MessagesPlaceholder(variable_name=\"history\"),\\r\\n'\n",
      "           '                    '\n",
      "           'MessagesPlaceholder(variable_name=\"messages\"),\\r\\n'\n",
      "           '                ]\\r\\n'\n",
      "           '     ',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-19T14:13:27Z',\n",
      "  '_issueNumber': '2142',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Subgraph state is not inserted to persistance db.',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'because in\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           '    def call_model(\\r\\n'\n",
      "           '        state: AgentState,\\r\\n'\n",
      "           '        config: RunnableConfig,\\r\\n'\n",
      "           '    )\\r\\n'\n",
      "           '...\\r\\n'\n",
      "           '        if (\\r\\n'\n",
      "           '            (\\r\\n'\n",
      "           '                \"remaining_steps\" not in state\\r\\n'\n",
      "           '                and state[\"is_last_step\"]\\r\\n'\n",
      "           '                and has_tool_calls\\r\\n'\n",
      "           '            )\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'https://github.com/langchain-ai/langgraph/blob/c0b56bf60d84ed435609c35b0691cd0305ceae78/libs/langgraph/langgraph/prebuilt/chat_agent_executor.py#L543\\r\\n'\n",
      "           'the AgentState requires is_last_step to have a default value, like '\n",
      "           '`False`, and `IsLastStep` can satisfy it. ',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-15T07:26:52Z',\n",
      "  '_issueNumber': '2109',\n",
      "  '_repo': 'langgraph',\n",
      "  '_state': 'open',\n",
      "  '_title': 'fix example in docs of state_schema in create_react_agent',\n",
      "  '_type': 'issue'}]\n",
      "Fetching issues from: https://api.github.com/repos/microsoft/autogen/issues\n",
      "[{'_body': '<!-- Thank you for your contribution! Please review '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute before opening '\n",
      "           'a pull request. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please add a reviewer to the assignee section when you create '\n",
      "           \"a PR. If you don't have the access to it, we will shortly find a \"\n",
      "           'reviewer and assign them to your PR. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Why are these changes needed?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please give a short summary of the change and the problem '\n",
      "           'this solves. -->\\r\\n'\n",
      "           'The changes are\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '1. Delete openai client from autogen_core\\r\\n'\n",
      "           '2. Delete symlinks to `code_executor` and `tools.langchain` that '\n",
      "           'where refactored in `autogen_ext`\\r\\n'\n",
      "           '3. Update files that relied on the deprecated imports\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Those changes are needed as part of the refactor clean up before '\n",
      "           '`0.4.0` release.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Related issue number\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- For example: \"Closes #1234\" -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Checks\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"- [ ] I've included any doc changes needed for \"\n",
      "           'https://microsoft.github.io/autogen/. See '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute#documentation '\n",
      "           'to build and test documentation locally.\\r\\n'\n",
      "           \"- [ ] I've added tests (if relevant) corresponding to the changes \"\n",
      "           'introduced in this PR.\\r\\n'\n",
      "           \"- [ ] I've made sure all auto checks have passed.\\r\\n\",\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T02:22:48Z',\n",
      "  '_issueNumber': '4305',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Delete autogen-ext refactor deprecations',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'makes Getsubscriptions api work as intended. ',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T01:05:24Z',\n",
      "  '_issueNumber': '4304',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'improve subscriptions api',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What feature would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'WebSurfur agent for .NET\\n'\n",
      "           '\\n'\n",
      "           \"There's a corresponding implementation\\n\"\n",
      "           '- '\n",
      "           'https://github.com/LittleLittleCloud/WebSurferAgent?tab=readme-ov-file\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T16:47:20Z',\n",
      "  '_issueNumber': '4298',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': '[.NET] Introduce websurfer agent',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'GRPC is a pretty heavy dependency to make required in core, '\n",
      "           'additionally since we pin it then it is more restrictive. The '\n",
      "           'current pinned version has no binary wheel for 3.13. \\n'\n",
      "           '\\n'\n",
      "           'While we do need to upgrade grpc, making this optional is also '\n",
      "           'important for people who dont need distributed support',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T15:40:40Z',\n",
      "  '_issueNumber': '4296',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Make distributed runtime/grpc dependency optional in core',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '\\n'\n",
      "           'Explore early tests on how to support websurfer agents in AGS. \\n'\n",
      "           '\\n'\n",
      "           '- enable adding '\n",
      "           '[WebSurfer](https://github.com/microsoft/autogen/tree/main/python/packages/autogen-ext/src/autogen_ext/agents/web_surfer) '\n",
      "           'agent to any team \\n'\n",
      "           '- enable viewing websurfer text messages in the ags ui \\n'\n",
      "           '- enable viewing websurfer multimodal messages in ui. ',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T21:26:24Z',\n",
      "  '_issueNumber': '4290',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Enable v1 support for WebSurfer Agent in AGS',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T17:57:06Z',\n",
      "  '_issueNumber': '4285',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Agentchat should validate model capabilities that it needs from a '\n",
      "            'given model client',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What feature would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'Implement a system for dynamically composing and optimizing agent '\n",
      "           'workflows using reinforcement learning (RL) techniques\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '(this feature can be integrated into Existing Framework by '\n",
      "           \"Extending the 'AgentWorkflow' class )\\n\"\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           \" This feature would enhance AutoGen's ability to adapt to complex, \"\n",
      "           'multi-step tasks by automatically discovering and refining '\n",
      "           'effective agent combinations.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T10:32:47Z',\n",
      "  '_issueNumber': '4282',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Dynamic Agent Composition with Reinforcement Learning',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Why are these changes needed?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- Added support for a new chat completion client using the Ollama '\n",
      "           'API (OllamaChatCompletionClient).\\r\\n'\n",
      "           '- Enhanced image handling with base64 encoding for the Ollama '\n",
      "           'API.\\r\\n'\n",
      "           '- Updated environment-based client creation to accommodate the new '\n",
      "           'Ollama client.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Related Issue Number\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- No specific issue linked. You can mention an issue if '\n",
      "           'applicable.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Checks\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x] Documentation updated to reflect new changes.\\r\\n'\n",
      "           '- [x] Tested locally with Ollama',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T06:12:22Z',\n",
      "  '_issueNumber': '4280',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Adding Ollama to Magentic One',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What happened?\\n'\n",
      "           '\\n'\n",
      "           'There is a fault while pip installs autoGen with the Python '\n",
      "           'versions higher than 3.12. But the current reminder only point to '\n",
      "           'the versions below 3.10.\\n'\n",
      "           '```\\n'\n",
      "           'File '\n",
      "           '\"/private/var/folders/0d/ftmmyfbs25g4t_4p7lhn3j3c0000gq/T/pip-build-env-q3_t8ewn/overlay/lib/python3.13/site-packages/setuptools/_distutils/unixccompiler.py\", '\n",
      "           'line 202, in _compile\\n'\n",
      "           'raise CompileError(msg)\\n'\n",
      "           \"distutils.errors.CompileError: command '/usr/bin/clang++' failed \"\n",
      "           'with exit code 1\\n'\n",
      "           '\\n'\n",
      "           '  [end of output]\\n'\n",
      "           'note: This error originates from a subprocess, and is likely not a '\n",
      "           'problem with pip.\\n'\n",
      "           'ERROR: Failed building wheel for grpcio\\n'\n",
      "           'Failed to build grpcio\\n'\n",
      "           'ERROR: ERROR: Failed to build installable wheels for some '\n",
      "           'pyproject.toml based projects (grpcio)\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### What did you expect to happen?\\n'\n",
      "           '\\n'\n",
      "           'Python version compatibility issue.\\n'\n",
      "           '\\n'\n",
      "           '### How can we reproduce it (as minimally and precisely as '\n",
      "           'possible)?\\n'\n",
      "           '\\n'\n",
      "           '1. Remark the compatible Python version range in the README doc.\\n'\n",
      "           '2. Ensure compatibility with future major versions of Python.\\n'\n",
      "           '\\n'\n",
      "           '### AutoGen version\\n'\n",
      "           '\\n'\n",
      "           '0.4\\n'\n",
      "           '\\n'\n",
      "           '### Which package was this bug in\\n'\n",
      "           '\\n'\n",
      "           'AgentChat\\n'\n",
      "           '\\n'\n",
      "           '### Model used\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Python version\\n'\n",
      "           '\\n'\n",
      "           '3.13 and above\\n'\n",
      "           '\\n'\n",
      "           '### Operating system\\n'\n",
      "           '\\n'\n",
      "           'MacOS\\n'\n",
      "           '\\n'\n",
      "           '### Any additional info you think would be helpful for fixing this '\n",
      "           'bug\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T03:56:08Z',\n",
      "  '_issueNumber': '4278',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Python Version Compatibility',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What feature would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'I would love to have a /v1/chat endpoint that communicates with my '\n",
      "           'Autogen agents. Is there any simple platforms that support this '\n",
      "           'with autogen agents?\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           'So I can interface with it with external openai api compatible '\n",
      "           'clients',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T23:34:41Z',\n",
      "  '_issueNumber': '4274',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Exporting an OpenAI compatible API for an agent',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Ability to side by side compare team configurations in AGS.\\n'\n",
      "           'A simple implementation would be to have a compare view with two '\n",
      "           'session each with different team configurations.\\n'\n",
      "           '\\n'\n",
      "           'fyi\\n'\n",
      "           '@husseinmozannar ',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T22:14:36Z',\n",
      "  '_issueNumber': '4273',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Ability to side by side compare team configurations in AGS',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Many agent applications often benefit from being able to retrieve '\n",
      "           'data from memory (rag).\\n'\n",
      "           'This PR is meant to enable ..\\n'\n",
      "           '\\n'\n",
      "           '- Defining memory as a component that can be declaratively '\n",
      "           'specified and attached to an agent, similar to how a model or tool '\n",
      "           'can be attached to an agent \\n'\n",
      "           '- Implement several base Memory classes e.g, Memory as list,  \\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '## Design Considerations.\\n'\n",
      "           'Memory is by nature should be persistent across runs - using some '\n",
      "           'type of db.\\n'\n",
      "           '\\n'\n",
      "           '- Declarative spec will keep a pointer to  the db entry \\n'\n",
      "           '- Have flexible defaults - e.g., create a memory entry if the '\n",
      "           'specified one is unavailable etc.  not fail etc\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'Should build on #4039 ',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T22:44:17Z',\n",
      "  '_issueNumber': '4264',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Enable support for Memory as a first class component in AGS',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'AssistantAgent can take a list of tools. \\n'\n",
      "           'These tools are typically python functions which themselves can '\n",
      "           'have dependencies and secrets.\\n'\n",
      "           'For example, a search tool might use a specific search library '\n",
      "           'e.g. googlesearch and need a search api key.\\n'\n",
      "           '\\n'\n",
      "           'In a no code environment, it is useful to have some mechanism to \\n'\n",
      "           '\\n'\n",
      "           '- [ ] install specified libraries and \\n'\n",
      "           '- [ ] load specified keys to make them available when the tool is '\n",
      "           'called. \\n'\n",
      "           '\\n'\n",
      "           '## How \\n'\n",
      "           '\\n'\n",
      "           'Create a ToolHelper class that is used with the '\n",
      "           '[component_factory](https://github.com/microsoft/autogen/blob/main/python/packages/autogen-studio/autogenstudio/database/component_factory.py) '\n",
      "           'in loading tools. \\n'\n",
      "           '\\n'\n",
      "           '- For each dependency, check if the dependency is installed '\n",
      "           '(attempt to import)\\n'\n",
      "           '- If not installed, install it (or validate and provide some '\n",
      "           'confirmation workflow where the user can agree to explicitly '\n",
      "           'install)\\n'\n",
      "           '- load the tool \\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '## Challenges / Considerations\\n'\n",
      "           '\\n'\n",
      "           '- Tool calls get executed in the same environment as the '\n",
      "           'application (AGS in this case). \\n'\n",
      "           '   - UX should communicate this to the user \\n'\n",
      "           '   - One assumption here is that the user designs/understands the '\n",
      "           'tools they create and implicitly are comfortable with outcomes and '\n",
      "           'side effects of their execution. The opposite of this is with a '\n",
      "           'general purpose tool like code execution where arbitrary code with '\n",
      "           'arbitrary side effects can be executed.\\n'\n",
      "           '\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T22:30:17Z',\n",
      "  '_issueNumber': '4263',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Add mechanism for tool dependencies in AGS (installation, '\n",
      "            'secrets)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What happened?\\n'\n",
      "           '\\n'\n",
      "           'https://github.com/microsoft/autogen/security/dependabot/31\\n'\n",
      "           '\\n'\n",
      "           '### What did you expect to happen?\\n'\n",
      "           '\\n'\n",
      "           'see https://github.com/microsoft/autogen/security/dependabot/31\\n'\n",
      "           '\\n'\n",
      "           '### How can we reproduce it (as minimally and precisely as '\n",
      "           'possible)?\\n'\n",
      "           '\\n'\n",
      "           'see https://github.com/microsoft/autogen/security/dependabot/31\\n'\n",
      "           '\\n'\n",
      "           '### AutoGen version\\n'\n",
      "           '\\n'\n",
      "           '0.4\\n'\n",
      "           '\\n'\n",
      "           '### Which package was this bug in\\n'\n",
      "           '\\n'\n",
      "           'AutoGen Studio\\n'\n",
      "           '\\n'\n",
      "           '### Model used\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Python version\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Operating system\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Any additional info you think would be helpful for fixing this '\n",
      "           'bug\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T21:44:33Z',\n",
      "  '_issueNumber': '4262',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'dependency vulnerability: cookie accepts cookie name, path, and '\n",
      "            'domain with out of bounds characters #31',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'I would really like to create an agent runtime that relies on a '\n",
      "           'shared queue that does not require GRPC connections, at least for '\n",
      "           'events. RPC will likely still require some kind of global '\n",
      "           'location. ',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T20:22:47Z',\n",
      "  '_issueNumber': '4261',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Eventhub/grid/kafka based agent runtime prototype',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What happened?\\n'\n",
      "           '\\n'\n",
      "           'https://github.com/microsoft/autogen/security/dependabot/30\\n'\n",
      "           '\\n'\n",
      "           '### What did you expect to happen?\\n'\n",
      "           '\\n'\n",
      "           'alert is remediated\\n'\n",
      "           '\\n'\n",
      "           '### How can we reproduce it (as minimally and precisely as '\n",
      "           'possible)?\\n'\n",
      "           '\\n'\n",
      "           'see https://github.com/microsoft/autogen/security/dependabot/30\\n'\n",
      "           '\\n'\n",
      "           '### AutoGen version\\n'\n",
      "           '\\n'\n",
      "           '0.4\\n'\n",
      "           '\\n'\n",
      "           '### Which package was this bug in\\n'\n",
      "           '\\n'\n",
      "           'AutoGen Studio\\n'\n",
      "           '\\n'\n",
      "           '### Model used\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Python version\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Operating system\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Any additional info you think would be helpful for fixing this '\n",
      "           'bug\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T19:08:31Z',\n",
      "  '_issueNumber': '4260',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'dependency vulnerability: DOM Clobbering Gadget found in rollup '\n",
      "            'bundled scripts that leads to XSS #30',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What feature would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'need to bring forward the Orleans Cluster azd/bicep infra code '\n",
      "           'from oagents and show how to implement a default Orleans Cluster '\n",
      "           'setup with a persistent store.\\n'\n",
      "           'similar to '\n",
      "           'https://learn.microsoft.com/en-us/dotnet/orleans/deployment/deploy-to-azure-app-service\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           'shows customers how to run in prod',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T18:57:11Z',\n",
      "  '_issueNumber': '4259',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'show customers how to run in prod: azd infra scripts for easy '\n",
      "            'setup of Orleans Cluster in azure',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '* changes to _worker_runtime.py that adds serialization for cloud '\n",
      "           'events\\r\\n'\n",
      "           '* samples for xlang by Peter',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T17:28:09Z',\n",
      "  '_issueNumber': '4256',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'the python side of the xlang changes',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '<!-- Thank you for your contribution! Please review '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute before opening '\n",
      "           'a pull request. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please add a reviewer to the assignee section when you create '\n",
      "           \"a PR. If you don't have the access to it, we will shortly find a \"\n",
      "           'reviewer and assign them to your PR. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'While current tutorial shows how to create custom agents, a '\n",
      "           'UserProxyAgent seems to be a common preset and it would be good to '\n",
      "           'have an implementation that can be easily reused as part of the '\n",
      "           'api instead of apps having multiple implementations (e.g., AGS) . '\n",
      "           'This PR is meant to start a design conversation around this.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This PR does the following:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- Inherits from BaseChatAgent \\r\\n'\n",
      "           '- Takes in an `input_func` in constructor that defaults to console '\n",
      "           '`input` if nothing is passed. \\r\\n'\n",
      "           '- `input_func` gets called when the UserProxyAgent gets a message, '\n",
      "           'and returns a string\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           '# defaults to built-in input\\r\\n'\n",
      "           'user_proxy = UserProxyAgent(name=\"user_agent\")\\r\\n'\n",
      "           'result =  await user_proxy.run(task=\"what is the height of the '\n",
      "           'eiffel tower\")\\r\\n'\n",
      "           'print(result.messages[-1].content\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'Stuff entered by the user\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '----\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           '# uses a custom input function (could stream to a websocket)\\r\\n'\n",
      "           'def input_fn(input_text: str) -> str:\\r\\n'\n",
      "           '    return \"The height of the eiffel tower is 324 meters. '\n",
      "           'Aloha!\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'user_proxy = UserProxyAgent(name=\"user_agent\", '\n",
      "           'input_func=input_fn)\\r\\n'\n",
      "           'result =  await user_proxy.run(task=\"what is the height of the '\n",
      "           'eiffel tower\")\\r\\n'\n",
      "           'print(result.messages[-1].content)\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'The height of the eiffel tower is 324 meters. Aloha!\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'To be done:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           ' \\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x] Handling handoff message (or other message types)\\r\\n'\n",
      "           '- [x] Adding tests \\r\\n'\n",
      "           '- [x] Pass cancellation token to input func  , \\r\\n'\n",
      "           '- [x] Should input_func get a list of all messages? - No\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Why are these changes needed?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please give a short summary of the change and the problem '\n",
      "           'this solves. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Provide some standard/guidance around creating a  '\n",
      "           'UserProxyAgent.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Related issue number\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- For example: \"Closes #1234\" -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Related to #3614\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Checks\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"- [ ] I've included any doc changes needed for \"\n",
      "           'https://microsoft.github.io/autogen/. See '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute#documentation '\n",
      "           'to build and test documentation locally.\\r\\n'\n",
      "           \"- [ ] I've added tests (if relevant) corresponding to the changes \"\n",
      "           'introduced in this PR.\\r\\n'\n",
      "           \"- [ ] I've made sure all auto checks have passed.\\r\\n\",\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T16:50:30Z',\n",
      "  '_issueNumber': '4255',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Add UserProxyAgent in AgentChat API',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '<!-- Thank you for your contribution! Please review '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute before opening '\n",
      "           'a pull request. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please add a reviewer to the assignee section when you create '\n",
      "           \"a PR. If you don't have the access to it, we will shortly find a \"\n",
      "           'reviewer and assign them to your PR. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Why are these changes needed?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Seems `_kwargs.update(kwargs)` will cause errors when using the '\n",
      "           'Azure OpenAI service. It forces the model set in the environment '\n",
      "           'to change to \"gpt-4o\", which can cause issues (e.g., `The API '\n",
      "           'deployment for this resource does not exist.`) in Azure. \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'The model name in Azure can be customized. For example, I created '\n",
      "           'a model based on gpt-4o, and its name is `my-gpt-4o` that should '\n",
      "           'be used in the API call. If we use `gpt-4o` as model in the '\n",
      "           'completion API call, the error will occur.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Note** I tested the code with the Azure OpenAI service, but I '\n",
      "           \"haven't had a chance to run it with OpenAI. Please double-check \"\n",
      "           'it.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Related issue number\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- For example: \"Closes #1234\" -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Checks\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"- [ ] I've included any doc changes needed for \"\n",
      "           'https://microsoft.github.io/autogen/. See '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute#documentation '\n",
      "           'to build and test documentation locally.\\r\\n'\n",
      "           \"- [ ] I've added tests (if relevant) corresponding to the changes \"\n",
      "           'introduced in this PR.\\r\\n'\n",
      "           \"- [ ] I've made sure all auto checks have passed.\\r\\n\",\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T15:01:02Z',\n",
      "  '_issueNumber': '4254',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Update utils.py- Fix error when using AzureOpenAI services',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Add more information about using Azure OpenAI services\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Thank you for your contribution! Please review '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute before opening '\n",
      "           'a pull request. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please add a reviewer to the assignee section when you create '\n",
      "           \"a PR. If you don't have the access to it, we will shortly find a \"\n",
      "           'reviewer and assign them to your PR. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Why are these changes needed?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please give a short summary of the change and the problem '\n",
      "           'this solves. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Related issue number\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- For example: \"Closes #1234\" -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Checks\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"- [ ] I've included any doc changes needed for \"\n",
      "           'https://microsoft.github.io/autogen/. See '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute#documentation '\n",
      "           'to build and test documentation locally.\\r\\n'\n",
      "           \"- [ ] I've added tests (if relevant) corresponding to the changes \"\n",
      "           'introduced in this PR.\\r\\n'\n",
      "           \"- [x] I've made sure all auto checks have passed.\\r\\n\",\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T13:25:55Z',\n",
      "  '_issueNumber': '4253',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Update README.md - add more information about using Azure OpenAI '\n",
      "            'services',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What feature would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'Create or expose API for observing all flowing message from  '\n",
      "           '`Microsoft.AutoGen.Agents.Client`\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           'Good for test/hybrid usage case.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-17T16:24:40Z',\n",
      "  '_issueNumber': '4248',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': '[.NET] expose API for observing messages from '\n",
      "            '`Microsoft.AutoGen.Agents.Client`',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What feature would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'accept `object` message type in `AgentBase.PublishEventAsync` \\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           '`AgentBase.PublishEventAsync` requires the input message to be '\n",
      "           'protobuf `IMessage`. If we can figure out a way to support '\n",
      "           '`object` message type, we can make protobuf an optional config for '\n",
      "           'in-memory use case.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-17T16:23:09Z',\n",
      "  '_issueNumber': '4247',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': '[.NET] Support `object` message type in '\n",
      "            '`AgentBase.PublishEventAsync`',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'AGS currently has support for AssistantAgent agent and '\n",
      "           'RoundRobin/LLM Selector teams from AgentChat.\\n'\n",
      "           'As developers experiment with new types of custom agents and '\n",
      "           'teams, we will need clear documentation on how to support these '\n",
      "           'new agent types in AGS.\\n'\n",
      "           '\\n'\n",
      "           'Current approach \\n'\n",
      "           '\\n'\n",
      "           '- Define your new agents and teams, add them to '\n",
      "           'autogenstudio.components\\n'\n",
      "           '- Update datamodel AgentTypes and TeamTypes to include new  '\n",
      "           '[datamodel](https://github.com/microsoft/autogen/blob/main/python/packages/autogen-studio/autogenstudio/datamodel/types.py) '\n",
      "           '. Add new AgentConfig that extends `AgentConfig`.\\n'\n",
      "           '\\n'\n",
      "           '```python\\n'\n",
      "           'class AgentTypes(str, Enum):\\n'\n",
      "           '    ASSISTANT = \"AssistantAgent\"\\n'\n",
      "           '    USERPROXY = \"UserProxyAgent\" \\n'\n",
      "           '+  CUSTOMWEBSURFER=\"CustomWebSurfer\" # your new agent\\n'\n",
      "           '```\\n'\n",
      "           '- Update '\n",
      "           '[ComponentFactory](https://github.com/microsoft/autogen/blob/main/python/packages/autogen-studio/autogenstudio/database/component_factory.py) '\n",
      "           'to include logic on how to instantiate new custom agent \\n'\n",
      "           '- Update tests \\n'\n",
      "           '\\n'\n",
      "           'In the future, it would be great to figure out something more '\n",
      "           'automatic. \\n'\n",
      "           'E.g., add type definitions and class to some directory and logic '\n",
      "           'to load is inferred.\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-17T00:55:57Z',\n",
      "  '_issueNumber': '4242',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Document process for supporting new types of Agents and Teams in '\n",
      "            'AGS',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'For example: \\n'\n",
      "           '\\n'\n",
      "           '1. Agent runtime listing all registered agent types and their '\n",
      "           'subscriptions.\\n'\n",
      "           '2. Find agent by regular expression.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-16T23:26:01Z',\n",
      "  '_issueNumber': '4241',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Agent runtime to support agent discovery',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What happened?\\n'\n",
      "           '\\n'\n",
      "           \"Hi, I've recently noticed that when I asked Magentic One to scrape \"\n",
      "           'the dynamic content on the certain page where the context is being '\n",
      "           'loaded dynamically by scrolling down. The `Coder` agent has '\n",
      "           \"written the code that uses **Selenium** and I didn't have it \"\n",
      "           'installed before running the script, so when `Executor` agent '\n",
      "           'tried to execute the code, it failed due to \"**missing modules**\" '\n",
      "           'such as `selenium` and `webdriver-manager` based on the . \\n'\n",
      "           'I got into a loop where the AI-Agent tried to install the '\n",
      "           'necessary modules, but it constantly failed and therefore attempts '\n",
      "           'of executing code were pointless.\\n'\n",
      "           '\\n'\n",
      "           '### What did you expect to happen?\\n'\n",
      "           '\\n'\n",
      "           'I expected `Executor` to install dependencies that were identified '\n",
      "           'as missing into an active virtual environment to fulfill my '\n",
      "           'query. \\n'\n",
      "           '\\n'\n",
      "           '### How can we reproduce it (as minimally and precisely as '\n",
      "           'possible)?\\n'\n",
      "           '\\n'\n",
      "           'To reproduce the issue, I am talking about, please follow the '\n",
      "           'steps below:\\n'\n",
      "           '\\n'\n",
      "           '1. Run the example with human-in-the-loop mode: `python '\n",
      "           'examples/example.py --logs_dir ./logs --hil_mode`\\n'\n",
      "           '2. Use the next prompt: `Your task is to scrape all the '\n",
      "           'submissions card titles on this page: [[3D Chess Design '\n",
      "           'Contest](https://www.tripo3d.ai/event/3d-chess-contest#submissions)](https://www.tripo3d.ai/event/3d-chess-contest#submissions). '\n",
      "           'Note: the new submissions are loaded dynamically, so you need to '\n",
      "           'first scroll up to down of the page and only then scrape the data '\n",
      "           'or do it dynamically, up to you (decide what’s easier and more '\n",
      "           'efficient).You need to provide me with a full list of scraped '\n",
      "           'submissions card titles.`\\n'\n",
      "           '3. Observe the `Coder` agent writes the code in Selenium\\n'\n",
      "           '4. Watch the `Executor` tries to execute the code that uses '\n",
      "           'external modules and returns errors if any are missing\\n'\n",
      "           '\\n'\n",
      "           '### AutoGen version\\n'\n",
      "           '\\n'\n",
      "           '0.2.38\\n'\n",
      "           '\\n'\n",
      "           '### Which package was this bug in\\n'\n",
      "           '\\n'\n",
      "           'Magentic One\\n'\n",
      "           '\\n'\n",
      "           '### Model used\\n'\n",
      "           '\\n'\n",
      "           'gpt-4o\\n'\n",
      "           '\\n'\n",
      "           '### Python version\\n'\n",
      "           '\\n'\n",
      "           '3.12\\n'\n",
      "           '\\n'\n",
      "           '### Operating system\\n'\n",
      "           '\\n'\n",
      "           'Windows 11\\n'\n",
      "           '\\n'\n",
      "           '### Any additional info you think would be helpful for fixing this '\n",
      "           'bug\\n'\n",
      "           '\\n'\n",
      "           'I have attached the full logs copied from the terminal, so you can '\n",
      "           'understand the situation better and perhaps help me resolve the '\n",
      "           \"issue with AI-Agent isn't installing modules. [Failed to install \"\n",
      "           'missing modules logs '\n",
      "           'file](https://github.com/user-attachments/files/17788173/failing-to-install-modules-logs-magentic-one.txt)\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-16T22:47:17Z',\n",
      "  '_issueNumber': '4240',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': '\"Executor\" agent isn\\'t installing missing modules - Magentic One',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### What happened?\\n'\n",
      "           '\\n'\n",
      "           'When I try to launch motebook form '\n",
      "           '`notebook/autobuild_agent_library.ipynb`\\n'\n",
      "           'Part of code:\\n'\n",
      "           '```\\n'\n",
      "           ' agent_list, _ = new_builder.build_from_library(building_task, '\n",
      "           'library_path_or_json, llm_config)\\n'\n",
      "           '```\\n'\n",
      "           'Return error code:\\n'\n",
      "           '```\\n'\n",
      "           'Expecting value: line 1 column 1 (char 0)\\n'\n",
      "           '```\\n'\n",
      "           'Associated with the use of json.loads function in '\n",
      "           '`build_from_library` function\\n'\n",
      "           'and the use of code below to generate json file\\n'\n",
      "           '\\n'\n",
      "           '```\\n'\n",
      "           'json.dumps(sys_msg_list, open(\"./agent_library_example.json\", '\n",
      "           '\"w\"), indent=4)\\n'\n",
      "           'library_path_or_json = \"./agent_library_example.json\"\\n'\n",
      "           '\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### What did you expect to happen?\\n'\n",
      "           '\\n'\n",
      "           'What is the right way to call `agent_builder.build_from_library` '\n",
      "           'function\\n'\n",
      "           'which type of json format?\\n'\n",
      "           'Section\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### How can we reproduce it (as minimally and precisely as '\n",
      "           'possible)?\\n'\n",
      "           '\\n'\n",
      "           'My code:\\n'\n",
      "           '\\n'\n",
      "           '```\\n'\n",
      "           'import json\\n'\n",
      "           'import autogen\\n'\n",
      "           'from autogen.agentchat.contrib.agent_builder import AgentBuilder\\n'\n",
      "           'from autogen import ConversableAgent, UserProxyAgent\\n'\n",
      "           '\\n'\n",
      "           'config_file_or_env = \"OAI_CONFIG_LIST.json\"\\n'\n",
      "           'llm_config = {\"temperature\": 0}\\n'\n",
      "           'config_list = autogen.config_list_from_json(config_file_or_env, '\n",
      "           'filter_dict={\"model\": [\"llama3.2\"]})\\n'\n",
      "           '\\n'\n",
      "           'def start_task(execution_task: str, agent_list: list):\\n'\n",
      "           '    group_chat = autogen.GroupChat(agents=agent_list, messages=[], '\n",
      "           'max_round=12)\\n'\n",
      "           '    manager = autogen.GroupChatManager(groupchat=group_chat, '\n",
      "           'llm_config={\"config_list\": config_list, **llm_config})\\n'\n",
      "           '    agent_list[0].initiate_chat(manager, message=execution_task)\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'AGENT_SYS_MSG_PROMPT = \"\"\"Acccording to the following postion '\n",
      "           'name, write a high quality instruction for the position following '\n",
      "           'a given example. You should only return the instruction.\\n'\n",
      "           '\\n'\n",
      "           '# Position Name\\n'\n",
      "           '{position}\\n'\n",
      "           '\\n'\n",
      "           '# Example instruction for Data Analyst\\n'\n",
      "           '\\n'\n",
      "           'As Data Analyst, you are tasked with leveraging your extensive '\n",
      "           'knowledge in data analysis to recognize and extract meaningful '\n",
      "           'features from vast datasets. Your expertise in machine learning, '\n",
      "           'specifically with the Random Forest Classifier, allows you to '\n",
      "           'construct robust predictive models adept at handling both '\n",
      "           'classification and regression tasks. You excel in model evaluation '\n",
      "           'and interpretation, ensuring that the performance of your '\n",
      "           'algorithms is not just assessed with precision, but also '\n",
      "           'understood in the context of the data and the problem at hand. '\n",
      "           'With a command over Python and proficiency in using the pandas '\n",
      "           'library, you manipulate and preprocess data with ease.\\n'\n",
      "           '\"\"\"\\n'\n",
      "           '\\n'\n",
      "           'AGENT_DESC_PROMPT = \"\"\"According to position name and the '\n",
      "           'instruction, summarize the position into a high quality one '\n",
      "           'sentence description.\\n'\n",
      "           '\\n'\n",
      "           '# Position Name\\n'\n",
      "           '{position}\\n'\n",
      "           '\\n'\n",
      "           '# Instruction\\n'\n",
      "           '{instruction}\\n'\n",
      "           '\"\"\"\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'position_list = [\\n'\n",
      "           '    \"Environmental_Scientist\",\\n'\n",
      "           '    \"Astronomer\",\\n'\n",
      "           '    \"Software_Developer\",\\n'\n",
      "           '    \"Data_Analyst\",\\n'\n",
      "           '    \"Journalist\",\\n'\n",
      "           '    \"Teacher\",\\n'\n",
      "           '    \"Lawyer\",\\n'\n",
      "           '    \"Programmer\",\\n'\n",
      "           '    \"Accountant\",\\n'\n",
      "           '    \"Mathematician\",\\n'\n",
      "           '    \"Physicist\",\\n'\n",
      "           '    \"Biologist\",\\n'\n",
      "           '    \"Chemist\",\\n'\n",
      "           '    \"Statistician\",\\n'\n",
      "           '    \"IT_Specialist\",\\n'\n",
      "           '    \"Cybersecurity_Expert\",\\n'\n",
      "           '    \"Artificial_Intelligence_Engineer\",\\n'\n",
      "           '    \"Financial_Analyst\",\\n'\n",
      "           '    ]\\n'\n",
      "           '\\n'\n",
      "           'build_manager = autogen.OpenAIWrapper(config_list=config_list)\\n'\n",
      "           'sys_msg_list = []\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'for pos in position_list:\\n'\n",
      "           '    resp_agent_sys_msg = (\\n'\n",
      "           '        build_manager.create(\\n'\n",
      "           '            messages=[\\n'\n",
      "           '                {\\n'\n",
      "           '                    \"role\": \"user\",\\n'\n",
      "           '                    \"content\": AGENT_SYS_MSG_PROMPT.format(\\n'\n",
      "           '                        position=pos,\\n'\n",
      "           '                    ),\\n'\n",
      "           '                }\\n'\n",
      "           '            ]\\n'\n",
      "           '        )\\n'\n",
      "           '        .choices[0]\\n'\n",
      "           '        .message.content\\n'\n",
      "           '    )\\n'\n",
      "           '    resp_desc_msg = (\\n'\n",
      "           '        build_manager.create(\\n'\n",
      "           '            messages=[\\n'\n",
      "           '                {\\n'\n",
      "           '                    \"role\": \"user\",\\n'\n",
      "           '                    \"content\": AGENT_DESC_PROMPT.format(\\n'\n",
      "           '                        position=pos,\\n'\n",
      "           '                        instruction=resp_agent_sys_msg,\\n'\n",
      "           '                    ),\\n'\n",
      "           '                }\\n'\n",
      "           '            ]\\n'\n",
      "           '        )\\n'\n",
      "           '        .choices[0]\\n'\n",
      "           '        .message.content\\n'\n",
      "           '    )\\n'\n",
      "           '    sys_msg_list.append({\"name\": pos, \"system_message\": '\n",
      "           'resp_agent_sys_msg, \"description\": resp_desc_msg})\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'json.dump(sys_msg_list, open(\"./agent_library_example.json\", \"w\"), '\n",
      "           'indent=4)\\n'\n",
      "           '\\n'\n",
      "           'library_path_or_json = \"./agent_library_example.json\"\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'building_task = \"Find a paper on arxiv by programming, and analyze '\n",
      "           'its application in some domain. For example, find a recent paper '\n",
      "           'about gpt-4 on arxiv and find its potential applications in '\n",
      "           'software.\"\\n'\n",
      "           '\\n'\n",
      "           'new_builder = AgentBuilder(config_file_or_env=config_file_or_env, '\n",
      "           'builder_model=\"llama3.2\", agent_model=\"llama3.2\")\\n'\n",
      "           'agent_list, _ = new_builder.build_from_library(building_task, '\n",
      "           'library_path_or_json, llm_config)\\n'\n",
      "           '\\n'\n",
      "           'start_task(\\n'\n",
      "           '    execution_task=\"Find a recent paper about explainable AI on '\n",
      "           'arxiv and find its potential applications in medical.\",\\n'\n",
      "           '    agent_list=agent_list,\\n'\n",
      "           ')\\n'\n",
      "           'new_builder.clear_all_agents()\\n'\n",
      "           '\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### AutoGen version\\n'\n",
      "           '\\n'\n",
      "           'autogen==0.3.2 autogen-agentchat==0.2.38 autogenstudio==0.1.5 '\n",
      "           'pyautogen==0.3.2\\n'\n",
      "           '\\n'\n",
      "           '### Which package was this bug in\\n'\n",
      "           '\\n'\n",
      "           'AgentChat\\n'\n",
      "           '\\n'\n",
      "           '### Model used\\n'\n",
      "           '\\n'\n",
      "           'llama3.2\\n'\n",
      "           '\\n'\n",
      "           '### Python version\\n'\n",
      "           '\\n'\n",
      "           '3.10\\n'\n",
      "           '\\n'\n",
      "           '### Operating system\\n'\n",
      "           '\\n'\n",
      "           'ubuntu\\n'\n",
      "           '\\n'\n",
      "           '### Any additional info you think would be helpful for fixing this '\n",
      "           'bug\\n'\n",
      "           '\\n'\n",
      "           '_No respons',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-16T14:59:51Z',\n",
      "  '_issueNumber': '4235',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'autobuild_agent_library.ipynb return Expecting value: line 1 '\n",
      "            'column 1 (char 0)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '<!-- Thank you for your contribution! Please review '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute before opening '\n",
      "           'a pull request. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please add a reviewer to the assignee section when you create '\n",
      "           \"a PR. If you don't have the access to it, we will shortly find a \"\n",
      "           'reviewer and assign them to your PR. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Why are these changes needed?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- Please give a short summary of the change and the problem '\n",
      "           'this solves. -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Related issue number\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '<!-- For example: \"Closes #1234\" -->\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Checks\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"- [ ] I've included any doc changes needed for \"\n",
      "           'https://microsoft.github.io/autogen/. See '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute#documentation '\n",
      "           'to build and test documentation locally.\\r\\n'\n",
      "           \"- [ ] I've added tests (if relevant) corresponding to the changes \"\n",
      "           'introduced in this PR.\\r\\n'\n",
      "           \"- [ ] I've made sure all auto checks have passed.\\r\\n\",\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T21:34:21Z',\n",
      "  '_issueNumber': '4226',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': '[WIP] Dynamically generate agent systems in AutoGen',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Why are these changes needed?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Add tests for python protobuf serialization\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Related issue number\\r\\n'\n",
      "           'https://github.com/microsoft/autogen/issues/3643\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Checks\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"- [ ] I've included any doc changes needed for \"\n",
      "           'https://microsoft.github.io/autogen/. See '\n",
      "           'https://microsoft.github.io/autogen/docs/Contribute#documentation '\n",
      "           'to build and test documentation locally.\\r\\n'\n",
      "           \"- [ ] I've added tests (if relevant) corresponding to the changes \"\n",
      "           'introduced in this PR.\\r\\n'\n",
      "           \"- [ ] I've made sure all auto checks have passed.\\r\\n\",\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T19:32:14Z',\n",
      "  '_issueNumber': '4224',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'add protobuf serialization test',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'As users experiment, it is frequently useful to do the following \\n'\n",
      "           '\\n'\n",
      "           '- [ ] Save and reload session (not implemented yet) \\n'\n",
      "           '- [ ] Explicitly \"share\" a session (either via a download or '\n",
      "           'link)\\n'\n",
      "           '- [ ] Include snapshot of session with full team config full '\n",
      "           'observability (what configuration led to that specific outcome)\\n'\n",
      "           '\\n'\n",
      "           'Notes:  All messages have a run_id,  All runs have a session_id  \\n'\n",
      "           '\\n'\n",
      "           '## How \\n'\n",
      "           '- Load session\\n'\n",
      "           '  - Load all runs \\n'\n",
      "           '  - Show messages (.. refactor ChatView and MessageList component '\n",
      "           'such that it can take a list of runs and messages )\\n'\n",
      "           '- Add to Gallery\\n'\n",
      "           ' - Creates gallery entry with sessionid and \\n'\n",
      "           ' - UI Gallery view visualizes session but with input disabled.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T16:59:21Z',\n",
      "  '_issueNumber': '4222',\n",
      "  '_repo': 'autogen',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Support the ability to  to save and review \"sessions\" in AGS',\n",
      "  '_type': 'issue'}]\n",
      "Fetching issues from: https://api.github.com/repos/openai/openai-cookbook/issues\n",
      "[{'_body': '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Briefly describe the changes and the goal of this PR. Make sure '\n",
      "           'the PR title summarizes the changes effectively.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Why are these changes necessary? How do they improve the '\n",
      "           'cookbook?\\r\\n'\n",
      "           'The notebook demonstrates how to optimize travel routes for '\n",
      "           \"multiple users using OpenAI's GPT-4 model. The optimized routes \"\n",
      "           'are then visualized on interactive maps using Folium and geocoded '\n",
      "           'using the Geopy library.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## For new content\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'When contributing new content, read through our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md), '\n",
      "           'and mark the following action items as completed:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [ ] I have added a new entry in '\n",
      "           '[registry.yaml](https://github.com/openai/openai-cookbook/blob/main/registry.yaml) '\n",
      "           '(and, optionally, in '\n",
      "           '[authors.yaml](https://github.com/openai/openai-cookbook/blob/main/authors.yaml)) '\n",
      "           'so that my content renders on the cookbook website.\\r\\n'\n",
      "           '- [ ] I have conducted a self-review of my content based on the '\n",
      "           '[contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md#rubric):\\r\\n'\n",
      "           '  - [ ] Relevance: This content is related to building with OpenAI '\n",
      "           'technologies and is useful to others.\\r\\n'\n",
      "           '  - [ ] Uniqueness: I have searched for related examples in the '\n",
      "           'OpenAI Cookbook, and verified that my content offers new insights '\n",
      "           'or unique information compared to existing documentation.\\r\\n'\n",
      "           '  - [ ] Spelling and Grammar: I have checked for spelling or '\n",
      "           'grammatical mistakes.\\r\\n'\n",
      "           '  - [ ] Clarity: I have done a final read-through and verified '\n",
      "           'that my submission is well-organized and easy to understand.\\r\\n'\n",
      "           '  - [ ] Correctness: The information I include is correct and all '\n",
      "           'of my code executes successfully.\\r\\n'\n",
      "           '  - [ ] Completeness: I have explained everything fully, including '\n",
      "           'all necessary references and citations.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'We will rate each of these areas on a scale from 1 to 4, and will '\n",
      "           'only accept contributions that score 3 or higher on all areas. '\n",
      "           'Refer to our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md) '\n",
      "           'for more details.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T03:43:14Z',\n",
      "  '_issueNumber': '1572',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Route optimization use case with GPT-4o',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '**Please do not use the issues page to ask general questions about '\n",
      "           'the OpenAI API.** Questions asked here will usually not receive '\n",
      "           'answers.\\n'\n",
      "           '\\n'\n",
      "           'Feel free to report problems with code examples, suggest new code '\n",
      "           'examples, or ask narrow questions about specific code examples.\\n'\n",
      "           '\\n'\n",
      "           'For general discussion, try:\\n'\n",
      "           '\\n'\n",
      "           '- [OpenAI API Community Forum](https://community.openai.com/)\\n'\n",
      "           '- [OpenAI Discord](https://discord.com/invite/openai)\\n'\n",
      "           '- [OpenAI subreddit](https://www.reddit.com/r/OpenAI/), [GPT3 '\n",
      "           'subreddit](https://www.reddit.com/r/GPT3/)\\n'\n",
      "           '- [OpenAI Cookbook discussion '\n",
      "           'page](https://github.com/openai/openai-cookbook/discussions)\\n'\n",
      "           '\\n'\n",
      "           'For general help, try:\\n'\n",
      "           '\\n'\n",
      "           '- [OpenAI '\n",
      "           'Documentation](https://platform.openai.com/docs/introduction)\\n'\n",
      "           '- [OpenAI Help Center](https://help.openai.com/en/)',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T01:28:02Z',\n",
      "  '_issueNumber': '1571',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[SUPPORT]',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional template]\\n'\n",
      "           '\\n'\n",
      "           '**Is your feature request related to a problem? Please '\n",
      "           'describe.**\\n'\n",
      "           \"A clear and concise description of what the problem is. Ex. I'm \"\n",
      "           'always frustrated when [...]\\n'\n",
      "           '\\n'\n",
      "           \"**Describe the solution you'd like**\\n\"\n",
      "           'A clear and concise description of what you want to happen.\\n'\n",
      "           '\\n'\n",
      "           '**Additional context**\\n'\n",
      "           'Add any other context or screenshots about the feature request '\n",
      "           'here.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T01:27:11Z',\n",
      "  '_issueNumber': '1570',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[FEATURE]',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional format]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Identify the file to be fixed**\\r\\n'\n",
      "           'Not being able to retrive the results\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Describe the problem**\\r\\n'\n",
      "           'I am not able to retrive the results after finishing the job\\r\\n'\n",
      "           '<img width=\"488\" alt=\"Screenshot 2024-11-19 at 17 12 53\" '\n",
      "           'src=\"https://github.com/user-attachments/assets/646015f3-f14e-44b1-bb64-77a7363f4394\">\\r\\n'\n",
      "           ', since the default batch_job.output_file_id is None. Here: '\n",
      "           'examples/batch_processing.ipynb\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Describe a solution**\\r\\n'\n",
      "           'Give a way to set the batch_job.output_file_id\\r\\n'\n",
      "           '\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T10:05:54Z',\n",
      "  '_issueNumber': '1564',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[PROBLEM] Retriving the results Batch API',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'I am trying to upload an image to get response from the openAI '\n",
      "           'using its API but the response says, i am unable to process '\n",
      "           'images.\\r\\n'\n",
      "           'my code:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'const completion = await openai.chat.completions.create({\\r\\n'\n",
      "           '      model: \"gpt-4o\",\\r\\n'\n",
      "           'messages: [\\r\\n'\n",
      "           '        {\\r\\n'\n",
      "           '          role: \"system\",\\r\\n'\n",
      "           '          content: \"You are a helpful assistant, i am sharing an '\n",
      "           'image with you please give me the solution for this math '\n",
      "           'problem.\",\\r\\n'\n",
      "           '        },\\r\\n'\n",
      "           '        {\\r\\n'\n",
      "           '          role: \"user\",\\r\\n'\n",
      "           '          content: JSON.stringify({\\r\\n'\n",
      "           '            type: \"image_url\",\\r\\n'\n",
      "           '            image_url: '\n",
      "           '\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\\r\\n'\n",
      "           '          }),\\r\\n'\n",
      "           '        },\\r\\n'\n",
      "           '      ],\\r\\n'\n",
      "           '    });\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Response (Postman):\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '{\\r\\n'\n",
      "           '    \"data\": {\\r\\n'\n",
      "           '        \"role\": \"assistant\",\\r\\n'\n",
      "           '        \"content\": \"I\\'m sorry, but as a text-based AI, I\\'m '\n",
      "           'unable to view or interpret images. However, if you describe the '\n",
      "           \"math problem to me or type it out, I'd be more than happy to \"\n",
      "           'assist you in solving it.\",\\r\\n'\n",
      "           '        \"refusal\": null\\r\\n'\n",
      "           '    },\\r\\n'\n",
      "           '    \"message\": \"Success\",\\r\\n'\n",
      "           '    \"success\": true\\r\\n'\n",
      "           '}\\r\\n'\n",
      "           '```',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-18T10:36:51Z',\n",
      "  '_issueNumber': '1562',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'openAI API not supporting Image processing',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '**for example**\\r\\n'\n",
      "           '<img width=\"362\" alt=\"屏幕截图 2024-11-06 222409\" '\n",
      "           'src=\"https://github.com/user-attachments/assets/edebc88f-65c7-42ad-be7c-45b4843e1256\">\\r\\n'\n",
      "           'now i can‘t use these code to obtain the log probability of each '\n",
      "           'token.\\r\\n'\n",
      "           '\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-06T14:39:32Z',\n",
      "  '_issueNumber': '1555',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[PROBLEM]I want to obtain the log probability of each token in a '\n",
      "            'given input text using GPT-3.5，but It appears that OpenAI has now '\n",
      "            'limited or removed this feature.',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional format]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Identify the file to be fixed**\\r\\n'\n",
      "           '[The name of the file containing the problem '\n",
      "           'https://github.com/openai/swarm/blob/main/swarm/core.py](https://github.com/openai/swarm/blob/main/swarm/core.py) \\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Describe the problem**\\r\\n'\n",
      "           'On line 158\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"'sender': agent.name\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           'should be\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"'sender': active_agent.name\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '**Describe a solution**\\r\\n'\n",
      "           'A clear and concise description of what a fixed version should '\n",
      "           'do.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Screenshots**\\r\\n'\n",
      "           'If applicable, add screenshots to help explain your problem.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Additional context**\\r\\n'\n",
      "           'Add any other context about the problem here.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-06T09:02:00Z',\n",
      "  '_issueNumber': '1553',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[PROBLEM] https://github.com/openai/swarm/blob/main/swarm/core.py',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-04T11:27:15Z',\n",
      "  '_issueNumber': '1552',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Will Sam release o1 model in november 2024?',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional template]\\n'\n",
      "           '\\n'\n",
      "           '**Is your feature request related to a problem? Please '\n",
      "           'describe.**\\n'\n",
      "           \"A clear and concise description of what the problem is. Ex. I'm \"\n",
      "           'always frustrated when [...]\\n'\n",
      "           '\\n'\n",
      "           \"**Describe the solution you'd like**\\n\"\n",
      "           'A clear and concise description of what you want to happen.\\n'\n",
      "           '\\n'\n",
      "           '**Additional context**\\n'\n",
      "           'Add any other context or screenshots about the feature request '\n",
      "           'here.\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-02T09:11:34Z',\n",
      "  '_issueNumber': '1551',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[FEATURE] web5tbdex',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '**Identify the file to be fixed**\\r\\n'\n",
      "           '[examples](https://github.com/openai/openai-cookbook/tree/main/examples)\\r\\n'\n",
      "           '/Chat_finetuning_data_prep.ipynb\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Describe the problem**\\r\\n'\n",
      "           'Through new things like vision fine-tuning and tool-calls instead '\n",
      "           'of function calls, the validator that one builds in this cookbook '\n",
      "           'is insufficient to check for .jsonl-File validity. Moreover, there '\n",
      "           'seems to be no good resource on all things that invalidate '\n",
      "           'training data. This info is still available in a tedious form, as '\n",
      "           'the fine tuning playground will explain each error to the user.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Describe a solution**\\r\\n'\n",
      "           'Update this cookbook to include, ideally, the same checks that the '\n",
      "           'playground performs. It would be helpful so that users can test '\n",
      "           'their jsonl-Files without uploading them.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-01T18:33:40Z',\n",
      "  '_issueNumber': '1549',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[PROBLEM] Update fine tuning data validation example',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Migrate Milvus database interaction from a low-level ORM SDK to '\n",
      "           'the higher-level MilvusClient SDK. The goal is to streamline '\n",
      "           'operations, improve code readability, and simplify maintenance by '\n",
      "           \"utilizing MilvusClient's higher-level abstractions.\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'The changes in this PR make our codebase more efficient and reduce '\n",
      "           'complexity by switching to MilvusClient. This transition enables '\n",
      "           'us to streamline the embedding and querying process for datasets '\n",
      "           'such as movie descriptions (with metadata filtering) and book '\n",
      "           'descriptions (simple retrieval), aligning our codebase with '\n",
      "           'current best practices and making it easier for developers to '\n",
      "           'extend and maintain.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Getting Started with Milvus and OpenAI: Introduces the use of '\n",
      "           'Milvus for embedding-based search on book descriptions, embedding '\n",
      "           'the descriptions with OpenAI and storing them for retrieval in '\n",
      "           'Milvus.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Filtered Search with Milvus and OpenAI: Demonstrates how to use '\n",
      "           'Milvus for vector similarity search on movie descriptions, '\n",
      "           \"utilizing OpenAI embeddings and Milvus's filtering \"\n",
      "           'capabilities.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## For new content\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'When contributing new content, read through our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md), '\n",
      "           'and mark the following action items as completed:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [ ✅ ] I have added a new entry in '\n",
      "           '[registry.yaml](https://github.com/openai/openai-cookbook/blob/main/registry.yaml) '\n",
      "           '(and, optionally, in '\n",
      "           '[authors.yaml](https://github.com/openai/openai-cookbook/blob/main/authors.yaml)) '\n",
      "           'so that my content renders on the cookbook website.\\r\\n'\n",
      "           '- [ ✅ ] I have conducted a self-review of my content based on the '\n",
      "           '[contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md#rubric):\\r\\n'\n",
      "           '  - [ ✅ ] Relevance: This content is related to building with '\n",
      "           'OpenAI technologies and is useful to others.\\r\\n'\n",
      "           '  - [ ✅ ] Uniqueness: I have searched for related examples in the '\n",
      "           'OpenAI Cookbook, and verified that my content offers new insights '\n",
      "           'or unique information compared to existing documentation.\\r\\n'\n",
      "           '  - [ ✅ ] Spelling and Grammar: I have checked for spelling or '\n",
      "           'grammatical mistakes.\\r\\n'\n",
      "           '  - [ ✅ ] Clarity: I have done a final read-through and verified '\n",
      "           'that my submission is well-organized and easy to understand.\\r\\n'\n",
      "           '  - [ ✅ ] Correctness: The information I include is correct and '\n",
      "           'all of my code executes successfully.\\r\\n'\n",
      "           '  - [ ✅ ] Completeness: I have explained everything fully, '\n",
      "           'including all necessary references and citations.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'We will rate each of these areas on a scale from 1 to 4, and will '\n",
      "           'only accept contributions that score 3 or higher on all areas. '\n",
      "           'Refer to our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md) '\n",
      "           'for more details.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-01T14:35:48Z',\n",
      "  '_issueNumber': '1548',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Vector Databse Milvus Tutorial Migrated to Higher-Level '\n",
      "            'MilvusClient SDK',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-01T13:22:28Z',\n",
      "  '_issueNumber': '1546',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '\\nWeb6g\\n',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional template]\\n'\n",
      "           '\\n'\n",
      "           '**Is your feature request related to a problem? Please '\n",
      "           'describe.**\\n'\n",
      "           \"A clear and concise description of what the problem is. Ex. I'm \"\n",
      "           'always frustrated when [...]\\n'\n",
      "           '\\n'\n",
      "           \"**Describe the solution you'd like**\\n\"\n",
      "           'A clear and concise description of what you want to happen.\\n'\n",
      "           '\\n'\n",
      "           '**Additional context**\\n'\n",
      "           'Add any other context or screenshots about the feature request '\n",
      "           'here.\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-01T03:45:03Z',\n",
      "  '_issueNumber': '1545',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[FEATURE]',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Description\\r\\n'\n",
      "           'Fixed a typo in the documentation where \"indate\" was incorrectly '\n",
      "           'used instead of \"indicate\". This change improves readability and '\n",
      "           'maintains professional documentation standards.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Summary\\r\\n'\n",
      "           'Fix typo: Change \"indate\" to \"indicate\" in the documentation.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           'This change corrects a spelling error to improve code '\n",
      "           'documentation clarity and readability. Clear documentation helps '\n",
      "           'reduce confusion for developers using the cookbook.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '## For new content\\r\\n'\n",
      "           'Since this is a minor typo fix rather than new content, the new '\n",
      "           'content checklist is not applicable. However, I have reviewed the '\n",
      "           'change for:\\r\\n'\n",
      "           '- [x] Spelling and Grammar: Corrected the misspelling of '\n",
      "           '\"indicate\"\\r\\n'\n",
      "           '- [x] Clarity: The fix improves document clarity\\r\\n'\n",
      "           '- [x] Correctness: The corrected spelling is accurate\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-31T19:07:56Z',\n",
      "  '_issueNumber': '1541',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Orchestrating_agents.ipynb word update \"indate\" to \"indicate\"',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '**Please do not use the issues page to ask general questions about '\n",
      "           'the OpenAI API.** Questions asked here will usually not receive '\n",
      "           'answers.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Feel free to report problems with code examples, suggest new code '\n",
      "           'examples, or ask narrow questions about specific code examples.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'For general discussion, try:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [OpenAI API Community Forum](https://community.openai.com/)\\r\\n'\n",
      "           '- [OpenAI Discord](https://discord.com/invite/openai)\\r\\n'\n",
      "           '- [OpenAI subreddit](https://www.reddit.com/r/OpenAI/), [GPT3 '\n",
      "           'subreddit](https://www.reddit.com/r/GPT3/)\\r\\n'\n",
      "           '- [OpenAI Cookbook discussion '\n",
      "           'page](https://github.com/openai/openai-cookbook/discussions)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'For general help, try:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [OpenAI '\n",
      "           'Documentation](https://platform.openai.com/docs/introduction)\\r\\n'\n",
      "           '- [OpenAI Help Center](https://help.openai.com/en/)\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-31T10:05:14Z',\n",
      "  '_issueNumber': '1537',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[SUPPORT]',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This PR:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x] Adds Microsoft.ML.Tokenizer library to C# libraries\\r\\n'\n",
      "           '- [x] Removes deprecated SharpToken library.\\r\\n'\n",
      "           '- [x] Removes unmaintained GPTTokenizer library.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Microsoft.ML.Tokenizers supplants deprecated / unmaintained '\n",
      "           \"libraries. It's also the recommended library for .NET and \"\n",
      "           'maintained by Microsoft.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Source: '\n",
      "           'https://github.com/dotnet/machinelearning/tree/main/src/Microsoft.ML.Tokenizers\\r\\n'\n",
      "           'Package: https://www.nuget.org/packages/Microsoft.ML.Tokenizers\\r\\n'\n",
      "           '\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-30T19:33:39Z',\n",
      "  '_issueNumber': '1535',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Update C# tokenizer libraries',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This PR adds a newly maintained Dart/Flutter package, openai_dart, '\n",
      "           'to the OpenAI Cookbook library. The package is designed to provide '\n",
      "           \"Dart developers with a streamlined way to interact with OpenAI's \"\n",
      "           'API, enabling integration within Flutter applications and other '\n",
      "           'Dart environments. This entry includes all relevant information to '\n",
      "           'guide developers in setting up and using openai_dart\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Including the openai_dart package expands the OpenAI Cookbook’s '\n",
      "           'language and framework support, making it more accessible to the '\n",
      "           'growing Dart and Flutter community. This addition supports '\n",
      "           'developers in leveraging OpenAI technologies on mobile and web '\n",
      "           'platforms built with Flutter, broadening the utility of the '\n",
      "           'Cookbook.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## For new content\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'When contributing new content, read through our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md), '\n",
      "           'and mark the following action items as completed:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x] I have added a new entry in '\n",
      "           '[registry.yaml](https://github.com/openai/openai-cookbook/blob/main/registry.yaml) '\n",
      "           '(and, optionally, in '\n",
      "           '[authors.yaml](https://github.com/openai/openai-cookbook/blob/main/authors.yaml)) '\n",
      "           'so that my content renders on the cookbook website.\\r\\n'\n",
      "           '- [x] I have conducted a self-review of my content based on the '\n",
      "           '[contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md#rubric):\\r\\n'\n",
      "           '  - [x] Relevance: This content is related to building with OpenAI '\n",
      "           'technologies and is useful to others.\\r\\n'\n",
      "           '  - [x] Uniqueness: I have searched for related examples in the '\n",
      "           'OpenAI Cookbook, and verified that my content offers new insights '\n",
      "           'or unique information compared to existing documentation.\\r\\n'\n",
      "           '  - [x] Spelling and Grammar: I have checked for spelling or '\n",
      "           'grammatical mistakes.\\r\\n'\n",
      "           '  - [x] Clarity: I have done a final read-through and verified '\n",
      "           'that my submission is well-organized and easy to understand.\\r\\n'\n",
      "           '  - [x] Correctness: The information I include is correct and all '\n",
      "           'of my code executes successfully.\\r\\n'\n",
      "           '  - [x] Completeness: I have explained everything fully, including '\n",
      "           'all necessary references and citations.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'We will rate each of these areas on a scale from 1 to 4, and will '\n",
      "           'only accept contributions that score 3 or higher on all areas. '\n",
      "           'Refer to our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md) '\n",
      "           'for more details.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-29T19:59:10Z',\n",
      "  '_issueNumber': '1533',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Adding Dart/Flutter Newly Maintained Package i.e. openai_dart in '\n",
      "            'Library',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '@0x2b3bfa0 any idea why CML report is broken here? \\n'\n",
      "           '\\n'\n",
      "           '_Originally posted by @shcheklein in '\n",
      "           'https://github.com/iterative/example-get-started/pull/83#issuecomment-2123830566_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-25T19:57:20Z',\n",
      "  '_issueNumber': '1518',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '@0x2b3bfa0 any idea why CML report is broken here?',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional template]\\n'\n",
      "           '\\n'\n",
      "           '**Is your feature request related to a problem? Please '\n",
      "           'describe.**\\n'\n",
      "           \"A clear and concise description of what the problem is. Ex. I'm \"\n",
      "           'always frustrated when [...]\\n'\n",
      "           '\\n'\n",
      "           \"**Describe the solution you'd like**\\n\"\n",
      "           'A clear and concise description of what you want to happen.\\n'\n",
      "           '\\n'\n",
      "           '**Additional context**\\n'\n",
      "           'Add any other context or screenshots about the feature request '\n",
      "           'here.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-23T22:09:54Z',\n",
      "  '_issueNumber': '1515',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[FEATURE]',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Briefly describe the changes and the goal of this PR. Make sure '\n",
      "           'the PR title summarizes the changes effectively.\\r\\n'\n",
      "           'OceanBase V4.3.3 support vector, we should Document it. Close '\n",
      "           '#1508\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Why are these changes necessary? How do they improve the '\n",
      "           'cookbook?\\r\\n'\n",
      "           'add the documentation\\r\\n'\n",
      "           '## For new content\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'When contributing new content, read through our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md), '\n",
      "           'and mark the following action items as completed:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [ ] I have added a new entry in '\n",
      "           '[registry.yaml](https://github.com/openai/openai-cookbook/blob/main/registry.yaml) '\n",
      "           '(and, optionally, in '\n",
      "           '[authors.yaml](https://github.com/openai/openai-cookbook/blob/main/authors.yaml)) '\n",
      "           'so that my content renders on the cookbook website.\\r\\n'\n",
      "           '- [ ] I have conducted a self-review of my content based on the '\n",
      "           '[contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md#rubric):\\r\\n'\n",
      "           '  - [ ] Relevance: This content is related to building with OpenAI '\n",
      "           'technologies and is useful to others.\\r\\n'\n",
      "           '  - [ ] Uniqueness: I have searched for related examples in the '\n",
      "           'OpenAI Cookbook, and verified that my content offers new insights '\n",
      "           'or unique information compared to existing documentation.\\r\\n'\n",
      "           '  - [ ] Spelling and Grammar: I have checked for spelling or '\n",
      "           'grammatical mistakes.\\r\\n'\n",
      "           '  - [ ] Clarity: I have done a final read-through and verified '\n",
      "           'that my submission is well-organized and easy to understand.\\r\\n'\n",
      "           '  - [ ] Correctness: The information I include is correct and all '\n",
      "           'of my code executes successfully.\\r\\n'\n",
      "           '  - [ ] Completeness: I have explained everything fully, including '\n",
      "           'all necessary references and citations.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'We will rate each of these areas on a scale from 1 to 4, and will '\n",
      "           'only accept contributions that score 3 or higher on all areas. '\n",
      "           'Refer to our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md) '\n",
      "           'for more details.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-23T09:45:21Z',\n",
      "  '_issueNumber': '1509',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[FEATURE]:OceanBase v4.3.3 add vector database support Document',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional template]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Is your feature request related to a problem? Please '\n",
      "           'describe.**\\r\\n'\n",
      "           \"A clear and concise description of what the problem is. Ex. I'm \"\n",
      "           'always frustrated when [...]\\r\\n'\n",
      "           'OceanBase V4.3.3 support vector, we should Document it\\r\\n'\n",
      "           \"**Describe the solution you'd like**\\r\\n\"\n",
      "           'A clear and concise description of what you want to happen.\\r\\n'\n",
      "           'I will add the documentation\\r\\n'\n",
      "           '**Additional context**\\r\\n'\n",
      "           'Add any other context or screenshots about the feature request '\n",
      "           'here.\\r\\n'\n",
      "           'please Read '\n",
      "           'https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000001484238',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-23T09:37:07Z',\n",
      "  '_issueNumber': '1508',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[FEATURE] OceanBase v4.3.3 add vector database support, should '\n",
      "            'Document it',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- fixes typos\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Briefly describe the changes and the goal of this PR. Make sure '\n",
      "           'the PR title summarizes the changes effectively.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Why are these changes necessary? How do they improve the '\n",
      "           'cookbook?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'The changes made were necessary to correct typographical errors in '\n",
      "           'the original text. These improvements, while minor, enhance '\n",
      "           'clarity and readability. There are 5 typos in total.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## For new content\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'When contributing new content, read through our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md), '\n",
      "           'and mark the following action items as completed:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x ] I have added a new entry in '\n",
      "           '[registry.yaml](https://github.com/openai/openai-cookbook/blob/main/registry.yaml) '\n",
      "           '(and, optionally, in '\n",
      "           '[authors.yaml](https://github.com/openai/openai-cookbook/blob/main/authors.yaml)) '\n",
      "           'so that my content renders on the cookbook website.\\r\\n'\n",
      "           '- [ x] I have conducted a self-review of my content based on the '\n",
      "           '[contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md#rubric):\\r\\n'\n",
      "           '  - [x ] Relevance: This content is related to building with '\n",
      "           'OpenAI technologies and is useful to others.\\r\\n'\n",
      "           '  - [x ] Uniqueness: I have searched for related examples in the '\n",
      "           'OpenAI Cookbook, and verified that my content offers new insights '\n",
      "           'or unique information compared to existing documentation.\\r\\n'\n",
      "           '  - [x ] Spelling and Grammar: I have checked for spelling or '\n",
      "           'grammatical mistakes.\\r\\n'\n",
      "           '  - [ x] Clarity: I have done a final read-through and verified '\n",
      "           'that my submission is well-organized and easy to understand.\\r\\n'\n",
      "           '  - [x ] Correctness: The information I include is correct and all '\n",
      "           'of my code executes successfully.\\r\\n'\n",
      "           '  - [x ] Completeness: I have explained everything fully, '\n",
      "           'including all necessary references and citations.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'We will rate each of these areas on a scale from 1 to 4, and will '\n",
      "           'only accept contributions that score 3 or higher on all areas. '\n",
      "           'Refer to our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md) '\n",
      "           'for more details.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-19T19:25:24Z',\n",
      "  '_issueNumber': '1495',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Fixes typos - patch fix',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'The first OpenAI GitHub community token to launch on Solana.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '$AIGIT\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'All communication will run from this thread. I will handle dex '\n",
      "           'payment/ads and external marketing.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'First comment will contain the official PF contract address, all '\n",
      "           'others are fake.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-16T05:05:05Z',\n",
      "  '_issueNumber': '1477',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'OpenAI GitHub Community Token on Solana $AIGIT',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'File Name\\r\\n'\n",
      "           'Orchestrating_agents.ipynb\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Problem\\r\\n'\n",
      "           'Typo in the first code block under Routines within the System '\n",
      "           'Prompt, point 3:\\r\\n'\n",
      "           '\"3. ONLY if not **satesfied**, offer a refund.\\\\n\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Solution\\r\\n'\n",
      "           'replace \"satesfied\" with satisfied',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-15T15:46:34Z',\n",
      "  '_issueNumber': '1474',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[TYPO] Typo in code block under Routines',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'add tiktoken_ruby as a tokenizer library in Ruby\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'See summary\\r\\n'\n",
      "           '\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-13T07:47:21Z',\n",
      "  '_issueNumber': '1468',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'add tiktoken_ruby as a tokenizer lib in Ruby',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional format]\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Identify the file to be fixed**\\r\\n'\n",
      "           '[How_to_count_tokens_with_tiktoken](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Describe the problem**\\r\\n'\n",
      "           'in `6. Counting tokens for chat completions API calls`\\r\\n'\n",
      "           \"the function doesn't account for images or for assistant messages \"\n",
      "           'with tools calls\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Describe a solution**\\r\\n'\n",
      "           'More specific logic should be included\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-13T00:20:46Z',\n",
      "  '_issueNumber': '1467',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': \"[PROBLEM] Token count example doesn't work with messages with \"\n",
      "            'images or tools_calls',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Closes #1463 \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Fixes the `Assistants_API_overview_python` notebook by updating '\n",
      "           'the code for the latest `openai` package. This also fixes the code '\n",
      "           'logic where multiple `ids` for the `tools` were present but not '\n",
      "           'submitted to the `thread`\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Necessary for the community who refer to this code to understand '\n",
      "           'the `Assistants` API.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-12T18:43:09Z',\n",
      "  '_issueNumber': '1464',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '`Assistants_API_overview_python` notebook updated for the latest '\n",
      "            '`openai` package',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '`Assistants_API_overview_python.ipynb` notebook is broken because '\n",
      "           'its using the code from an older version of the `openai` package. '\n",
      "           'Most are incorrect parameter values but there is also an issue '\n",
      "           'with the code logic when using threads to submit the tool '\n",
      "           'output.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Screenshots**\\r\\n'\n",
      "           '<img width=\"722\" alt=\"image\" '\n",
      "           'src=\"https://github.com/user-attachments/assets/b04b516e-a865-482a-a2c6-85890874652a\">\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-12T18:28:47Z',\n",
      "  '_issueNumber': '1463',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[PROBLEM] Assisstants API Overview notebook broken due to '\n",
      "            'outdated code',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '## Summary\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This PR aims to expands the cookbook library on GPT actions by '\n",
      "           'adding a new one about Google Ads. This cookbook explains how to '\n",
      "           'connect to Google Ads reporting data to ChatGPT via Adzviser, a '\n",
      "           '3rd-party middleware that retrieves and transforms the Google Ads '\n",
      "           'data for the user.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## Motivation\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'There are many marketers who use ChatGPT on a daily basis today. '\n",
      "           'Some upload their downloaded reporting data files from Google Ads '\n",
      "           'UI to ChatGPT for it to analyze it deeper and brainstorm '\n",
      "           'optimization ideas. This cookbook gives a tutorial on how to '\n",
      "           'connect Google Ads reporting data directly to ChatGPT through GPT '\n",
      "           \"actions, so that marketers don't have to download and upload files \"\n",
      "           'each time. It will save them time and overheads.  \\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '## For new content\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'When contributing new content, read through our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md), '\n",
      "           'and mark the following action items as completed:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [x] I have added a new entry in '\n",
      "           '[registry.yaml](https://github.com/openai/openai-cookbook/blob/main/registry.yaml) '\n",
      "           '(and, optionally, in '\n",
      "           '[authors.yaml](https://github.com/openai/openai-cookbook/blob/main/authors.yaml)) '\n",
      "           'so that my content renders on the cookbook website.\\r\\n'\n",
      "           '- [x] I have conducted a self-review of my content based on the '\n",
      "           '[contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md#rubric):\\r\\n'\n",
      "           '  - [x] Relevance: This content is related to building with OpenAI '\n",
      "           'technologies and is useful to others.\\r\\n'\n",
      "           '  - [x] Uniqueness: I have searched for related examples in the '\n",
      "           'OpenAI Cookbook, and verified that my content offers new insights '\n",
      "           'or unique information compared to existing documentation.\\r\\n'\n",
      "           '  - [x] Spelling and Grammar: I have checked for spelling or '\n",
      "           'grammatical mistakes.\\r\\n'\n",
      "           '  - [x] Clarity: I have done a final read-through and verified '\n",
      "           'that my submission is well-organized and easy to understand.\\r\\n'\n",
      "           '  - [x] Correctness: The information I include is correct and all '\n",
      "           'of my code executes successfully.\\r\\n'\n",
      "           '  - [x] Completeness: I have explained everything fully, including '\n",
      "           'all necessary references and citations.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'We will rate each of these areas on a scale from 1 to 4, and will '\n",
      "           'only accept contributions that score 3 or higher on all areas. '\n",
      "           'Refer to our [contribution '\n",
      "           'guidelines](https://github.com/openai/openai-cookbook/blob/main/CONTRIBUTING.md) '\n",
      "           'for more details.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-11T04:43:06Z',\n",
      "  '_issueNumber': '1462',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Adds GPT action cookbook about connecting to Google Ads real-time '\n",
      "            'reporting data',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '[optional template]\\n'\n",
      "           '\\n'\n",
      "           '**Is your feature request related to a problem? Please '\n",
      "           'describe.**\\n'\n",
      "           \"A clear and concise description of what the problem is. Ex. I'm \"\n",
      "           'always frustrated when [...]\\n'\n",
      "           '\\n'\n",
      "           \"**Describe the solution you'd like**\\n\"\n",
      "           'A clear and concise description of what you want to happen.\\n'\n",
      "           '\\n'\n",
      "           '**Additional context**\\n'\n",
      "           'Add any other context or screenshots about the feature request '\n",
      "           'here.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-10T05:58:27Z',\n",
      "  '_issueNumber': '1460',\n",
      "  '_repo': 'openai-cookbook',\n",
      "  '_state': 'open',\n",
      "  '_title': '[FEATURE]',\n",
      "  '_type': 'issue'}]\n",
      "Fetching issues from: https://api.github.com/repos/elastic/elasticsearch/issues\n",
      "[{'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T03:29:23Z',\n",
      "  '_issueNumber': '117303',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Remove HTTP content copies',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This updates the constants for `OperatorPrivilegesIT` to include '\n",
      "           'the registered actions that were missing and unmutes the test\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Backport of: #117218\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T02:20:03Z',\n",
      "  '_issueNumber': '117302',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Fix and unmute OperatorPrivilegesIT',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '`.async-search` can sometimes appear if async request is slow, and '\n",
      "           \"there's no point for the test cleanup to complain about it. \\r\\n\"\n",
      "           '\\r\\n'\n",
      "           'Fixes https://github.com/elastic/elasticsearch/issues/117099',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-22T02:00:18Z',\n",
      "  '_issueNumber': '117301',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'FIx async search tests - do not warn on the presence of '\n",
      "            '.async-search',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Relates to https://github.com/elastic/elasticsearch/pull/117293, '\n",
      "           'https://github.com/elastic/elasticsearch/pull/115375\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'If the \"Transient settings migration guide\" page is required in '\n",
      "           '9.0, this PR re-adds it to the navigation such that it has the '\n",
      "           'same type of location as in '\n",
      "           'https://www.elastic.co/guide/en/elasticsearch/reference/current/transient-settings-migration-guide.html\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T23:47:14Z',\n",
      "  '_issueNumber': '117299',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': '[DOCS] Re-add transient settings migration guide',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Legacy yaml test runner does not support supplying test cluster '\n",
      "           'with test features. Due to recently introduced '\n",
      "           '`mapper.source.mode_from_index_setting` test feature, a lot of '\n",
      "           'tests using it were silently ignored. This PR fixes this by '\n",
      "           'migrating all projects using legacy runner and '\n",
      "           '`mapper.source.mode_from_index_setting` to a \"proper\" test '\n",
      "           'plugin.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Related to #117284.\\r\\n'\n",
      "           'Related to #116072.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T23:44:46Z',\n",
      "  '_issueNumber': '117298',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Migrate mapper-related modules to internal-*-rest-test',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '> [esql] > Unexpected error from Elasticsearch: '\n",
      "           'illegal_state_exception - sink exchanger for id '\n",
      "           '[ruxoDDxXTGW55oIPHoCT-g:964613010] already exists.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This issue occurs when two or more `clusterAliases` point to the '\n",
      "           'same physical remote cluster. The exchange service assumes the '\n",
      "           'destination is unique, which is not true in this topology. This PR '\n",
      "           'addresses the problem by appending a suffix using a monotonic '\n",
      "           'increasing number, ensuring that different exchanges are created '\n",
      "           'in such cases.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Another issue arising from this behavior is that data on a remote '\n",
      "           'cluster is processed multiple times, leading to incorrect results. '\n",
      "           'I can work on the fix for this once we agree that this is an '\n",
      "           'issue.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T22:58:15Z',\n",
      "  '_issueNumber': '117297',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Fix CCS exchange when multi cluster aliases point to same cluster',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '**Build Scans:**\\n'\n",
      "           '- [elasticsearch-periodic #4976 / '\n",
      "           'release-tests](https://gradle-enterprise.elastic.co/s/33vq6zb3irmt4)\\n'\n",
      "           '- [elasticsearch-pull-request #42472 / '\n",
      "           'part-3](https://gradle-enterprise.elastic.co/s/ef5kodnq22cfa)\\n'\n",
      "           '\\n'\n",
      "           '**Reproduction Line:**\\n'\n",
      "           '```\\n'\n",
      "           './gradlew \":x-pack:plugin:yamlRestTest\" --tests '\n",
      "           '\"org.elasticsearch.xpack.test.rest.XPackRestIT.test '\n",
      "           '{p0=snapshot/10_basic/Create a source only snapshot and then '\n",
      "           'restore it}\" -Dtests.seed=D84D929E6A400AEA -Dbuild.snapshot=false '\n",
      "           '-Dtests.jvm.argline=\"-Dbuild.snapshot=false\" '\n",
      "           '-Dlicense.key=x-pack/license-tools/src/test/resources/public.key '\n",
      "           '-Dtests.locale=gd -Dtests.timezone=Etc/GMT+9 -Druntime.java=23\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '**Applicable branches:**\\n'\n",
      "           'main\\n'\n",
      "           '\\n'\n",
      "           '**Reproduces locally?:**\\n'\n",
      "           'N/A\\n'\n",
      "           '\\n'\n",
      "           '**Failure History:**\\n'\n",
      "           '[See '\n",
      "           \"dashboard](https://es-delivery-stats.elastic.dev/app/dashboards#/view/dcec9e60-72ac-11ee-8f39-55975ded9e63?_g=(refreshInterval:(pause:!t,value:60000),time:(from:now-7d%2Fd,to:now))&_a=(controlGroupState:(initialChildControlState:('0c0c9cb8-ccd2-45c6-9b13-96bac4abc542':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:task.keyword,order:0,selectedOptions:!(),title:'GradleTask',type:optionsListControl),'4e6ad9d6-6fdc-4fcc-bf1a-aa6ca79e0850':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:className.keyword,order:1,selectedOptions:!(org.elasticsearch.xpack.test.rest.XPackRestIT),title:'Suite',type:optionsListControl),'144933da-5c1b-4257-a969-7f43455a7901':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:name.keyword,order:2,selectedOptions:!(test%20%7Bp0%3Dsnapshot%2F10_basic%2FCreate%20a%20source%20only%20snapshot%20and%20then%20restore%20it%7D),title:'Test',type:optionsListControl)))))\\n\"\n",
      "           '\\n'\n",
      "           '**Failure Message:**\\n'\n",
      "           '```\\n'\n",
      "           'java.lang.AssertionError: Failure at [snapshot/10_basic:49]: \\n'\n",
      "           'Expected: <1>\\n'\n",
      "           '     but: was <3>\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '**Issue Reasons:**\\n'\n",
      "           '- [main] 2 failures in test test {p0=snapshot/10_basic/Create a '\n",
      "           'source only snapshot and then restore it} (0.4% fail rate in 495 '\n",
      "           'executions)\\n'\n",
      "           '\\n'\n",
      "           '**Note:**\\n'\n",
      "           'This issue was created using new test triage automation. Please '\n",
      "           'report issues or feedback to es-delivery.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T22:31:01Z',\n",
      "  '_issueNumber': '117295',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': '[CI] XPackRestIT test {p0=snapshot/10_basic/Create a source only '\n",
      "            'snapshot and then restore it} failing',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Always emit the `inference_id` param when writing a '\n",
      "           '`semantic_text` field mapping to XContent.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T21:41:46Z',\n",
      "  '_issueNumber': '117294',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Always Emit Inference ID in Semantic Text Mapping',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Backports the following commits to 8.x:\\n'\n",
      "           ' - Fix SecureSM to allow innocuous threads and threadgroups for '\n",
      "           'parallel streams (#117277)',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T21:12:12Z',\n",
      "  '_issueNumber': '117292',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': '[8.x] Fix SecureSM to allow innocuous threads and threadgroups '\n",
      "            'for parallel streams (#117277)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'For the Google Vertex AI rerank API, for an infer request with the '\n",
      "           'following example inputs:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '{\\r\\n'\n",
      "           '  \"input\": [\\r\\n'\n",
      "           '    \"A canvas stretched across the day,\\\\nWhere sunlight learns to '\n",
      "           'dance and play.\\\\nBlue, a hue of scattered light,\\\\nA gentle '\n",
      "           'whisper, soft and bright.\",\\r\\n'\n",
      "           '    \"The sky appears blue due to a phenomenon called Rayleigh '\n",
      "           'scattering. Sunlight is comprised of all the colors of the '\n",
      "           'rainbow. Blue light has shorter wavelengths than other colors, and '\n",
      "           'is thus scattered more easily.\"\\r\\n'\n",
      "           '  ]\\r\\n'\n",
      "           '}\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'We create a request that looks like this, following the [API '\n",
      "           'specs](https://cloud.google.com/generative-ai-app-builder/docs/ranking)\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\"records\": [\\r\\n'\n",
      "           '   {\\r\\n'\n",
      "           '       \"id\": \"1\",\\r\\n'\n",
      "           '       \"content\": \"A canvas stretched across the day,\\\\nWhere '\n",
      "           'sunlight learns to dance and play.\\\\nBlue, a hue of scattered '\n",
      "           'light,\\\\nA gentle whisper, soft and bright.\"\\r\\n'\n",
      "           '   },\\r\\n'\n",
      "           '   {\\r\\n'\n",
      "           '       \"id\": \"2\",\\r\\n'\n",
      "           '       \"content\": \"The sky appears blue due to a phenomenon called '\n",
      "           'Rayleigh scattering. Sunlight is comprised of all the colors of '\n",
      "           'the rainbow. Blue light has shorter wavelengths than other colors, '\n",
      "           'and is thus scattered more easily.\"\\r\\n'\n",
      "           '   }\\r\\n'\n",
      "           ']\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'Note that for the ID, we use the index of the entry in the input '\n",
      "           'array '\n",
      "           'https://github.com/elastic/elasticsearch/blob/6d963d324aa71a514cd4baa01bd0805eaba7426e/x-pack/plugin/inference/src/main/java/org/elasticsearch/xpack/inference/external/request/googlevertexai/GoogleVertexAiRerankRequestEntity.java#L47-L53\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'The API response is an array of records, sorted in descending '\n",
      "           'order by score, for example\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '{\\r\\n'\n",
      "           '    \"records\": [\\r\\n'\n",
      "           '        {\\r\\n'\n",
      "           '            \"id\": \"2\",\\r\\n'\n",
      "           '            \"score\": 0.98,\\r\\n'\n",
      "           '            \"content\": \"The sky appears blue due to a phenomenon '\n",
      "           'called Rayleigh scattering. Sunlight is comprised of all the '\n",
      "           'colors of the rainbow. Blue light has shorter wavelengths than '\n",
      "           'other colors, and is thus scattered more easily.\"\\r\\n'\n",
      "           '        },\\r\\n'\n",
      "           '        {\\r\\n'\n",
      "           '            \"id\": \"1\",\\r\\n'\n",
      "           '            \"score\": 0.64,\\r\\n'\n",
      "           '            \"content\": \"A canvas stretched across the day,\\\\nWhere '\n",
      "           'sunlight learns to dance and play.\\\\nBlue, a hue of scattered '\n",
      "           'light,\\\\nA gentle whisper, soft and bright.\"\\r\\n'\n",
      "           '        }\\r\\n'\n",
      "           '    ]\\r\\n'\n",
      "           '}\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'In our response parser, we were not using the record ID (index of '\n",
      "           'the entry in the input array) as the index into our result array, '\n",
      "           'resulting in results where the score did not match up to the entry '\n",
      "           'in the input array.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T20:51:58Z',\n",
      "  '_issueNumber': '117287',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Fixing bug setting index when parsing Google Vertex AI results',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This is a follow-up to '\n",
      "           'https://github.com/elastic/elasticsearch/pull/117182.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"That PR didn't change yaml tests since they were not running and \"\n",
      "           \"didn't introduce a test feature. Tests didn't run because legacy \"\n",
      "           \"yaml rest tests don't provide tests features and the test was \"\n",
      "           'using previously introduced '\n",
      "           '`mapper.source.mode_from_index_setting`. As a result this test was '\n",
      "           'always skipped.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This PR introduces new test feature, fixes the test and migrates '\n",
      "           'this project to proper yaml test runner.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T20:47:39Z',\n",
      "  '_issueNumber': '117284',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Fix constand_keyword test run and properly test recent behavior '\n",
      "            'change',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'None',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T20:10:23Z',\n",
      "  '_issueNumber': '117282',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'WIP: Add ESQL telemetry collection',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Now that fast refresh searches go to search nodes, we need to wait '\n",
      "           'for replicas to be available on them before we hit them. See '\n",
      "           \"#117217 for context, it's the same issue.\\r\\n\",\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T20:09:22Z',\n",
      "  '_issueNumber': '117281',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Wait for all shards to be available in synonyms test',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Description\\n'\n",
      "           '\\n'\n",
      "           'Right now, for vectors stored as `element_type: byte` we disallow '\n",
      "           'scripting functions to be calculated with floating point query. '\n",
      "           'However, if the user used some external quantization methodology, '\n",
      "           'allowing the asymmetric distance calculation like this might be '\n",
      "           'useful. \\n'\n",
      "           '\\n'\n",
      "           'Since we already calculate magnitude for everything, the '\n",
      "           'implementation will be fairly trivial. \\n'\n",
      "           '\\n'\n",
      "           'The one aspect around this that might be \"slow\" is the actual '\n",
      "           'vector ops. We have no SIMD optimized operations between `float[], '\n",
      "           'byte[]` for dot-product. But, that should be fairly simple to do.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T18:56:35Z',\n",
      "  '_issueNumber': '117274',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Allow `float[]` with `byte[]` comparisons for `cosine` and '\n",
      "            '`dotProduct` for dense_vector scripting',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Addresses #117258',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T18:39:42Z',\n",
      "  '_issueNumber': '117272',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Handle semantic text partial updates when the field is in an '\n",
      "            'object',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'The coordinator rewrite has logic to skip indices if the provided '\n",
      "           'date range filter is not within the min and max range of all of '\n",
      "           'its shards. This mechanism is enabled for event.ingested and '\n",
      "           '@timestamp fields, against searchable snapshots.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'We have basic checks that such fields need to be of date field '\n",
      "           'type, yet if they are defined as alias of a date field, their '\n",
      "           'range will be empty, which indicates that the shards are empty, '\n",
      "           'and the coord rewrite logic resolves the alias and ends up '\n",
      "           'skipping shards that may have matching docs.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This commit adds an explicit check that declares the range UNKNOWN '\n",
      "           'instead of EMPTY in these circumstances. The same check is also '\n",
      "           'performed in the coord rewrite logic, so that shards are no longer '\n",
      "           'skipped by mistake.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T18:17:56Z',\n",
      "  '_issueNumber': '117271',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': \"Don't skip shards in coord rewrite if timestamp is an alias\",\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Fix a test for the task results when running the `LIMIT` '\n",
      "           'operation. We were releasing a few permits to get the query '\n",
      "           'started. And when you combine that with the page worth of permits '\n",
      "           \"that the test was releasing we'd sometimes finish the entire \"\n",
      "           'limited query, stopping the task too early to find a running '\n",
      "           'task.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Closes #107293\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T18:15:15Z',\n",
      "  '_issueNumber': '117270',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'ESQL: Fix limit task test',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '# Backport\\n'\n",
      "           '\\n'\n",
      "           'This will backport the following commits from `main` to `8.x`:\\n'\n",
      "           ' - [IndexNameExpressionResolver refactoring '\n",
      "           '(#116085)](https://github.com/elastic/elasticsearch/pull/116085)\\n'\n",
      "           '\\n'\n",
      "           '<!--- Backport version: 9.6.0 -->\\n'\n",
      "           '\\n'\n",
      "           '### Questions ?\\n'\n",
      "           'Please refer to the [Backport tool '\n",
      "           'documentation](https://github.com/sorenlouv/backport)',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T16:24:27Z',\n",
      "  '_issueNumber': '117267',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': '[8.x] IndexNameExpressionResolver refactoring (#116085)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Elasticsearch Version\\n'\n",
      "           '\\n'\n",
      "           'Elasticsearch high-level REST client 7.17\\n'\n",
      "           '\\n'\n",
      "           '### Installed Plugins\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Java Version\\n'\n",
      "           '\\n'\n",
      "           'openjdk version \"17.0.13\" 2024-10-15\\n'\n",
      "           '\\n'\n",
      "           '### OS Version\\n'\n",
      "           '\\n'\n",
      "           'Linux 6.1.0-27-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.115-1 '\n",
      "           '(2024-11-01) x86_64 GNU/Linux\\n'\n",
      "           '\\n'\n",
      "           '### Problem Description\\n'\n",
      "           '\\n'\n",
      "           'If Elasticsearch high-level REST client is used in front of an API '\n",
      "           'gateway, such as Spring Cloud Gateway, it sometimes needs to be '\n",
      "           'configured to send custom additional HTTP headers in order to be '\n",
      "           'validated by the API gateway (these headers might contain '\n",
      "           'mandatory values to submit).\\n'\n",
      "           'We discovered that the client checks the version of Elasticsearch '\n",
      "           'without sending the additional headers. It anyway ignores the '\n",
      "           'problem if it gets HTTP codes 401 or 403, but not if the returned '\n",
      "           'code is HTTP 400.\\n'\n",
      "           'In my humble opinion, the root cause of this error is not sending '\n",
      "           'the additional headers. Can you please fix that?\\n'\n",
      "           '\\n'\n",
      "           '### Steps to Reproduce\\n'\n",
      "           '\\n'\n",
      "           '1. Configure Spring Cloud Gateway to stop calls without a set of '\n",
      "           'mandatory HTTP headers. Be sure that it returns 400 and not '\n",
      "           '401/403 HTTP codes.\\n'\n",
      "           '2. Configure the high-level client with the mandatory HTTP '\n",
      "           'headers.\\n'\n",
      "           '3. Run a generic call with the high-level gateway. Even if the '\n",
      "           'call is \"white-listed\", the client will return an error anyway.\\n'\n",
      "           '\\n'\n",
      "           '### Logs (if relevant)\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T16:06:03Z',\n",
      "  '_issueNumber': '117266',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': \"Elasticsearch high-level REST client doesn't send additional HTTP \"\n",
      "            'headers while querying for Elasticsearch version',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'DRAFT: not ready for review. Creating this for testing purposes '\n",
      "           'only right now.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T15:31:36Z',\n",
      "  '_issueNumber': '117265',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'ESQL: async search responses have CCS metadata while searches are '\n",
      "            'running',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Description\\n'\n",
      "           '\\n'\n",
      "           '## Description\\n'\n",
      "           '\\n'\n",
      "           'When the provided input for a chunked inference request breaks '\n",
      "           \"into many chunks, it's possible that it can exceed the queue size \"\n",
      "           'limit (defined either by the user or defaulted to 1000) on the ML '\n",
      "           'node. We previously implemented a fix to \"batch the chunks\" to '\n",
      "           'avoid hitting this queue limit. This fix waits for each batch of '\n",
      "           'chunks to complete before sending the next one essentailly adding '\n",
      "           \"a queuing mechanism on top of the existing queue. Long term we'd \"\n",
      "           'like to replace this with a retry strategy on our calls to the '\n",
      "           'queue that would backoff when a queue size limit is hit and try to '\n",
      "           'push to it again after some period of time.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T15:20:58Z',\n",
      "  '_issueNumber': '117264',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': '[ML] Add retries on chunking queue full exceptions',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This commit bump hadoop hdfs to 3.4.1.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '-------\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I used mvn:dependency tree from a test project to help ensure '\n",
      "           'correct alignment of transient versions:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '[INFO] \\\\- org.apache.hadoop:hadoop-hdfs:jar:3.4.1:compile\\r\\n'\n",
      "           '[INFO]    +- '\n",
      "           'org.apache.hadoop.thirdparty:hadoop-shaded-guava:jar:1.3.0:compile\\r\\n'\n",
      "           '[INFO]    +- '\n",
      "           'org.eclipse.jetty:jetty-server:jar:9.4.53.v20231009:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'org.eclipse.jetty:jetty-http:jar:9.4.53.v20231009:compile\\r\\n'\n",
      "           '[INFO]    |  \\\\- '\n",
      "           'org.eclipse.jetty:jetty-io:jar:9.4.53.v20231009:compile\\r\\n'\n",
      "           '[INFO]    +- '\n",
      "           'org.eclipse.jetty:jetty-util:jar:9.4.53.v20231009:compile\\r\\n'\n",
      "           '[INFO]    +- '\n",
      "           'org.eclipse.jetty:jetty-util-ajax:jar:9.4.53.v20231009:compile\\r\\n'\n",
      "           '[INFO]    +- com.sun.jersey:jersey-core:jar:1.19.4:compile\\r\\n'\n",
      "           '[INFO]    |  \\\\- javax.ws.rs:jsr311-api:jar:1.1.1:compile\\r\\n'\n",
      "           '[INFO]    +- com.sun.jersey:jersey-server:jar:1.19.4:compile\\r\\n'\n",
      "           '[INFO]    +- commons-cli:commons-cli:jar:1.5.0:compile\\r\\n'\n",
      "           '[INFO]    +- commons-codec:commons-codec:jar:1.15:compile\\r\\n'\n",
      "           '[INFO]    +- commons-io:commons-io:jar:2.16.1:compile\\r\\n'\n",
      "           '[INFO]    +- commons-daemon:commons-daemon:jar:1.0.13:compile\\r\\n'\n",
      "           '[INFO]    +- ch.qos.reload4j:reload4j:jar:1.2.22:compile\\r\\n'\n",
      "           '[INFO]    +- javax.servlet:javax.servlet-api:jar:3.1.0:compile\\r\\n'\n",
      "           '[INFO]    +- io.netty:netty-all:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- io.netty:netty-buffer:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- io.netty:netty-codec:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-dns:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-haproxy:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-http:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-http2:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-memcache:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-mqtt:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-redis:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-smtp:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-socks:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-stomp:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-codec-xml:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- io.netty:netty-common:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-handler:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-native-unix-common:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-handler-proxy:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-handler-ssl-ocsp:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-resolver:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-resolver-dns:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-rxtx:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-sctp:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-udt:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-classes-epoll:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-classes-kqueue:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-resolver-dns-classes-macos:jar:4.1.100.Final:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-native-epoll:jar:linux-x86_64:4.1.100.Final:runtime\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-native-epoll:jar:linux-aarch_64:4.1.100.Final:runtime\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-native-kqueue:jar:osx-x86_64:4.1.100.Final:runtime\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-transport-native-kqueue:jar:osx-aarch_64:4.1.100.Final:runtime\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'io.netty:netty-resolver-dns-native-macos:jar:osx-x86_64:4.1.100.Final:runtime\\r\\n'\n",
      "           '[INFO]    |  \\\\- '\n",
      "           'io.netty:netty-resolver-dns-native-macos:jar:osx-aarch_64:4.1.100.Final:runtime\\r\\n'\n",
      "           '[INFO]    +- '\n",
      "           'org.fusesource.leveldbjni:leveldbjni-all:jar:1.8:compile\\r\\n'\n",
      "           '[INFO]    +- '\n",
      "           'com.fasterxml.jackson.core:jackson-databind:jar:2.12.7.1:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'com.fasterxml.jackson.core:jackson-annotations:jar:2.12.7:compile\\r\\n'\n",
      "           '[INFO]    |  \\\\- '\n",
      "           'com.fasterxml.jackson.core:jackson-core:jar:2.12.7:compile\\r\\n'\n",
      "           '[INFO]    \\\\- '\n",
      "           'org.apache.hadoop:hadoop-annotations:jar:3.4.1:compile\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\\\- org.apache.hadoop:hadoop-client:jar:3.4.1:compile\\r\\n'\n",
      "           '[INFO]    +- org.apache.hadoop:hadoop-common:jar:3.4.1:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'org.apache.hadoop.thirdparty:hadoop-shaded-protobuf_3_25:jar:1.3.0:compile\\r\\n'\n",
      "           '[INFO]    |  +- '\n",
      "           'org.apache.hadoop.thirdparty:hadoop-shaded-guava:jar:1.3.0:compile\\r\\n'\n",
      "           '[INFO]    |  +- com.google.guava:guava:jar:27.0-jre:compile\\r\\n'\n",
      "           '[INFO]    |  |  +- '\n",
      "           'com.google.guava:failureaccess:jar:1.0:compile\\r\\n'\n",
      "           '[INFO]    |  |  +- '\n",
      "           'com.google.guava:listenablefuture:jar:9999.0-empty-to-avoid-conflict-with-guava:compile\\r\\n'\n",
      "           '[INFO]    |  |  +- '\n",
      "           'org.checkerframework:checker-qual:jar:2.5.2:compile\\r\\n'\n",
      "           '[INFO]    |  |  +- '\n",
      "           'com.google.j2objc:j2objc-annotations:jar:1.1:compile\\r\\n'\n",
      "           '[INFO]    |  |  \\\\- '\n",
      "           'org.codehaus.mojo:animal-sniffer-annotations:jar:1.17:compile\\r\\n'\n",
      "           '[INFO]    |  +- commons-cli:commons-cli:jar:1.5.0:compile\\r\\n'\n",
      "           '[INFO]    |  +- org.a',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T15:11:49Z',\n",
      "  '_issueNumber': '117263',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'bump hadoop hdfs to 3.4.1',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Test that filters work on sigle count(...) with no group.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Related #115522\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '(cherry picked from commit '\n",
      "           'c190c5762bf659461dc8aa455b01fa1789001c39)\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T14:58:24Z',\n",
      "  '_issueNumber': '117261',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'ESQL: Add tests for single count with filter (#117180)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Elasticsearch Version\\n'\n",
      "           '\\n'\n",
      "           '8.15.x, 8.16.x, 8.17.x\\n'\n",
      "           '\\n'\n",
      "           '### Installed Plugins\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Java Version\\n'\n",
      "           '\\n'\n",
      "           '_bundled_\\n'\n",
      "           '\\n'\n",
      "           '### OS Version\\n'\n",
      "           '\\n'\n",
      "           'N/A\\n'\n",
      "           '\\n'\n",
      "           '### Problem Description\\n'\n",
      "           '\\n'\n",
      "           'Under certain scenarios, you are unable to update a semantic text '\n",
      "           'field using the Update API when the semantic text field is in an '\n",
      "           'object field.\\n'\n",
      "           '\\n'\n",
      "           '### Steps to Reproduce\\n'\n",
      "           '\\n'\n",
      "           '1. Create an index with a semantic text field in an object:\\n'\n",
      "           '\\n'\n",
      "           '```json\\n'\n",
      "           'PUT _inference/sparse_embedding/my-elser-endpoint\\n'\n",
      "           '{\\n'\n",
      "           '  \"service\": \"elser\",\\n'\n",
      "           '  \"service_settings\": {\\n'\n",
      "           '    \"num_allocations\": 1,\\n'\n",
      "           '    \"num_threads\": 1\\n'\n",
      "           '  }\\n'\n",
      "           '}\\n'\n",
      "           '\\n'\n",
      "           'PUT my-index\\n'\n",
      "           '{\\n'\n",
      "           '  \"mappings\": {\\n'\n",
      "           '    \"properties\": {\\n'\n",
      "           '      \"object\": {\\n'\n",
      "           '        \"properties\": {\\n'\n",
      "           '          \"inference_field\": {\\n'\n",
      "           '            \"type\": \"semantic_text\",\\n'\n",
      "           '            \"inference_id\": \"my-elser-endpoint\"\\n'\n",
      "           '          }\\n'\n",
      "           '        }\\n'\n",
      "           '      }\\n'\n",
      "           '    }\\n'\n",
      "           '  }\\n'\n",
      "           '}\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '2. Add a document to the index, defining the semantic text field '\n",
      "           'value using a nested structure\\n'\n",
      "           '\\n'\n",
      "           '```json\\n'\n",
      "           'PUT my-index/_doc/doc1\\n'\n",
      "           '{\\n'\n",
      "           '  \"object\": {\\n'\n",
      "           '    \"inference_field\": \"test value\"\\n'\n",
      "           '  }\\n'\n",
      "           '}\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '3. Update the document using the Update API, defining the semantic '\n",
      "           'text field value using a flat structure\\n'\n",
      "           '\\n'\n",
      "           '```json\\n'\n",
      "           'POST my-index/_update/doc1\\n'\n",
      "           '{\\n'\n",
      "           '  \"doc\": { \\n'\n",
      "           '    \"object.inference_field\": \"updated value\"\\n'\n",
      "           '  }\\n'\n",
      "           '}\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           'The update fails with the error:\\n'\n",
      "           '\\n'\n",
      "           '```json\\n'\n",
      "           '{\\n'\n",
      "           '    \"error\": {\\n'\n",
      "           '        \"root_cause\": [\\n'\n",
      "           '            {\\n'\n",
      "           '                \"type\": \"status_exception\",\\n'\n",
      "           '                \"reason\": \"Invalid format for field '\n",
      "           '[object.inference_field], expected [String] got [ArrayList]\"\\n'\n",
      "           '            }\\n'\n",
      "           '        ],\\n'\n",
      "           '        \"type\": \"status_exception\",\\n'\n",
      "           '        \"reason\": \"Invalid format for field '\n",
      "           '[object.inference_field], expected [String] got [ArrayList]\"\\n'\n",
      "           '    },\\n'\n",
      "           '    \"status\": 400\\n'\n",
      "           '}\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Logs (if relevant)\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T14:46:26Z',\n",
      "  '_issueNumber': '117258',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Unable to update semantic text field in object using Update API',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Description\\n'\n",
      "           '\\n'\n",
      "           'In ESQL `CONCAT(\"a\", NULL, \"b\")` is `null`. That\\'s true in '\n",
      "           '[MySQL](https://www.db-fiddle.com/f/5V3nU8bLunQdrdcZSNa8Zm/0) but '\n",
      "           'not in '\n",
      "           '[Postgres](https://www.db-fiddle.com/f/97ea9QJjSo2CmUwGaSTnxz/0)!\\n'\n",
      "           '\\n'\n",
      "           'Do we want to be more like Postgres here? That comes with some fun '\n",
      "           '[side effects](https://stackoverflow.com/a/47564272), maybe.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T14:45:46Z',\n",
      "  '_issueNumber': '117257',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'ESQL: CONCAT on null',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Backports the following commits to 8.16:\\n'\n",
      "           ' - [ML] Fix deberta tokenizer bug caused by bug in normalizer  '\n",
      "           '(#117189)',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T14:39:50Z',\n",
      "  '_issueNumber': '117256',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': '[8.16] [ML] Fix deberta tokenizer bug caused by bug in '\n",
      "            'normalizer  (#117189)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '**Build Scans:**\\n'\n",
      "           '- [elasticsearch-periodic #4970 / '\n",
      "           'release-tests](https://gradle-enterprise.elastic.co/s/2vt7524h2r7eg)\\n'\n",
      "           '- [elasticsearch-periodic-platform-support #4940 / '\n",
      "           'debian-11_platform-support-unix](https://gradle-enterprise.elastic.co/s/j42rx4zfzafuc)\\n'\n",
      "           '\\n'\n",
      "           '**Reproduction Line:**\\n'\n",
      "           '```\\n'\n",
      "           './gradlew \":x-pack:plugin:esql:internalClusterTest\" --tests '\n",
      "           '\"org.elasticsearch.xpack.esql.action.EsqlNodeFailureIT.testFailureLoadingFields\" '\n",
      "           '-Dtests.seed=A12C66FC28B948E5 -Dbuild.snapshot=false '\n",
      "           '-Dtests.jvm.argline=\"-Dbuild.snapshot=false\" '\n",
      "           '-Dlicense.key=x-pack/license-tools/src/test/resources/public.key '\n",
      "           '-Dtests.locale=ccp-BD -Dtests.timezone=Asia/Jerusalem '\n",
      "           '-Druntime.java=23\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '**Applicable branches:**\\n'\n",
      "           'main\\n'\n",
      "           '\\n'\n",
      "           '**Reproduces locally?:**\\n'\n",
      "           'N/A\\n'\n",
      "           '\\n'\n",
      "           '**Failure History:**\\n'\n",
      "           '[See '\n",
      "           \"dashboard](https://es-delivery-stats.elastic.dev/app/dashboards#/view/dcec9e60-72ac-11ee-8f39-55975ded9e63?_g=(refreshInterval:(pause:!t,value:60000),time:(from:now-7d%2Fd,to:now))&_a=(controlGroupState:(initialChildControlState:('0c0c9cb8-ccd2-45c6-9b13-96bac4abc542':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:task.keyword,order:0,selectedOptions:!(),title:'GradleTask',type:optionsListControl),'4e6ad9d6-6fdc-4fcc-bf1a-aa6ca79e0850':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:className.keyword,order:1,selectedOptions:!(org.elasticsearch.xpack.esql.action.EsqlNodeFailureIT),title:'Suite',type:optionsListControl),'144933da-5c1b-4257-a969-7f43455a7901':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:name.keyword,order:2,selectedOptions:!(testFailureLoadingFields),title:'Test',type:optionsListControl)))))\\n\"\n",
      "           '\\n'\n",
      "           '**Failure Message:**\\n'\n",
      "           '```\\n'\n",
      "           'java.lang.AssertionError: Leftover exchanges '\n",
      "           'ExchangeService{sinks=[z3NUjnMETZWPthW2xTghQA:385]} on node '\n",
      "           'node_s2\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '**Issue Reasons:**\\n'\n",
      "           '- [main] 2 failures in test testFailureLoadingFields (1.4% fail '\n",
      "           'rate in 142 executions)\\n'\n",
      "           '\\n'\n",
      "           '**Note:**\\n'\n",
      "           'This issue was created using new test triage automation. Please '\n",
      "           'report issues or feedback to es-delivery.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T14:31:39Z',\n",
      "  '_issueNumber': '117253',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': '[CI] EsqlNodeFailureIT testFailureLoadingFields failing',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This is the shell of the persistent task to reindex a data stream. '\n",
      "           'It includes the transport action that creates the persistent task, '\n",
      "           'returning the persistent task id. The persistent task currently '\n",
      "           'just looks up all indices for a data stream, finds the ones that '\n",
      "           'need upgrading, and then marks itself as complete. The actual '\n",
      "           'implementation of reindex will come later, as will the ability to '\n",
      "           'call it via a rest endpoint, and the ability to fetch the status '\n",
      "           'of the reindex based on the persistent task id.\\r\\n'\n",
      "           'Note that when the reindex task is complete, it actually schedules '\n",
      "           'the persistent task to complete in 1 day. This is to allow the '\n",
      "           'user (most likely the kibana upgrade assistant) up to 1 day to '\n",
      "           'check the status of a reindex after it completes. Related, this '\n",
      "           'means that a user must currently find and kill the task if they '\n",
      "           'want to run reindex again within 1 day of a failed run. This might '\n",
      "           'be improved in a future PR by using a unique persistent task id.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T13:59:50Z',\n",
      "  '_issueNumber': '117251',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Reindex data stream persistent task (#116780)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'checkPart4 is currently the longest build step and we want to try '\n",
      "           'running more in parallel first before looking into further '\n",
      "           'measures',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T13:49:29Z',\n",
      "  '_issueNumber': '117250',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Run checkpart 4 with configuration cache enabled',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '**Build Scans:**\\n'\n",
      "           '- [elasticsearch-periodic-platform-support #4946 / '\n",
      "           'rhel-9_platform-support-unix](https://gradle-enterprise.elastic.co/s/fzefbqrjrplxs)\\n'\n",
      "           '- [elasticsearch-pull-request #41604 / '\n",
      "           'part-1](https://gradle-enterprise.elastic.co/s/5fkidihvb2avk)\\n'\n",
      "           '\\n'\n",
      "           '**Reproduction Line:**\\n'\n",
      "           '```\\n'\n",
      "           './gradlew \":server:internalClusterTest\" --tests '\n",
      "           '\"org.elasticsearch.versioning.ConcurrentSeqNoVersioningIT.testSeqNoCASLinearizability\" '\n",
      "           '-Dtests.seed=13DFC458438680C3 -Dtests.locale=or '\n",
      "           '-Dtests.timezone=Portugal -Druntime.java=23\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '**Applicable branches:**\\n'\n",
      "           'main\\n'\n",
      "           '\\n'\n",
      "           '**Reproduces locally?:**\\n'\n",
      "           'N/A\\n'\n",
      "           '\\n'\n",
      "           '**Failure History:**\\n'\n",
      "           '[See '\n",
      "           \"dashboard](https://es-delivery-stats.elastic.dev/app/dashboards#/view/dcec9e60-72ac-11ee-8f39-55975ded9e63?_g=(refreshInterval:(pause:!t,value:60000),time:(from:now-7d%2Fd,to:now))&_a=(controlGroupState:(initialChildControlState:('0c0c9cb8-ccd2-45c6-9b13-96bac4abc542':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:task.keyword,order:0,selectedOptions:!(),title:'GradleTask',type:optionsListControl),'4e6ad9d6-6fdc-4fcc-bf1a-aa6ca79e0850':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:className.keyword,order:1,selectedOptions:!(org.elasticsearch.versioning.ConcurrentSeqNoVersioningIT),title:'Suite',type:optionsListControl),'144933da-5c1b-4257-a969-7f43455a7901':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:name.keyword,order:2,selectedOptions:!(testSeqNoCASLinearizability),title:'Test',type:optionsListControl)))))\\n\"\n",
      "           '\\n'\n",
      "           '**Failure Message:**\\n'\n",
      "           '```\\n'\n",
      "           \"java.lang.AssertionError: Index{id='ID:4', seqNo=3, primaryTerm=1, \"\n",
      "           'version=2, autoGeneratedIdTimestamp=-1}\\n'\n",
      "           'Expected: <2L>\\n'\n",
      "           '     but: was <1L>\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '**Issue Reasons:**\\n'\n",
      "           '- [main] 2 failures in test testSeqNoCASLinearizability (0.2% fail '\n",
      "           'rate in 825 executions)\\n'\n",
      "           '\\n'\n",
      "           '**Note:**\\n'\n",
      "           'This issue was created using new test triage automation. Please '\n",
      "           'report issues or feedback to es-delivery.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T13:29:15Z',\n",
      "  '_issueNumber': '117249',\n",
      "  '_repo': 'elasticsearch',\n",
      "  '_state': 'open',\n",
      "  '_title': '[CI] ConcurrentSeqNoVersioningIT testSeqNoCASLinearizability '\n",
      "            'failing',\n",
      "  '_type': 'issue'}]\n",
      "Fetching issues from: https://api.github.com/repos/milvus-io/pymilvus/issues\n",
      "[{'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           'When I do `MilvusClient().search(...., _async=True, ...)` I get an '\n",
      "           'exception:\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           'I expect `MIlvusClient().search(_async=True)` to return a '\n",
      "           'SearchFuture\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           \"I've added a PR to address this #2369\\n\"\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '- Hardware/Softward conditions (OS, CPU, GPU, Memory):\\r\\n'\n",
      "           '- Method of installation (Docker, or from source):\\r\\n'\n",
      "           '- Milvus version (v0.3.1, or v0.4.0):\\r\\n'\n",
      "           '- Milvus configuration (Settings you made in '\n",
      "           '`server_config.yaml`):\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T23:14:03Z',\n",
      "  '_issueNumber': '2370',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': \"[Bug]: MilvusClient.search doesn't support _async\",\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This pr allows MilvusClient to return a SearchFuture when '\n",
      "           '`_async=True`',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T23:11:40Z',\n",
      "  '_issueNumber': '2369',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': 'add _async support to MilvusClient.search',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [X] I have searched the existing issues\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Describe the bug\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This is similar to #2331 but it got retagged as a feature request. '\n",
      "           'The bug is:\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'collection.load()\\r\\n'\n",
      "           'milvus_client.search(data=data,filter=\"<partition_key> == '\n",
      "           '\\'a_partition_key\\'\")\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '1. This appears to be the only way to load partitions with '\n",
      "           'pymilvus but this looks like it loads the entire collection and '\n",
      "           'not just the relevant partition_key. Is there a way to only load '\n",
      "           'the partition?\\r\\n'\n",
      "           '2. When I do this search, I get results from all partitions. Not '\n",
      "           'just \"<partition_key> ==  \\'a_partition_key\\'\".\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Expected Behavior\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'collection.load(partition_key=\"a_partition_key\")\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'or something similar.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'milvus_client.search(data=data, filter=\"<partition_key> == '\n",
      "           '\\'a_partition_key\\'\"\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'should return results where only `partition_key` is '\n",
      "           '`\"a_partition_key\"`.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '_No response_\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Environment details\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```markdown\\r\\n'\n",
      "           'Pymilvus 2.4.9\\r\\n'\n",
      "           'Milvus Standalone docker container:latest\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Anything else?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-21T21:11:23Z',\n",
      "  '_issueNumber': '2368',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': \"[Bug]: Partition Key doesn't appear to function in pymilvus?\",\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'issue: [#2362](https://github.com/milvus-io/pymilvus/issues/2362)',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T04:31:50Z',\n",
      "  '_issueNumber': '2363',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Enhancement]: Add a property to ExtraList for extracting data',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [X] I have searched the existing issues\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### What would you like to be added?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I would like a property to be added to the `ExtraList` class that '\n",
      "           'allows users to extract its data. This property should make it '\n",
      "           'easy to use the underlying data without any additional structure '\n",
      "           'or formatting.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Why is this needed?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Currently, when using the latest master branch version, '\n",
      "           '`hybrid_search`, `search`, `query` and `get` functions of '\n",
      "           '`MilvusClient` class return an `ExtraList` object. While this is '\n",
      "           'helpful for additional metadata, it complicates situations where '\n",
      "           'the underlying data can not be accessed directly for further '\n",
      "           'processing or calculations.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Adding this feature will improve usability and make the class more '\n",
      "           'intuitive for users who need direct access to the data.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Anything else?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Current behavior:**\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'result = ExtraList([1, 2, 3], extra={\"total\": 3})\\r\\n'\n",
      "           \"print(result)  # Output: data: ['1', '2', '3'], extra_info: \"\n",
      "           \"{'total': 3}\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '# Attempting to process data\\r\\n'\n",
      "           \"sum(result)  # Fails, as `ExtraList` doesn't directly behave like \"\n",
      "           'a list for some operations.\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Desired behavior:**\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'result = ExtraList([1, 2, 3], extra={\"total\": 3})\\r\\n'\n",
      "           \"print(result.data)  # Output: ['1', '2', '3']\\r\\n\"\n",
      "           'sum(result.data)    # Works as expected.\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Here’s an example of the current issue when using ExtraList with '\n",
      "           'the Milvus query functionality:\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'from pymilvus import Collection, FieldSchema, CollectionSchema, '\n",
      "           'DataType, connections, MilvusClient\\r\\n'\n",
      "           'import random\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'connections.connect(\"default\", host=\"localhost\", port=\"19530\")\\r\\n'\n",
      "           'milvus_client = MilvusClient(\"http://localhost:19530\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Define schema and collection\\r\\n'\n",
      "           'schema = CollectionSchema([\\r\\n'\n",
      "           '    FieldSchema(\"film_id\", DataType.INT64, is_primary=True),\\r\\n'\n",
      "           '    FieldSchema(\"film_date\", DataType.INT64),\\r\\n'\n",
      "           '    FieldSchema(\"films\", dtype=DataType.FLOAT_VECTOR, dim=2)\\r\\n'\n",
      "           '])\\r\\n'\n",
      "           'collection = Collection(\"test_collection_query\", schema)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Insert sample data\\r\\n'\n",
      "           'data = [\\r\\n'\n",
      "           '    [i for i in range(10)],\\r\\n'\n",
      "           '    [i + 2000 for i in range(10)],\\r\\n'\n",
      "           '    [[random.random() for _ in range(2)] for _ in range(10)],\\r\\n'\n",
      "           ']\\r\\n'\n",
      "           'collection.insert(data)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Create index and load collection\\r\\n'\n",
      "           'index_param = {\"index_type\": \"FLAT\", \"metric_type\": \"L2\", '\n",
      "           '\"params\": {}}\\r\\n'\n",
      "           'collection.create_index(\"films\", index_param)\\r\\n'\n",
      "           'collection.load()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Perform query\\r\\n'\n",
      "           'expr = \"film_id == 3\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'res = milvus_client.query(\\r\\n'\n",
      "           \"    collection_name='test_collection_query',\\r\\n\"\n",
      "           '    filter=expr,\\r\\n'\n",
      "           '    output_fields=[\"film_date\"]\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Current behavior\\r\\n'\n",
      "           'print(res)  \\r\\n'\n",
      "           '# Output: data: [\"{\\'film_id\\': 3, \\'film_date\\': 2003}\"], cannot '\n",
      "           'access data directly\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Desired behavior with a new property\\r\\n'\n",
      "           'print(res.data)  \\r\\n'\n",
      "           '# Output: [\"{\\'film_id\\': 3, \\'film_date\\': 2003}\"], a plain list '\n",
      "           'object accessible for further calculations.\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           'In the example above, when querying the Milvus collection, it '\n",
      "           'returns an ExtraList. This structure makes it difficult to '\n",
      "           'directly extract the query result for further processing. Adding a '\n",
      "           '`.data` property or a similar method would allow users to directly '\n",
      "           'access the query results, making them easier to work with for '\n",
      "           'calculations, transformations, or other downstream processes.',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-20T04:27:32Z',\n",
      "  '_issueNumber': '2362',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Enhancement]: Add a property to ExtraList for extracting data '\n",
      "            'from result of search, query, get,... function of MilvusClient '\n",
      "            'class',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           'grpcio==1.68.0\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '![img_v3_02gp_ef3905a1-c54c-4ad1-8043-5d6e06f34deg](https://github.com/user-attachments/assets/572e6852-b9e0-4d74-abab-5fa0e4f22d4e)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'grpcio==1.60.0 not report connection error\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'fouram benchmark test case '\n",
      "           '`test_concurrent_locust_ivf_sq8_search_cluster` can reproduce this '\n",
      "           'issue\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '- Hardware/Softward conditions (OS, CPU, GPU, Memory):\\r\\n'\n",
      "           '- Method of installation (Docker, or from source):\\r\\n'\n",
      "           '- Milvus version (v0.3.1, or v0.4.0):\\r\\n'\n",
      "           '- Milvus configuration (Settings you made in '\n",
      "           '`server_config.yaml`):\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-19T11:36:11Z',\n",
      "  '_issueNumber': '2358',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: After grpcio is upgraded to 1.68.0, multi-threaded '\n",
      "            'concurrent dql request will report error `failed to connect to '\n",
      "            'all address`',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### What is your question?\\n'\n",
      "           '\\n'\n",
      "           'Not sure which is the problem, the versions look like are the '\n",
      "           'adequate. The code I am ussing and is failing is \\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           'from pymilvus import MilvusClient, FieldSchema, CollectionSchema, '\n",
      "           'DataType, Collection, Index\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '# Connect to Milvus\\r\\n'\n",
      "           'client = MilvusClient(\\r\\n'\n",
      "           '    uri=\"https://milvus.k8s.xxxxxxx.com\",\\r\\n'\n",
      "           '    db_name=\"default\"\\r\\n'\n",
      "           ')\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'This is milvus standalone deployed on a microk8s single node '\n",
      "           'cluster\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'the deployment has been done with helm\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T18:00:20Z',\n",
      "  '_issueNumber': '2355',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[QUESTION]: Milvus 2.4.15 - pymilvus 2.4.9 Message -> this '\n",
      "            'version of sdk is incompatible with server, please downgrade your '\n",
      "            'sdk or upgrade your server',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           'The check rule for the parameter \"collection_name\" of \"flush\" '\n",
      "           'interface is not consistent with that of \"create_collection\" '\n",
      "           'interface\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'when collection_name  is \"12-s\", create collection reports error '\n",
      "           '\"f\"Invalid collection name: {collection_name}. the first character '\n",
      "           'of a collection name must be an underscore or letter: invalid '\n",
      "           'parameter\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'but flush( \"12-s\") reports \"collection not '\n",
      "           'found[database=default][collection=12-s]\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '>>> milvus_client.create_collection(collection_name=\"12-s\", '\n",
      "           'dimension=8)\\r\\n'\n",
      "           'RPC error: [create_collection], <MilvusException: (code=1100, '\n",
      "           'message=Invalid collection name: 12-s. the first character of a '\n",
      "           'collection name must be an underscore or letter: invalid '\n",
      "           \"parameter)>, <Time:{'RPC start': '2024-11-15 16:14:50.873458', \"\n",
      "           \"'RPC error': '2024-11-15 16:14:50.898214'}>\\r\\n\"\n",
      "           'Failed to create collection: 12-s\\r\\n'\n",
      "           'Traceback (most recent call last):\\r\\n'\n",
      "           '  File \"<stdin>\", line 1, in <module>\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/milvus_client/milvus_client.py\", '\n",
      "           'line 80, in create_collection\\r\\n'\n",
      "           '    return self._fast_create_collection(\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/milvus_client/milvus_client.py\", '\n",
      "           'line 140, in _fast_create_collection\\r\\n'\n",
      "           '    raise ex from ex\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/milvus_client/milvus_client.py\", '\n",
      "           'line 136, in _fast_create_collection\\r\\n'\n",
      "           '    conn.create_collection(collection_name, schema, '\n",
      "           'timeout=timeout, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 141, in handler\\r\\n'\n",
      "           '    raise e from e\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 137, in handler\\r\\n'\n",
      "           '    return func(*args, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 176, in handler\\r\\n'\n",
      "           '    return func(self, *args, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 116, in handler\\r\\n'\n",
      "           '    raise e from e\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 86, in handler\\r\\n'\n",
      "           '    return func(*args, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/client/grpc_handler.py\", '\n",
      "           'line 309, in create_collection\\r\\n'\n",
      "           '    check_status(status)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/client/utils.py\", '\n",
      "           'line 63, in check_status\\r\\n'\n",
      "           '    raise MilvusException(status.code, status.reason, '\n",
      "           'status.error_code)\\r\\n'\n",
      "           'pymilvus.exceptions.MilvusException: <MilvusException: (code=1100, '\n",
      "           'message=Invalid collection name: 12-s. the first character of a '\n",
      "           'collection name must be an underscore or letter: invalid '\n",
      "           'parameter)>\\r\\n'\n",
      "           '>>>\\r\\n'\n",
      "           '>>>\\r\\n'\n",
      "           '>>> milvus_client.flush(collection_name=\"12-s\")\\r\\n'\n",
      "           'RPC error: [flush], <MilvusException: (code=100, '\n",
      "           'message=collection not found[database=default][collection=12-s])>, '\n",
      "           \"<Time:{'RPC start': '2024-11-15 16:15:37.485106', 'RPC error': \"\n",
      "           \"'2024-11-15 16:15:37.561322'}>\\r\\n\"\n",
      "           'Traceback (most recent call last):\\r\\n'\n",
      "           '  File \"<stdin>\", line 1, in <module>\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/milvus_client/milvus_client.py\", '\n",
      "           'line 1067, in flush\\r\\n'\n",
      "           '    conn.flush([collection_name], timeout=timeout, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 141, in handler\\r\\n'\n",
      "           '    raise e from e\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 137, in handler\\r\\n'\n",
      "           '    return func(*args, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 176, in handler\\r\\n'\n",
      "           '    return func(self, *args, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 116, in handler\\r\\n'\n",
      "           '    raise e from e\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 86, in handler\\r\\n'\n",
      "           '    return func(*args, **kwargs)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/client/grpc_handler.py\", '\n",
      "           'line 1458, in flush\\r\\n'\n",
      "           '    check_status(response.status)\\r\\n'\n",
      "           '  File '\n",
      "           '\"/Users/binbin/milvus_latest/lib/python3.8/site-packages/pymilvus/client/utils.py\", '\n",
      "           'line 63, in check_status\\r\\n'\n",
      "           '    raise MilvusException(status.code, status.reason, '\n",
      "           'status.error_code)\\r\\n'\n",
      "           'pymilvus.exceptions.MilvusException: <MilvusException: (code=100, '\n",
      "           'message=collection not '\n",
      "           'found[database=default][collection=12-s])>\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           'The check rule for the parameter \"collection_name\" of \"flush\" '\n",
      "           'interface is consistent with that of \"create_collection\" '\n",
      "           'interface\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           'from pymilvus import MilvusClient\\r\\n'\n",
      "           'milvus_client = MilvusClient()\\r\\n'\n",
      "           'milvus_client.create_collection(collection_name=\"12-s\", '\n",
      "           'dimension=8)\\r\\n'\n",
      "           'milvus_client.flush(collection_name=\"12-s\")\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '- Hardware/Softw',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T08:16:51Z',\n",
      "  '_issueNumber': '2354',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: [milvus_client_p2] The check rule for the parameter '\n",
      "            '\"collection_name\" of \"flush\" interface is not consistent with '\n",
      "            'that of \"create_collection\" interface',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           'https://github.com/milvus-io/pymilvus/blob/016ff553af24fa32fdebaf418b6afe23581bab71/pymilvus/orm/schema.py#L442\\r\\n'\n",
      "           'https://github.com/milvus-io/pymilvus/blob/0be8e7fc04b4536f012b1a5cc56d1ad7abee5db4/pymilvus/orm/schema.py#L353\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '- Hardware/Softward conditions (OS, CPU, GPU, Memory):\\r\\n'\n",
      "           '- Method of installation (Docker, or from source):\\r\\n'\n",
      "           '- Milvus version (v0.3.1, or v0.4.0):\\r\\n'\n",
      "           '- Milvus configuration (Settings you made in '\n",
      "           '`server_config.yaml`):\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T07:18:43Z',\n",
      "  '_issueNumber': '2352',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: Try best to cast type params key values',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Also optinal variables default value should always be None. And '\n",
      "           'empty str is always invalid variable\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'See also: #2327\\r\\n'\n",
      "           'pr: #2350',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T06:54:11Z',\n",
      "  '_issueNumber': '2351',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': 'fix: cannot pass consistency level for delete',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Also optinal variables default value should always be None.\\r\\n'\n",
      "           'And empty str is always invalid variable\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'See also: #2327',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T06:43:44Z',\n",
      "  '_issueNumber': '2350',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': 'fix: cannot pass consistency level for delete',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '- Added grpc as a valid protocol for uri (#2090)\\r\\n'\n",
      "           '- build(deps): bump urllib3 from 1.26.18 to 1.26.19 (#2140)\\r\\n'\n",
      "           '- build(deps): bump certifi from 2023.7.22 to 2024.7.4 (#2170)\\r\\n'\n",
      "           '- feat(pymilvus/settings.py): Load configuration without altering '\n",
      "           'the environment (#2192)\\r\\n'\n",
      "           '- feat: Add compact, get_server_version and flush api (#2326)\\r\\n'\n",
      "           '- Fix typo and correct grammar (#2333)\\r\\n'\n",
      "           '- Update return type of describe_role to Dict (#2337)\\r\\n'\n",
      "           '- enhance: Reorganize the examples (#2340)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Related: #2166, #2325, #2332',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-15T03:34:47Z',\n",
      "  '_issueNumber': '2349',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Multi cherry picks from master branch',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### What would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'Add **_async** parameter for query() interface, just like the '\n",
      "           'other interfaces such as search/insert/load\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Currently, the query() always wait the result:\\r\\n'\n",
      "           'https://github.com/milvus-io/pymilvus/blob/31101398e30245a279e707abcef1d92d24ae99e5/pymilvus/client/grpc_handler.py#L1539\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-13T09:12:18Z',\n",
      "  '_issueNumber': '2343',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Enhancement]: Support _async parameter for query()',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### What would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           \"Currently, the upload function in the RemoteBulkWriter class isn't \"\n",
      "           'yet equipped with a retry mechanism, leading to [almost silent] '\n",
      "           'upload failure if the remote storage system refuses to accept the '\n",
      "           'request. \\r\\n'\n",
      "           '\\r\\n'\n",
      "           'It would be good to equipe this function with a simple backup '\n",
      "           'mechanism, such as:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '# Upload function with retry\\r\\n'\n",
      "           'def _upload(self, file_path: str, object_name: str, max_retries: '\n",
      "           'int = 5):\\r\\n'\n",
      "           '        logger.info(f\"Prepare to upload \\'{file_path}\\' to '\n",
      "           '\\'{object_name}\\'\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        retry_count = 0\\r\\n'\n",
      "           '        while retry_count <= max_retries:\\r\\n'\n",
      "           '            try:\\r\\n'\n",
      "           '                # Check if Minio client\\r\\n'\n",
      "           '                if isinstance(self._client, Minio):\\r\\n'\n",
      "           '                    logger.info(f\"Target bucket: '\n",
      "           '\\'{self._connect_param._bucket_name}\\'\")\\r\\n'\n",
      "           '                    self._client.fput_object(\\r\\n'\n",
      "           '                        '\n",
      "           'bucket_name=self._connect_param._bucket_name,\\r\\n'\n",
      "           '                        object_name=object_name,\\r\\n'\n",
      "           '                        file_path=file_path,\\r\\n'\n",
      "           '                    )\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '                # Check if BlobServiceClient for Azure\\r\\n'\n",
      "           '                elif isinstance(self._client, '\n",
      "           'BlobServiceClient):\\r\\n'\n",
      "           '                    logger.info(f\"Target bucket: '\n",
      "           '\\'{self._connect_param._container_name}\\'\")\\r\\n'\n",
      "           '                    container_client = '\n",
      "           'self._client.get_container_client(\\r\\n'\n",
      "           '                        self._connect_param._container_name\\r\\n'\n",
      "           '                    )\\r\\n'\n",
      "           '                    with Path(file_path).open(\"rb\") as data:\\r\\n'\n",
      "           '                        container_client.upload_blob(\\r\\n'\n",
      "           '                            name=object_name,\\r\\n'\n",
      "           '                            data=data,\\r\\n'\n",
      "           '                            overwrite=True,\\r\\n'\n",
      "           '                            '\n",
      "           'max_concurrency=self._connect_param._upload_concurrency,\\r\\n'\n",
      "           '                            connection_timeout=600,\\r\\n'\n",
      "           '                        )\\r\\n'\n",
      "           '                \\r\\n'\n",
      "           '                else:\\r\\n'\n",
      "           '                    raise MilvusException(message=\"Blob storage '\n",
      "           'client is not initialized\")\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '                # If upload successful, log and exit\\r\\n'\n",
      "           '                logger.info(f\"Upload file \\'{file_path}\\' to '\n",
      "           '\\'{object_name}\\' succeeded\")\\r\\n'\n",
      "           '                break\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '            except S3Error as e:\\r\\n'\n",
      "           '                if isinstance(self._client, Minio) and retry_count '\n",
      "           '< max_retries:\\r\\n'\n",
      "           '                    wait_time = 2 ** retry_count  # Exponential '\n",
      "           'backoff\\r\\n'\n",
      "           '                    logger.warning(f\"Vinhn---SlowDown error. '\n",
      "           'Retrying in {wait_time} seconds...\")\\r\\n'\n",
      "           '                    time.sleep(wait_time)\\r\\n'\n",
      "           '                    retry_count += 1\\r\\n'\n",
      "           '                else:\\r\\n'\n",
      "           '                    logger.error(f\"Failed to upload '\n",
      "           '\\'{file_path}\\' to \\'{object_name}\\': {e}\")\\r\\n'\n",
      "           '                    raise\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '            except Exception as e:\\r\\n'\n",
      "           '                logger.error(f\"nexpected error while uploading '\n",
      "           '\\'{file_path}\\' to \\'{object_name}\\': {e}\")\\r\\n'\n",
      "           '                raise\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           'More robust file ingestion mechanism.\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           'https://github.com/milvus-io/pymilvus/blob/31101398e30245a279e707abcef1d92d24ae99e5/pymilvus/bulk_writer/remote_bulk_writer.py#L275',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-11T23:44:19Z',\n",
      "  '_issueNumber': '2341',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Enhancement]: Upload retry mechanism in RemoteBulkWriter class',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'enhance :\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'alterindex delete properties\\r\\n'\n",
      "           'We have introduced a new parameter deleteKeys to the alterindex '\n",
      "           'functionality, which allows for the deletion of properties within '\n",
      "           'an index. This enhancement provides users with the flexibility to '\n",
      "           'manage index properties more effectively by removing specific keys '\n",
      "           'as needed.\\r\\n'\n",
      "           'altercollection delete properties\\r\\n'\n",
      "           'We have introduced a new parameter deleteKeys to the '\n",
      "           'altercollection functionality, which allows for the deletion of '\n",
      "           'properties within an collection. This enhancement provides users '\n",
      "           'with the flexibility to manage collection properties more '\n",
      "           'effectively by removing specific keys as needed.\\r\\n'\n",
      "           '3.support altercollectionfield\\r\\n'\n",
      "           'We currently support modifying the fieldparams of a field in a '\n",
      "           'collection using altercollectionfield, which only allows changes '\n",
      "           'to the max-length attribute.\\r\\n'\n",
      "           'Key Points:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'New Parameter - deleteKeys: This new parameter enables the '\n",
      "           'deletion of specified properties from an index. By passing a list '\n",
      "           'of keys to deleteKeys, users can remove the corresponding '\n",
      "           'properties from the index.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Mutual Exclusivity: The deleteKeys parameter cannot be used in '\n",
      "           'conjunction with the extraParams parameter. Users must choose one '\n",
      "           'parameter to pass based on their requirement. If deleteKeys is '\n",
      "           'provided, it indicates an intent to delete properties; if '\n",
      "           'extraParams is provided, it signifies the addition or update of '\n",
      "           'properties.\\r\\n'\n",
      "           'issue :https://github.com/milvus-io/pymilvus/issues/2338',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-08T03:22:28Z',\n",
      "  '_issueNumber': '2339',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': 'enhance: alterindex & altercollection supports altering '\n",
      "            'properties ',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### What would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'alterindex & altercollection supports altering properties\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-08T03:21:53Z',\n",
      "  '_issueNumber': '2338',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Enhancement]: alterindex & altercollection supports altering '\n",
      "            'properties',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [X] I have searched the existing issues\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Describe the bug\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'hi!\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I want to inform you that the search with the partition key does '\n",
      "           'not work\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"Let's first look at the documentation \"\n",
      "           '[here](https://milvus.io/docs/use-partition-key.md#Use-Partition-Key), '\n",
      "           \"what's notable is that you don't call the load collection or load \"\n",
      "           'partition method into memory. Apparently it is assumed that the '\n",
      "           'presence of a partitioning key will cause the partition to be '\n",
      "           'loaded from the filter expression automatically inside Milvus, but '\n",
      "           'it doesnt work, because Milvus throw the errors: '\n",
      "           '`<MilvusException: (code=65535, message=not support manually '\n",
      "           'specifying the partition names if partition key mode is used)>`, '\n",
      "           '`<MilvusException: (code=65535, message=disable load partitions if '\n",
      "           'partition key mode is used)>`\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '**Workaround**\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'For example, here is my collection, which has a **partition key** '\n",
      "           '- `category` field:\\r\\n'\n",
      "           '<img width=\"964\" alt=\"image\" '\n",
      "           'src=\"https://github.com/user-attachments/assets/48ab3dda-dc2a-4633-9701-316250a9401e\">\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I made my code by analogy with the code in the documentation: this '\n",
      "           'means that I call the `search` method without calling the '\n",
      "           '`load_collection` or `load_partitions`, while in the filter '\n",
      "           'expression I have a filter on the field which is the partition '\n",
      "           'key. In this case Milvus throw the next error: `<MilvusException: '\n",
      "           '(code=101, message=failed to search: collection not '\n",
      "           'loaded[collection=452934647721745216])>`\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Ok... if milvus asks to load a collection, then knowing that the '\n",
      "           'collection has a partition key, I don’t want to load the entire '\n",
      "           'collection, but only the required partition. Hence I will call the '\n",
      "           '`load_partitions` method, but Milvus throw error '\n",
      "           '`<MilvusException: (code=65535, message=not support manually '\n",
      "           'specifying the partition names if partition key mode is used)>`. '\n",
      "           'In this situation Milvus literally leaves no choice and forces me '\n",
      "           'to unload the entire collection into memory\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '---\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I have two questions:\\r\\n'\n",
      "           '1. Is the example code in the documentation wrong? \\r\\n'\n",
      "           '2. How can I load only the required partition into memory if I '\n",
      "           'have a partitioning key?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I make a full code example where I demonstrated cases of how I '\n",
      "           'tried to do a search by partition\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Expected Behavior\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I see two ways to fix the situation:\\r\\n'\n",
      "           '* I want to be able to load partitions using the `load_partitions` '\n",
      "           'method in the current configuration (when we have a partition key '\n",
      "           'in the collection);\\r\\n'\n",
      "           '* Milvus automatically loads partitions into memory if we pass the '\n",
      "           'corresponding field names in the filter expression\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python3\\r\\n'\n",
      "           'import logging\\r\\n'\n",
      "           'from random import Random\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'from pymilvus import MilvusClient, DataType\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'def create_milvus_client(uri: str, token: str) -> MilvusClient:\\r\\n'\n",
      "           '    return MilvusClient(uri=uri, token=token)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class BaseMilvusCollection:\\r\\n'\n",
      "           \"    db_name: str = 'default'\\r\\n\"\n",
      "           '    collection_name = None\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def __init__(self, *, client: MilvusClient):\\r\\n'\n",
      "           '        self.client = client\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def get_schema(self):\\r\\n'\n",
      "           '        raise NotImplementedError\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def get_index_params(self):\\r\\n'\n",
      "           '        raise NotImplementedError\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def create(self):\\r\\n'\n",
      "           '        schema = self.get_schema()\\r\\n'\n",
      "           '        index_params = self.get_index_params()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        self.client.create_collection(\\r\\n'\n",
      "           '            schema=schema,\\r\\n'\n",
      "           '            index_params=index_params,\\r\\n'\n",
      "           '            collection_name=self.collection_name,\\r\\n'\n",
      "           '        )\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class Detections(BaseMilvusCollection):\\r\\n'\n",
      "           \"    collection_name = 'test_collection'\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '    def get_schema(self):\\r\\n'\n",
      "           '        # https://milvus.io/docs/use-partition-key.md\\r\\n'\n",
      "           '        schema = self.client.create_schema(\\r\\n'\n",
      "           \"            partition_key_field='category',\\r\\n\"\n",
      "           '        )\\r\\n'\n",
      "           '        schema.add_field(\\r\\n'\n",
      "           \"            field_name='id',\\r\\n\"\n",
      "           '            datatype=DataType.INT64,\\r\\n'\n",
      "           '            auto_id=True,\\r\\n'\n",
      "           '            is_primary=True,\\r\\n'\n",
      "           '        )\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        schema.add_field(\\r\\n'\n",
      "           \"            field_name='category',\\r\\n\"\n",
      "           '            datatype=DataType.VARCHAR,\\r\\n'\n",
      "           '            max_length=200,\\r\\n'\n",
      "           '        )\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"        schema.add_field(field_name='metadata', \"\n",
      "           'datatype=DataType.JSON)\\r\\n'\n",
      "           \"        schema.add_field(field_name='detection_pk', \"\n",
      "           'datatype=DataType.INT64)\\r\\n'\n",
      "           \"        schema.add_field(field_name='vector', \"\n",
      "           'datatype=DataType.FLOAT_VECTOR, dim=64)\\r\\n'\n",
      "           '        return schema\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def get_index_params(self):\\r\\n'\n",
      "           '        index_params = self.client.prepare_index_params()\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        index_params.add_index(\\r\\n'\n",
      "           \"            field_name='vector',\\r\\n\"\n",
      "           \"            index_type='IVF_FLAT',\\r\\n\"\n",
      "           \"            metric_type='COSINE',\\r\\n\"\n",
      "           \"            params={'nlist': 128},\\r\\n\"\n",
      "           '        )\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        return index_params\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'class BaseMilvusRepository:\\r\\n'\n",
      "           '    collection_name = None\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def __init__(self, *, client: MilvusClient):\\r\\n'\n",
      "           '        if self.collection_name is None:\\r\\n'\n",
      "           \"            msg = 'Collection name not specified!'\\r\\n\"\n",
      "           '            raise Exception(msg)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '        self.logger = logging.getLogger(__name__)\\r\\n'\n",
      "           '        self.client = client\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    def release_collection(self) -> None:\\r\\n'\n",
      "           '        self.client.release_collection(collection_name',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-06T12:56:01Z',\n",
      "  '_issueNumber': '2331',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: search vectors doesnt work with partition key',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '- [X] I have searched the existing issues\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Describe the bug\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'When I do\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           \"my_collection.delete(expr='...', consistency_level='Strong')  # Or \"\n",
      "           'any `consistency_level` for that matter\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I get the following error:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           '    @retry_on_rpc_failure()\\r\\n'\n",
      "           '    def delete(\\r\\n'\n",
      "           '        self,\\r\\n'\n",
      "           '        collection_name: str,\\r\\n'\n",
      "           '        expression: str,\\r\\n'\n",
      "           '        partition_name: Optional[str] = None,\\r\\n'\n",
      "           '        timeout: Optional[float] = None,\\r\\n'\n",
      "           '        **kwargs,\\r\\n'\n",
      "           '    ):\\r\\n'\n",
      "           '        check_pass_param(collection_name=collection_name, '\n",
      "           'timeout=timeout)\\r\\n'\n",
      "           '        try:\\r\\n'\n",
      "           '>           req = Prepare.delete_request(\\r\\n'\n",
      "           '                collection_name,\\r\\n'\n",
      "           '                partition_name,\\r\\n'\n",
      "           '                expression,\\r\\n'\n",
      "           '                consistency_level=kwargs.get(\"consistency_level\", '\n",
      "           '0),\\r\\n'\n",
      "           '                param_name=kwargs.pop(\"param_name\", None),\\r\\n'\n",
      "           '                **kwargs,\\r\\n'\n",
      "           '            )\\r\\n'\n",
      "           'E           TypeError: '\n",
      "           'pymilvus.client.prepare.Prepare.delete_request() got multiple '\n",
      "           \"values for keyword argument 'consistency_level'\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '/usr/local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py:597: '\n",
      "           'TypeError\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Expected Behavior\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'To not fail\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'All you need to do is pass the `consistency_level` to the `delete` '\n",
      "           'method. This bug is directly due to the use of `kwargs.get` in the '\n",
      "           'function in order to populate a \"new\" keyword argument called '\n",
      "           '`consistency_level` in addition to the existing one. It should '\n",
      "           'happen no matter the other circumstances.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Environment details\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```markdown\\r\\n'\n",
      "           '- Hardware/Softward conditions: (OS: `6.10.0-linuxkit` Docker '\n",
      "           'Desktop on Mac running Linux using the image `python:3.12-slim`, '\n",
      "           'CPU: Apple M2 Pro, Memory: 8GB)\\r\\n'\n",
      "           '- Method of installation (Docker, or from source): A Docker image, '\n",
      "           \"as mentioned above. I'm using LangChain, so technically not \"\n",
      "           'calling the collection directly. `langchain-milvus==0.1.4`\\r\\n'\n",
      "           '- Milvus version (v0.3.1, or v0.4.0): Milvus is running using the '\n",
      "           'Docker image `milvusdb/milvus:v2.4.6`\\r\\n'\n",
      "           '- Milvus configuration (Settings you made in '\n",
      "           \"`server_config.yaml`): Didn't change anything.\\r\\n\"\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '### Anything else?\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'The bug is inherit in that call in the code, it basically will '\n",
      "           'never work if `consistency_level` is provided. It looks like a '\n",
      "           'direct result of this change: '\n",
      "           'https://github.com/milvus-io/pymilvus/commit/cb4cbc6e8672f11c40bfe3dd41ec6c08408ecfc5\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"The solution could be to change the `.get` to `.pop` but it's \"\n",
      "           \"worth making sure it's not going to be a problem with the line \\r\\n\"\n",
      "           '\\r\\n'\n",
      "           '```python\\r\\n'\n",
      "           '                f = MutationFuture(future, cb, timeout=timeout, '\n",
      "           '**kwargs)\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"which is also inside this function (I wasn't able to fully follow \"\n",
      "           'the logic of `MutationFuture`).',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-06T10:11:26Z',\n",
      "  '_issueNumber': '2327',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: `TypeError` if `consistency_level` is passed to '\n",
      "            '`Collection.delete`',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### What would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'I would like to add `compact`, `get_compaction_state`, `flush` and '\n",
      "           '`get_server_version` in `MilvusClient`.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           ' def flush(\\r\\n'\n",
      "           '        self,\\r\\n'\n",
      "           '        collection_name: str,\\r\\n'\n",
      "           '        timeout: Optional[float] = None,\\r\\n'\n",
      "           '        **kwargs):\\r\\n'\n",
      "           '        pass\\r\\n'\n",
      "           '        \\r\\n'\n",
      "           ' \\r\\n'\n",
      "           'def compact(\\r\\n'\n",
      "           '        self,\\r\\n'\n",
      "           '        collection_name: str,\\r\\n'\n",
      "           '        is_clustering: Optional[bool] = False,\\r\\n'\n",
      "           '        timeout: Optional[float] = None,\\r\\n'\n",
      "           '        **kwargs,\\r\\n'\n",
      "           '    ) -> int:\\r\\n'\n",
      "           '    return job_id\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'def get_compaction_state(\\r\\n'\n",
      "           '        self,\\r\\n'\n",
      "           '        job_id: int,\\r\\n'\n",
      "           '        timeout: Optional[float] = None,\\r\\n'\n",
      "           '        **kwargs,\\r\\n'\n",
      "           '    ) -> str:\\r\\n'\n",
      "           '    \"\"\"\\r\\n'\n",
      "           '       Possible values are \"UndefiedState\", \"Executing\" and '\n",
      "           '\"Completed\".\\r\\n'\n",
      "           '    \"\"\"\\r\\n'\n",
      "           '    return \"\"\\r\\n'\n",
      "           ' \\r\\n'\n",
      "           'def get_server_version(\\r\\n'\n",
      "           '        self,\\r\\n'\n",
      "           '        timeout: Optional[float] = None,\\r\\n'\n",
      "           '        **kwargs,\\r\\n'\n",
      "           '    ) -> str:\\r\\n'\n",
      "           '    return \"\"\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           'sync with Collection(orm).\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-06T06:26:39Z',\n",
      "  '_issueNumber': '2325',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Enhancement]: Add compact, flush and get_server_version api in '\n",
      "            'MilvusClient',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'This pull request handle **Normalization** function mentioned here '\n",
      "           '[milvus-io/milvus/#27469](https://github.com/milvus-io/milvus/issues/27469)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Run: `examples/example_normalization_fields.py` to evaluate my '\n",
      "           'pull request.\\r\\n',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-11-04T16:29:49Z',\n",
      "  '_issueNumber': '2322',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': 'normalize vector data to a standard form during insertion '\n",
      "            '(#27469)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           \"I'm using Kotaemon, that is a RAG that by default uses milvus \"\n",
      "           'lite, when moving to a external milvus and inserting items, I got '\n",
      "           'this error:\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'dynamic field exceeds max length (65536)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'I have tried to reduce the size of the metadata but still the '\n",
      "           'error raises, is there a way to expand the size of the metadata '\n",
      "           'field?\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '-\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '- Hardware/Softward conditions (OS, CPU, GPU, Memory):\\r\\n'\n",
      "           '- Method of installation (Docker, or from source):\\r\\n'\n",
      "           '- Milvus version (v0.3.1, or v0.4.0):\\r\\n'\n",
      "           '- Milvus configuration (Settings you made in '\n",
      "           '`server_config.yaml`):\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           'PC error: [insert_rows], <MilvusException: (code=1100, message=the '\n",
      "           'length (381827) of dynamic field exceeds max length (65536): '\n",
      "           'invalid parameter[expected=valid length dynamic '\n",
      "           \"field][actual=length exceeds max length])>, <Time:{'RPC start': \"\n",
      "           \"'2024-10-29 07:36:26.031426', 'RPC error': '2024-10-29 \"\n",
      "           \"07:36:26.449905'}>\\r\\n\"\n",
      "           'Exception in thread Thread-4 (<lambda>):\\r\\n'\n",
      "           'Traceback (most recent call last):\\r\\n'\n",
      "           'File \"/usr/local/lib/python3.10/threading.py\", line 1016, in '\n",
      "           '_bootstrap_inner\\r\\n'\n",
      "           'self.run()\\r\\n'\n",
      "           'File \"/usr/local/lib/python3.10/threading.py\", line 953, in run\\r\\n'\n",
      "           'self._target(*self._args, **self._kwargs)\\r\\n'\n",
      "           'File \"/app/libs/ktem/ktem/index/file/pipelines.py\", line 399, in '\n",
      "           '<lambda>\\r\\n'\n",
      "           'target=lambda: list(insert_chunks_to_vectorstore())\\r\\n'\n",
      "           'File \"/app/libs/ktem/ktem/index/file/pipelines.py\", line 387, in '\n",
      "           'insert_chunks_to_vectorstore\\r\\n'\n",
      "           'self.handle_chunks_vectorstore(chunks, file_id)\\r\\n'\n",
      "           'File \"/app/libs/ktem/ktem/index/file/pipelines.py\", line 429, in '\n",
      "           'handle_chunks_vectorstore\\r\\n'\n",
      "           'self.vector_indexing.add_to_vectorstore(chunks)\\r\\n'\n",
      "           'File \"/app/libs/kotaemon/kotaemon/indices/vectorindex.py\", line '\n",
      "           '139, in add_to_vectorstore\\r\\n'\n",
      "           'self.vector_store.add(\\r\\n'\n",
      "           'File '\n",
      "           '\"/app/libs/kotaemon/kotaemon/storages/vectorstores/milvus.py\", '\n",
      "           'line 106, in add\\r\\n'\n",
      "           'return super().add(embeddings=embeddings, metadatas=metadatas, '\n",
      "           'ids=ids)\\r\\n'\n",
      "           'File \"/app/libs/kotaemon/kotaemon/storages/vectorstores/base.py\", '\n",
      "           'line 135, in add\\r\\n'\n",
      "           'return self._client.add(nodes=nodes)\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/llama_index/vector_stores/milvus/base.py\", '\n",
      "           'line 364, in add\\r\\n'\n",
      "           'self._collection.insert(insert_batch)\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/pymilvus/orm/collection.py\", '\n",
      "           'line 507, in insert\\r\\n'\n",
      "           'return conn.insert_rows(\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 148, in handler\\r\\n'\n",
      "           'raise e from e\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 144, in handler\\r\\n'\n",
      "           'return func(*args, **kwargs)\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 183, in handler\\r\\n'\n",
      "           'return func(self, *args, **kwargs)\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 123, in handler\\r\\n'\n",
      "           'raise e from e\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/pymilvus/decorators.py\", '\n",
      "           'line 87, in handler\\r\\n'\n",
      "           'return func(*args, **kwargs)\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/pymilvus/client/grpc_handler.py\", '\n",
      "           'line 496, in insert_rows\\r\\n'\n",
      "           'check_status(resp.status)\\r\\n'\n",
      "           'File '\n",
      "           '\"/usr/local/lib/python3.10/site-packages/pymilvus/client/utils.py\", '\n",
      "           'line 63, in check_status\\r\\n'\n",
      "           'raise MilvusException(status.code, status.reason, '\n",
      "           'status.error_code)\\r\\n'\n",
      "           'pymilvus.exceptions.MilvusException: <MilvusException: (code=1100, '\n",
      "           'message=the length (381827) of dynamic field exceeds max length '\n",
      "           '(65536): invalid parameter[expected=valid length dynamic '\n",
      "           'field][actual=length exceeds max length])>',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-29T09:50:09Z',\n",
      "  '_issueNumber': '2318',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: dynamic field exceeds max length (65536)',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### What is your question?\\n'\n",
      "           '\\n'\n",
      "           'While I try to run this program to run example.py \\r\\n'\n",
      "           '![Screenshot from 2024-10-28 '\n",
      "           '18-14-01](https://github.com/user-attachments/assets/f7c296d4-4dd8-4cd9-9a45-97a667777c00)\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '![Screenshot from 2024-10-28 '\n",
      "           '18-13-50](https://github.com/user-attachments/assets/6d59dfdb-aa98-414f-a53b-06497a18bd70)\\r\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-28T13:23:17Z',\n",
      "  '_issueNumber': '2315',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[QUESTION]: Facing Error while running example.py',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           'When the bulk writer fails to generate a file, it internally '\n",
      "           'handles the error instead of throwing it out, which is not a '\n",
      "           'reasonable behavior.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Data path '\n",
      "           'created: /Applications/PyCharm '\n",
      "           'CE.app/Contents/plugins/python-ce/helpers/pycharm/bulk_writer '\n",
      "           '(local_bulk_writer.py:77)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Data path '\n",
      "           'created: /Applications/PyCharm '\n",
      "           'CE.app/Contents/plugins/python-ce/helpers/pycharm/bulk_writer/6c82cb06-dff3-4dcf-ba6e-e2a48c89f262 '\n",
      "           '(local_bulk_writer.py:82)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - remote_bulk_writer]: Minio/S3 blob '\n",
      "           'storage client successfully initialized '\n",
      "           '(remote_bulk_writer.py:157)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - remote_bulk_writer]: Remote buffer '\n",
      "           'writer initialized, target path: '\n",
      "           '/bulk_data/6c82cb06-dff3-4dcf-ba6e-e2a48c89f262 '\n",
      "           '(remote_bulk_writer.py:123)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Prepare to flush '\n",
      "           'buffer, row_count: 1000, size: 1360576 '\n",
      "           '(local_bulk_writer.py:109)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Flush thread '\n",
      "           'begin, name: Thread-10 (local_bulk_writer.py:116)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - ERROR - local_bulk_writer]: Failed to '\n",
      "           'fulsh, error: int() argument must be a string, a bytes-like object '\n",
      "           \"or a number, not 'NoneType' (local_bulk_writer.py:142)\\r\\n\"\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Wait flush to '\n",
      "           'finish (local_bulk_writer.py:120)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Flush thread '\n",
      "           'finished, name: Thread-10 (local_bulk_writer.py:146)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Commit done with '\n",
      "           'async=False (local_bulk_writer.py:124)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - ci_test]: bulk insert files: [] '\n",
      "           '(test_bulk_insert.py:1874)\\r\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '- Hardware/Softward conditions (OS, CPU, GPU, Memory):\\r\\n'\n",
      "           '- Method of installation (Docker, or from source):\\r\\n'\n",
      "           '- Milvus version (v0.3.1, or v0.4.0):\\r\\n'\n",
      "           '- Milvus configuration (Settings you made in '\n",
      "           '`server_config.yaml`):\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-28T02:41:26Z',\n",
      "  '_issueNumber': '2314',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: When the bulkwriter fails to generate a file, it returns '\n",
      "            'an empty list instead of throwing an error.',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           '```\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - ERROR - local_bulk_writer]: Failed to '\n",
      "           'fulsh, error: int() argument must be a string, a bytes-like object '\n",
      "           \"or a number, not 'NoneType' (local_bulk_writer.py:142)\\r\\n\"\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '[2024-10-25 19:42:27 - INFO - ci_test]: '\n",
      "           '################################################################################ '\n",
      "           '(conftest.py:232)\\r\\n'\n",
      "           '[2024-10-25 19:42:27 - INFO - ci_test]: [initialize_milvus] Log '\n",
      "           'cleaned up, start testing... (conftest.py:233)\\r\\n'\n",
      "           '[2024-10-25 19:42:27 - INFO - ci_test]: [setup_class] Start setup '\n",
      "           'class... (client_base.py:40)\\r\\n'\n",
      "           '[2024-10-25 19:42:27 - INFO - ci_test]: '\n",
      "           '*********************************** setup '\n",
      "           '*********************************** (client_base.py:46)\\r\\n'\n",
      "           '[2024-10-25 19:42:27 - INFO - ci_test]: [setup_method] Start setup '\n",
      "           'test case test_with_all_field_csv_with_bulk_writer. '\n",
      "           '(client_base.py:47)\\r\\n'\n",
      "           '-------------------------------- live log call '\n",
      "           '---------------------------------\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Data path '\n",
      "           'created: /Applications/PyCharm '\n",
      "           'CE.app/Contents/plugins/python-ce/helpers/pycharm/bulk_writer '\n",
      "           '(local_bulk_writer.py:77)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Data path '\n",
      "           'created: /Applications/PyCharm '\n",
      "           'CE.app/Contents/plugins/python-ce/helpers/pycharm/bulk_writer/6c82cb06-dff3-4dcf-ba6e-e2a48c89f262 '\n",
      "           '(local_bulk_writer.py:82)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - remote_bulk_writer]: Minio/S3 blob '\n",
      "           'storage client successfully initialized '\n",
      "           '(remote_bulk_writer.py:157)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - remote_bulk_writer]: Remote buffer '\n",
      "           'writer initialized, target path: '\n",
      "           '/bulk_data/6c82cb06-dff3-4dcf-ba6e-e2a48c89f262 '\n",
      "           '(remote_bulk_writer.py:123)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Prepare to flush '\n",
      "           'buffer, row_count: 1000, size: 1360576 '\n",
      "           '(local_bulk_writer.py:109)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Flush thread '\n",
      "           'begin, name: Thread-10 (local_bulk_writer.py:116)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - ERROR - local_bulk_writer]: Failed to '\n",
      "           'fulsh, error: int() argument must be a string, a bytes-like object '\n",
      "           \"or a number, not 'NoneType' (local_bulk_writer.py:142)\\r\\n\"\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Wait flush to '\n",
      "           'finish (local_bulk_writer.py:120)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Flush thread '\n",
      "           'finished, name: Thread-10 (local_bulk_writer.py:146)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Commit done with '\n",
      "           'async=False (local_bulk_writer.py:124)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - ci_test]: bulk insert files: [] '\n",
      "           '(test_bulk_insert.py:1874)\\r\\n'\n",
      "           '[2024-10-25 19:42:28 - INFO - local_bulk_writer]: Delete local '\n",
      "           \"directory '/Applications/PyCharm \"\n",
      "           \"CE.app/Contents/plugins/python-ce/helpers/pycharm/bulk_writer/6c82cb06-dff3-4dcf-ba6e-e2a48c89f262' \"\n",
      "           '(local_bulk_writer.py:88)\\r\\n'\n",
      "           '[2024-10-25 19:42:29 - INFO - ci_test]:  collection entities: 0 '\n",
      "           '(test_bulk_insert.py:1889)\\r\\n'\n",
      "           'FAILED\\r\\n'\n",
      "           'testcases/test_bulk_insert.py:1806 '\n",
      "           '(TestBulkInsert.test_with_all_field_csv_with_bulk_writer[doc-True-True-1000-128-True])\\r\\n'\n",
      "           '0 != 1000\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'Expected :1000\\r\\n'\n",
      "           'Actual   :0\\r\\n'\n",
      "           '<Click to see difference>\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'self = <test_bulk_insert.TestBulkInsert object at 0x130eae7c0>, '\n",
      "           'auto_id = True\\r\\n'\n",
      "           'dim = 128, entities = 1000, enable_dynamic_field = True, '\n",
      "           \"sparse_format = 'doc'\\r\\n\"\n",
      "           'nullable = True\\r\\n'\n",
      "           '\\r\\n'\n",
      "           '    @pytest.mark.tags(CaseLabel.L3)\\r\\n'\n",
      "           '    @pytest.mark.parametrize(\"auto_id\", [True, False])\\r\\n'\n",
      "           '    @pytest.mark.parametrize(\"dim\", [128])  # 128\\r\\n'\n",
      "           '    @pytest.mark.parametrize(\"entities\", [1000])  # 1000\\r\\n'\n",
      "           '    @pytest.mark.parametrize(\"enable_dynamic_field\", [True, '\n",
      "           'False])\\r\\n'\n",
      "           '    @pytest.mark.parametrize(\"nullable\", [True, False])\\r\\n'\n",
      "           '    @pytest.mark.parametrize(\"sparse_format\", [\"doc\", \"coo\"])\\r\\n'\n",
      "           '    def test_with_all_field_csv_with_bulk_writer(self, auto_id, '\n",
      "           'dim, entities, enable_dynamic_field, sparse_format, nullable):\\r\\n'\n",
      "           '        \"\"\"\\r\\n'\n",
      "           '        \"\"\"\\r\\n'\n",
      "           '        self._connect()\\r\\n'\n",
      "           '        fields = [\\r\\n'\n",
      "           '            cf.gen_int64_field(name=df.pk_field, is_primary=True, '\n",
      "           'auto_id=auto_id),\\r\\n'\n",
      "           '            cf.gen_int64_field(name=df.int_field, '\n",
      "           'nullable=nullable),\\r\\n'\n",
      "           '            cf.gen_float_field(name=df.float_field, '\n",
      "           'nullable=nullable),\\r\\n'\n",
      "           '            cf.gen_string_field(name=df.string_field, '\n",
      "           'nullable=nullable),\\r\\n'\n",
      "           '            cf.gen_json_field(name=df.json_field, '\n",
      "           'nullable=nullable),\\r\\n'\n",
      "           '            cf.gen_array_field(name=df.array_int_field, '\n",
      "           'element_type=DataType.INT64, nullable=nullable),\\r\\n'\n",
      "           '            cf.gen_array_field(name=df.array_float_field, '\n",
      "           'element_type=DataType.FLOAT, nullable=nullable),\\r\\n'\n",
      "           '            cf.gen_array_field(name=df.array_string_field, '\n",
      "           'element_type=DataType.VARCHAR, max_length=100, '\n",
      "           'nullable=nullable),\\r\\n'\n",
      "           '            cf.gen_array_field(name=df.array_bool_field, '\n",
      "           'element_type=DataType.BOOL, nullable=nullable),\\r\\n'\n",
      "           '            cf.gen_float_vec_field(name=df.float_vec_field, '\n",
      "           'dim=dim),\\r\\n'\n",
      "           '            cf.gen_float16_vec_field(name=df.fp16_vec_field, '\n",
      "           'dim=dim),\\r\\n'\n",
      "           '            cf.gen_bfloat16_vec_field(name=df.bf16_vec_field, '\n",
      "           'dim=dim),\\r\\n'\n",
      "           '            cf.gen_sparse_vec_field(name=df.sparse_vec_field),\\r\\n'\n",
      "           '        ]\\r\\n'\n",
      "           '        c_name = cf.gen_uniqu',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-25T11:45:27Z',\n",
      "  '_issueNumber': '2313',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: The bulk writer cannot convert nullable data to a CSV '\n",
      "            'file.',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [ ] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           'Function and FunctionType are not found in pymilvus 2.4.4/2.4.8\\r\\n'\n",
      "           '![1729842220596](https://github.com/user-attachments/assets/039d9761-49b1-40ee-b24d-9341fff377bc)\\r\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '- Hardware/Softward conditions (OS, CPU, GPU, Memory):\\r\\n'\n",
      "           '- Method of installation (Docker, or from source):\\r\\n'\n",
      "           '- Milvus version (v0.3.1, or v0.4.0):\\r\\n'\n",
      "           '- Milvus configuration (Settings you made in '\n",
      "           '`server_config.yaml`):\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-25T08:04:22Z',\n",
      "  '_issueNumber': '2312',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': \"[Bug]: ImportError: cannot import name 'Function' from 'pymilvus'\",\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           'The `MilvusClient.create_index()` method expects an `IndexParams` '\n",
      "           \"type, but this type isn't exposed in the public API.\\r\\n\"\n",
      "           '\\r\\n'\n",
      "           'The create_index signature requires it.\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '    def create_index(\\r\\n'\n",
      "           '        self,\\r\\n'\n",
      "           '        collection_name: str,\\r\\n'\n",
      "           '        index_params: IndexParams,\\r\\n'\n",
      "           '        timeout: Optional[float] = None,\\r\\n'\n",
      "           '        **kwargs,\\r\\n'\n",
      "           '    ):\\r\\n'\n",
      "           '```\\r\\n'\n",
      "           '\\r\\n'\n",
      "           \"But I can't import this type.\\r\\n\"\n",
      "           '```\\r\\n'\n",
      "           '>>> from pymilvus import IndexParams\\r\\n'\n",
      "           \"ImportError: cannot import name 'IndexParams' from 'pymilvus'\\r\\n\"\n",
      "           '>>> from pymilvus.index import IndexParams  \\r\\n'\n",
      "           \"ModuleNotFoundError: No module named 'pymilvus.index'\\r\\n\"\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-25T00:58:18Z',\n",
      "  '_issueNumber': '2311',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: IndexParams type required by create_index() but not '\n",
      "            'exposed in public API',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### What would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           '1. fix int pk cannot be writen into cp file\\r\\n'\n",
      "           '2. remove cp file after close\\r\\n'\n",
      "           '3. wrap io operations with try-except\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-22T07:25:21Z',\n",
      "  '_issueNumber': '2306',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Enhancement]: Iterator cp file is not handled correctly in some '\n",
      "            'cases',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### What would you like to be added?\\n'\n",
      "           '\\n'\n",
      "           'currently we validate server schema by comparing with user '\n",
      "           'provided schema '\n",
      "           'https://github.com/milvus-io/pymilvus/blob/76de0ab1caba89a939a784545e1a61d13ea139a3/pymilvus/orm/collection.py#L134.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'with doc in doc out, we introduced `tokenizer_params` in `params`, '\n",
      "           'which is a dict in user input, but a json string in server '\n",
      "           'response. direct comparing will cause a failure.\\r\\n'\n",
      "           '\\r\\n'\n",
      "           'now the `tokenizer_params` is simple so I used a temp resolution '\n",
      "           'in https://github.com/milvus-io/pymilvus/pull/2298 to convert the '\n",
      "           'json string back to a dict, but that will likely fail after we '\n",
      "           'introduced more configs in `tokenizer_params`: keys in json may be '\n",
      "           'reordered and the resulting dict will no longer equal.\\n'\n",
      "           '\\n'\n",
      "           '### Why is this needed?\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-15T03:35:49Z',\n",
      "  '_issueNumber': '2299',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Enhancement]: schema validation is fragile',\n",
      "  '_type': 'issue'},\n",
      " {'_body': '### Is there an existing issue for this?\\n'\n",
      "           '\\n'\n",
      "           '- [X] I have searched the existing issues\\n'\n",
      "           '\\n'\n",
      "           '### Describe the bug\\n'\n",
      "           '\\n'\n",
      "           'QueryIterator cannot iterate through all data in the target '\n",
      "           'collection.\\n'\n",
      "           '\\n'\n",
      "           '### Expected Behavior\\n'\n",
      "           '\\n'\n",
      "           'Iterator go through all data without any loss\\n'\n",
      "           '\\n'\n",
      "           '### Steps/Code To Reproduce behavior\\n'\n",
      "           '\\n'\n",
      "           '_No response_\\n'\n",
      "           '\\n'\n",
      "           '### Environment details\\n'\n",
      "           '\\n'\n",
      "           '```markdown\\n'\n",
      "           '- Hardware/Softward conditions (OS, CPU, GPU, Memory):\\r\\n'\n",
      "           '- Method of installation (Docker, or from source):\\r\\n'\n",
      "           '- Milvus version (v0.3.1, or v0.4.0):\\r\\n'\n",
      "           '- Milvus configuration (Settings you made in '\n",
      "           '`server_config.yaml`):\\n'\n",
      "           '```\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           '### Anything else?\\n'\n",
      "           '\\n'\n",
      "           '_No response_',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-12T01:53:29Z',\n",
      "  '_issueNumber': '2292',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': '[Bug]: Query iterator handle offset incorrectly',\n",
      "  '_type': 'issue'},\n",
      " {'_body': 'Fix: https://github.com/milvus-io/pymilvus/issues/2161',\n",
      "  '_closedAt': 'None',\n",
      "  '_createdAt': '2024-10-09T05:17:53Z',\n",
      "  '_issueNumber': '2285',\n",
      "  '_repo': 'pymilvus',\n",
      "  '_state': 'open',\n",
      "  '_title': 'Add database name to alias dictionary for retrieval in '\n",
      "            'list_connections',\n",
      "  '_type': 'issue'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "# Define the GitHub base URL\n",
    "base_url = \"https://api.github.com/repos\"\n",
    "\n",
    "# Method that returns the base url\n",
    "def fetch_url(owner, repo):\n",
    "    return f\"https://\"+headers[\"Git_Username\"]+\":\"+headers[\"access_token\"]+f\"@api.github.com/repos/{owner}/{repo}\"\n",
    "\n",
    "# Set your token here\n",
    "token = \"\"\n",
    "\n",
    "# Define from_date for comparison (make sure it's set properly)\n",
    "from_date = \"2023-01-01\"  # Example date\n",
    "\n",
    "# Loop through the owner-repo combinations\n",
    "for owner, repo in zip(owners, repos):\n",
    "    repo_url = f\"{base_url}/{owner}/{repo}/issues\"\n",
    "    response = requests.get(repo_url, headers={\"Authorization\": f\"token {token}\"})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Fetching issues from: {repo_url}\")\n",
    "        issues = response.json()\n",
    "\n",
    "        # Ensure the response is a list of issues\n",
    "        if not isinstance(issues, list):\n",
    "            print(f\"Unexpected response format for {owner}/{repo}: {issues}\")\n",
    "            break\n",
    "\n",
    "        # Create a new list for processed issues to avoid modifying the list while iterating\n",
    "        processed_issues = []\n",
    "\n",
    "        # Process each issue in the list\n",
    "        for obj in issues:\n",
    "            try:\n",
    "                created_at = obj.get(\"created_at\", \"\")\n",
    "                # Check if 'created_at' is not empty before processing\n",
    "                if created_at:\n",
    "                    if datetime.strptime(from_date, \"%Y-%m-%d\") <= datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%SZ\"):\n",
    "                        issueObject = {\n",
    "                            \"_type\": \"issue\",\n",
    "                            \"_repo\": repo,\n",
    "                            \"_issueNumber\": str(obj.get('number', \"\")),\n",
    "                            \"_title\": str(obj.get('title', \"\")),\n",
    "                            \"_createdAt\": created_at,\n",
    "                            \"_closedAt\": str(obj.get('closed_at', \"2024-12-31T00:36:30Z\")),\n",
    "                            \"_state\": str(obj.get('state', \"\")),\n",
    "                            \"_body\": str(obj.get('body', \"\"))[:5000]\n",
    "                        }\n",
    "                        processed_issues.append(issueObject)\n",
    "                else:\n",
    "                    print(\"Skipping issue with missing 'created_at'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing issue: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Print the processed issues\n",
    "        pprint(processed_issues)\n",
    "\n",
    "    else:\n",
    "        print(f\"Repository {owner}/{repo} not found or inaccessible. Skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7843a0f6-914f-417f-9733-179d3787498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'active_lock_reason': None,\n",
      " 'assignee': None,\n",
      " 'assignees': [],\n",
      " 'author_association': 'NONE',\n",
      " 'body': '### Is there an existing issue for this?\\n'\n",
      "         '\\n'\n",
      "         '- [X] I have searched the existing issues\\n'\n",
      "         '\\n'\n",
      "         '### Describe the bug\\n'\n",
      "         '\\n'\n",
      "         'When I do `MilvusClient().search(...., _async=True, ...)` I get an '\n",
      "         'exception:\\n'\n",
      "         '\\n'\n",
      "         '### Expected Behavior\\n'\n",
      "         '\\n'\n",
      "         'I expect `MIlvusClient().search(_async=True)` to return a '\n",
      "         'SearchFuture\\n'\n",
      "         '\\n'\n",
      "         '### Steps/Code To Reproduce behavior\\n'\n",
      "         '\\n'\n",
      "         '```markdown\\n'\n",
      "         \"I've added a PR to address this #2369\\n\"\n",
      "         '```\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '### Environment details\\n'\n",
      "         '\\n'\n",
      "         '```markdown\\n'\n",
      "         '- Hardware/Softward conditions (OS, CPU, GPU, Memory):\\r\\n'\n",
      "         '- Method of installation (Docker, or from source):\\r\\n'\n",
      "         '- Milvus version (v0.3.1, or v0.4.0):\\r\\n'\n",
      "         '- Milvus configuration (Settings you made in `server_config.yaml`):\\n'\n",
      "         '```\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '### Anything else?\\n'\n",
      "         '\\n'\n",
      "         '_No response_',\n",
      " 'closed_at': None,\n",
      " 'closed_by': None,\n",
      " 'comments': 0,\n",
      " 'comments_url': 'https://api.github.com/repos/milvus-io/pymilvus/issues/2370/comments',\n",
      " 'created_at': '2024-11-21T23:14:03Z',\n",
      " 'events_url': 'https://api.github.com/repos/milvus-io/pymilvus/issues/2370/events',\n",
      " 'html_url': 'https://github.com/milvus-io/pymilvus/issues/2370',\n",
      " 'id': 2681264184,\n",
      " 'labels': [{'color': 'd73a4a',\n",
      "             'default': False,\n",
      "             'description': \"Something isn't working\",\n",
      "             'id': 1404544374,\n",
      "             'name': 'kind/bug',\n",
      "             'node_id': 'MDU6TGFiZWwxNDA0NTQ0Mzc0',\n",
      "             'url': 'https://api.github.com/repos/milvus-io/pymilvus/labels/kind/bug'}],\n",
      " 'labels_url': 'https://api.github.com/repos/milvus-io/pymilvus/issues/2370/labels{/name}',\n",
      " 'locked': False,\n",
      " 'milestone': None,\n",
      " 'node_id': 'I_kwDOC23lUc6f0Ng4',\n",
      " 'number': 2370,\n",
      " 'performed_via_github_app': None,\n",
      " 'reactions': {'+1': 0,\n",
      "               '-1': 0,\n",
      "               'confused': 0,\n",
      "               'eyes': 0,\n",
      "               'heart': 0,\n",
      "               'hooray': 0,\n",
      "               'laugh': 0,\n",
      "               'rocket': 0,\n",
      "               'total_count': 0,\n",
      "               'url': 'https://api.github.com/repos/milvus-io/pymilvus/issues/2370/reactions'},\n",
      " 'repository_url': 'https://api.github.com/repos/milvus-io/pymilvus',\n",
      " 'state': 'open',\n",
      " 'state_reason': None,\n",
      " 'timeline_url': 'https://api.github.com/repos/milvus-io/pymilvus/issues/2370/timeline',\n",
      " 'title': \"[Bug]: MilvusClient.search doesn't support _async\",\n",
      " 'updated_at': '2024-11-21T23:14:03Z',\n",
      " 'url': 'https://api.github.com/repos/milvus-io/pymilvus/issues/2370',\n",
      " 'user': {'avatar_url': 'https://avatars.githubusercontent.com/u/9318247?v=4',\n",
      "          'events_url': 'https://api.github.com/users/drawnwren/events{/privacy}',\n",
      "          'followers_url': 'https://api.github.com/users/drawnwren/followers',\n",
      "          'following_url': 'https://api.github.com/users/drawnwren/following{/other_user}',\n",
      "          'gists_url': 'https://api.github.com/users/drawnwren/gists{/gist_id}',\n",
      "          'gravatar_id': '',\n",
      "          'html_url': 'https://github.com/drawnwren',\n",
      "          'id': 9318247,\n",
      "          'login': 'drawnwren',\n",
      "          'node_id': 'MDQ6VXNlcjkzMTgyNDc=',\n",
      "          'organizations_url': 'https://api.github.com/users/drawnwren/orgs',\n",
      "          'received_events_url': 'https://api.github.com/users/drawnwren/received_events',\n",
      "          'repos_url': 'https://api.github.com/users/drawnwren/repos',\n",
      "          'site_admin': False,\n",
      "          'starred_url': 'https://api.github.com/users/drawnwren/starred{/owner}{/repo}',\n",
      "          'subscriptions_url': 'https://api.github.com/users/drawnwren/subscriptions',\n",
      "          'type': 'User',\n",
      "          'url': 'https://api.github.com/users/drawnwren',\n",
      "          'user_view_type': 'public'}}\n"
     ]
    }
   ],
   "source": [
    "#Sample Issue\n",
    "pprint(issues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449551ce-f1fd-4c1c-83d3-e4d24fa6ba49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e6c3e7d-032d-414c-88af-db7d82cd4be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#Number of Issues in the given timeframe\n",
    "pprint(len(issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c232e5-aa18-4187-b838-3a3b1732ff35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68599a46-1c6b-4897-a4e6-190059999f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of Issues to a DataFrame\n",
    "df_Issues = pd.DataFrame(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ecc4d-cf70-410f-bf16-68bb298a39ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a0a26fa-5fce-4e10-b2b1-5011a43d733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all NaN values with None in columns as elasticsearch does not recognize it\n",
    "df_Issues.fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76669868-930c-4af6-a8c9-c43b3f2f7af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ce3ebd-bbd5-4edc-a5ab-ca1ef4c6779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embeddings from OpenAI API\n",
    "def embed(texts):\n",
    "    # Make a request to OpenAI API to get embeddings\n",
    "    embeddings = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model='text-embedding-ada-002'\n",
    "    )\n",
    "    # Extract embeddings from the API response\n",
    "    return [result.embedding for result in embeddings.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83e0c9-0b7b-48fa-a1a2-6eea57961218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89df7bc0-1fd5-485b-a9c2-29283dfe7907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_Issues: Index(['url', 'repository_url', 'labels_url', 'comments_url', 'events_url',\n",
      "       'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels',\n",
      "       'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments',\n",
      "       'created_at', 'updated_at', 'closed_at', 'author_association',\n",
      "       'active_lock_reason', 'body', 'closed_by', 'reactions', 'timeline_url',\n",
      "       'performed_via_github_app', 'state_reason', 'draft', 'pull_request'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 9897.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding all batches.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "openai.api_key = \"\"  # Replace with your actual API key\n",
    "\n",
    "def embed_with_retry(data, retries=5):\n",
    "    \"\"\"Embed data with retries in case of connection errors.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = openai.embeddings.create(input=data, model=\"text-embedding-ada-002\")\n",
    "            # Access the embeddings from the response object using .data attribute\n",
    "            return [item.embedding for item in response.data]  # Correct access for response data\n",
    "        except openai.APIConnectionError as e:  # Retry logic for connection errors\n",
    "            if attempt < retries - 1:\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                print(f\"Connection error, retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(\"Failed after multiple retries.\")\n",
    "                raise\n",
    "        except openai.error.APIError as e:  # Handle API-specific errors\n",
    "            print(f\"API error occurred: {e}\")\n",
    "            raise\n",
    "        except Exception as e:  # Catch any other errors\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize the embeddings list and batch processing\n",
    "Issue_embeddings = []\n",
    "batch_size = 500\n",
    "data = [[]]\n",
    "\n",
    "# Check if the DataFrame has correct columns\n",
    "print(\"Columns in df_Issues:\", df_Issues.columns)\n",
    "\n",
    "# Loop through the DataFrame and prepare the data for embedding\n",
    "for i in tqdm(range(0, len(df_Issues))):\n",
    "    # Make sure to replace '_title' and '_body' with the correct column names\n",
    "    title = str(df_Issues.iloc[i].get('title', '')).replace(\"\\n\", \"\")  # Use the actual column name\n",
    "    body = str(df_Issues.iloc[i].get('body', '')).replace(\"\\n\", \"\")  # Use the actual column name\n",
    "    combined_text = f\"Repository:{owner}/{repo} Issue Title:{title} Issue Body:{body}\"\n",
    "    \n",
    "    data[0].append(combined_text)\n",
    "    \n",
    "    # Process data in batches\n",
    "    if len(data[0]) % batch_size == 0:\n",
    "        print(\"Embedding batch...\")\n",
    "        embeddings_batch = embed_with_retry(data[0])\n",
    "        Issue_embeddings.extend(embeddings_batch)\n",
    "        data = [[]]\n",
    "        print(\"Waiting for 1 minute before the next batch...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "# Embed the remaining data if any\n",
    "if len(data[0]) != 0:\n",
    "    embeddings_rem = embed_with_retry(data[0])\n",
    "    Issue_embeddings.extend(embeddings_rem)\n",
    "\n",
    "print(\"Finished embedding all batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340dacbf-ef0a-4f7c-b13f-427c37113eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a630d2f2-346a-4927-8bd6-761b097f09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Generated embeddings to GitHub_Issue_vector column in the dataframe\n",
    "\n",
    "df_Issues[\"GitHub_Issue_vector\"] = Issue_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca323fed-13c1-4636-bebb-dd7c3257e5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a3c634e-a209-4f00-9ed5-59bc16ad45df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>body</th>\n",
       "      <th>closed_by</th>\n",
       "      <th>reactions</th>\n",
       "      <th>timeline_url</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "      <th>state_reason</th>\n",
       "      <th>draft</th>\n",
       "      <th>pull_request</th>\n",
       "      <th>GitHub_Issue_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvus</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://github.com/milvus-io/pymilvus/issues/2311</td>\n",
       "      <td>2612824165</td>\n",
       "      <td>I_kwDOC23lUc6bvIhl</td>\n",
       "      <td>2311</td>\n",
       "      <td>[Bug]: IndexParams type required by create_ind...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>### Is there an existing issue for this?\\n\\n- ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/milvus-i...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.007584445644170046, 0.015350805595517159, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvus</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://github.com/milvus-io/pymilvus/issues/2306</td>\n",
       "      <td>2604522709</td>\n",
       "      <td>I_kwDOC23lUc6bPdzV</td>\n",
       "      <td>2306</td>\n",
       "      <td>[Enhancement]: Iterator cp file is not handled...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>### Is there an existing issue for this?\\n\\n- ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/milvus-i...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.019045177847146988, 0.012543156743049622, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvus</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://github.com/milvus-io/pymilvus/issues/2299</td>\n",
       "      <td>2587539268</td>\n",
       "      <td>I_kwDOC23lUc6aOrdE</td>\n",
       "      <td>2299</td>\n",
       "      <td>[Enhancement]: schema validation is fragile</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>### Is there an existing issue for this?\\n\\n- ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/milvus-i...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.002528787823393941, 0.007733011618256569, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvus</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://github.com/milvus-io/pymilvus/issues/2292</td>\n",
       "      <td>2582406088</td>\n",
       "      <td>I_kwDOC23lUc6Z7GPI</td>\n",
       "      <td>2292</td>\n",
       "      <td>[Bug]: Query iterator handle offset incorrectly</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>### Is there an existing issue for this?\\n\\n- ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/milvus-i...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.04156330227851868, -0.026999227702617645, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvus</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>https://github.com/milvus-io/pymilvus/pull/2285</td>\n",
       "      <td>2574784993</td>\n",
       "      <td>PR_kwDOC23lUc5-Bndd</td>\n",
       "      <td>2285</td>\n",
       "      <td>Add database name to alias dictionary for retr...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Fix: https://github.com/milvus-io/pymilvus/iss...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/milvus-i...</td>\n",
       "      <td>https://api.github.com/repos/milvus-io/pymilvu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/milvus-i...</td>\n",
       "      <td>[-0.017571212723851204, -0.016792472451925278,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "25  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "26  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "27  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "28  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "29  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "\n",
       "                                     repository_url  \\\n",
       "25  https://api.github.com/repos/milvus-io/pymilvus   \n",
       "26  https://api.github.com/repos/milvus-io/pymilvus   \n",
       "27  https://api.github.com/repos/milvus-io/pymilvus   \n",
       "28  https://api.github.com/repos/milvus-io/pymilvus   \n",
       "29  https://api.github.com/repos/milvus-io/pymilvus   \n",
       "\n",
       "                                           labels_url  \\\n",
       "25  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "26  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "27  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "28  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "29  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "\n",
       "                                         comments_url  \\\n",
       "25  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "26  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "27  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "28  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "29  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "\n",
       "                                           events_url  \\\n",
       "25  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "26  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "27  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "28  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "29  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "\n",
       "                                             html_url          id  \\\n",
       "25  https://github.com/milvus-io/pymilvus/issues/2311  2612824165   \n",
       "26  https://github.com/milvus-io/pymilvus/issues/2306  2604522709   \n",
       "27  https://github.com/milvus-io/pymilvus/issues/2299  2587539268   \n",
       "28  https://github.com/milvus-io/pymilvus/issues/2292  2582406088   \n",
       "29    https://github.com/milvus-io/pymilvus/pull/2285  2574784993   \n",
       "\n",
       "                node_id  number  \\\n",
       "25   I_kwDOC23lUc6bvIhl    2311   \n",
       "26   I_kwDOC23lUc6bPdzV    2306   \n",
       "27   I_kwDOC23lUc6aOrdE    2299   \n",
       "28   I_kwDOC23lUc6Z7GPI    2292   \n",
       "29  PR_kwDOC23lUc5-Bndd    2285   \n",
       "\n",
       "                                                title  ... active_lock_reason  \\\n",
       "25  [Bug]: IndexParams type required by create_ind...  ...               None   \n",
       "26  [Enhancement]: Iterator cp file is not handled...  ...               None   \n",
       "27        [Enhancement]: schema validation is fragile  ...               None   \n",
       "28    [Bug]: Query iterator handle offset incorrectly  ...               None   \n",
       "29  Add database name to alias dictionary for retr...  ...               None   \n",
       "\n",
       "                                                 body closed_by  \\\n",
       "25  ### Is there an existing issue for this?\\n\\n- ...      None   \n",
       "26  ### Is there an existing issue for this?\\n\\n- ...      None   \n",
       "27  ### Is there an existing issue for this?\\n\\n- ...      None   \n",
       "28  ### Is there an existing issue for this?\\n\\n- ...      None   \n",
       "29  Fix: https://github.com/milvus-io/pymilvus/iss...      None   \n",
       "\n",
       "                                            reactions  \\\n",
       "25  {'url': 'https://api.github.com/repos/milvus-i...   \n",
       "26  {'url': 'https://api.github.com/repos/milvus-i...   \n",
       "27  {'url': 'https://api.github.com/repos/milvus-i...   \n",
       "28  {'url': 'https://api.github.com/repos/milvus-i...   \n",
       "29  {'url': 'https://api.github.com/repos/milvus-i...   \n",
       "\n",
       "                                         timeline_url  \\\n",
       "25  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "26  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "27  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "28  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "29  https://api.github.com/repos/milvus-io/pymilvu...   \n",
       "\n",
       "   performed_via_github_app state_reason  draft  \\\n",
       "25                     None         None   None   \n",
       "26                     None         None   None   \n",
       "27                     None         None   None   \n",
       "28                     None         None   None   \n",
       "29                     None         None  False   \n",
       "\n",
       "                                         pull_request  \\\n",
       "25                                               None   \n",
       "26                                               None   \n",
       "27                                               None   \n",
       "28                                               None   \n",
       "29  {'url': 'https://api.github.com/repos/milvus-i...   \n",
       "\n",
       "                                  GitHub_Issue_vector  \n",
       "25  [-0.007584445644170046, 0.015350805595517159, ...  \n",
       "26  [-0.019045177847146988, 0.012543156743049622, ...  \n",
       "27  [0.002528787823393941, 0.007733011618256569, 0...  \n",
       "28  [-0.04156330227851868, -0.026999227702617645, ...  \n",
       "29  [-0.017571212723851204, -0.016792472451925278,...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the new Column is created\n",
    "df_Issues.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682465d1-0413-4e65-8f0d-62a1579bb3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95e897aa-f073-4e35-9c2f-645ae5fdee44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure Elasticsearch connection\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "es.ping()   #connection testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8622726-a3cf-4a62-a0d9-8d1d57511de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2118a2e8-5c50-49b0-aec5-882a76f606e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x1308e3ad0>: Failed to establish a new connection: [Errno 61] Connection refused))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    200\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m    202\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[1;32m    203\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elastic_transport/_node/_http_urllib3.py:167\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    165\u001b[0m     body_to_send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    168\u001b[0m     method,\n\u001b[1;32m    169\u001b[0m     target,\n\u001b[1;32m    170\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody_to_send,\n\u001b[1;32m    171\u001b[0m     retries\u001b[38;5;241m=\u001b[39mRetry(\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    172\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    174\u001b[0m )\n\u001b[1;32m    175\u001b[0m response_headers \u001b[38;5;241m=\u001b[39m HttpHeaders(response\u001b[38;5;241m.\u001b[39mheaders)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[1;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    845\u001b[0m )\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/util/retry.py:449\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m error:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# Disabled, indicate to re-raise the error.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[1;32m    451\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    496\u001b[0m         method,\n\u001b[1;32m    497\u001b[0m         url,\n\u001b[1;32m    498\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    499\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    500\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    501\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    502\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    503\u001b[0m         enforce_content_length\u001b[38;5;241m=\u001b[39menforce_content_length,\n\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:441\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:279\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:214\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x13051cda0>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Index Mapping for githubissues\u001b[39;00m\n\u001b[1;32m      3\u001b[0m index_mapping\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      5\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGitHub_Issue_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m    }\n\u001b[1;32m     20\u001b[0m }\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m es\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mexists(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgithub_issues\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     23\u001b[0m     es\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdelete(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgithub_issues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m es\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mcreate(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgithub_issues\u001b[39m\u001b[38;5;124m\"\u001b[39m, body\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmappings\u001b[39m\u001b[38;5;124m\"\u001b[39m: index_mapping})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m api(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/indices.py:1227\u001b[0m, in \u001b[0;36mIndicesClient.exists\u001b[0;34m(self, index, allow_no_indices, error_trace, expand_wildcards, filter_path, flat_settings, human, ignore_unavailable, include_defaults, local, pretty)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     __query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretty\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretty\n\u001b[1;32m   1226\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 1227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_request(  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1229\u001b[0m     __path,\n\u001b[1;32m   1230\u001b[0m     params\u001b[38;5;241m=\u001b[39m__query,\n\u001b[1;32m   1231\u001b[0m     headers\u001b[38;5;241m=\u001b[39m__headers,\n\u001b[1;32m   1232\u001b[0m     endpoint_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices.exists\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1233\u001b[0m     path_parts\u001b[38;5;241m=\u001b[39m__path_parts,\n\u001b[1;32m   1234\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/_base.py:423\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    412\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[1;32m    424\u001b[0m         method,\n\u001b[1;32m    425\u001b[0m         path,\n\u001b[1;32m    426\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    427\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    428\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    429\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    430\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts,\n\u001b[1;32m    431\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_request(\n\u001b[1;32m    272\u001b[0m             method,\n\u001b[1;32m    273\u001b[0m             path,\n\u001b[1;32m    274\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    275\u001b[0m             headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    276\u001b[0m             body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    277\u001b[0m             otel_span\u001b[38;5;241m=\u001b[39motel_span,\n\u001b[1;32m    278\u001b[0m         )\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/_base.py:316\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     target \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m--> 316\u001b[0m meta, resp_body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[1;32m    317\u001b[0m     method,\n\u001b[1;32m    318\u001b[0m     target,\n\u001b[1;32m    319\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[1;32m    320\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    321\u001b[0m     request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_timeout,\n\u001b[1;32m    322\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_retries,\n\u001b[1;32m    323\u001b[0m     retry_on_status\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_on_status,\n\u001b[1;32m    324\u001b[0m     retry_on_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_on_timeout,\n\u001b[1;32m    325\u001b[0m     client_meta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_meta,\n\u001b[1;32m    326\u001b[0m     otel_span\u001b[38;5;241m=\u001b[39motel_span,\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m299\u001b[39m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m     )\n\u001b[1;32m    338\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elastic_transport/_transport.py:342\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta, otel_span)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     otel_span\u001b[38;5;241m.\u001b[39mset_node_metadata(node\u001b[38;5;241m.\u001b[39mhost, node\u001b[38;5;241m.\u001b[39mport, node\u001b[38;5;241m.\u001b[39mbase_url, target)\n\u001b[0;32m--> 342\u001b[0m     resp \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[1;32m    343\u001b[0m         method,\n\u001b[1;32m    344\u001b[0m         target,\n\u001b[1;32m    345\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest_body,\n\u001b[1;32m    346\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[1;32m    347\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [status:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m duration:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         )\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elastic_transport/_node/_http_urllib3.py:202\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    194\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e), errors\u001b[38;5;241m=\u001b[39m(e,))\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    196\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    197\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m         exception\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    201\u001b[0m     )\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    204\u001b[0m meta \u001b[38;5;241m=\u001b[39m ApiResponseMeta(\n\u001b[1;32m    205\u001b[0m     node\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    206\u001b[0m     duration\u001b[38;5;241m=\u001b[39mduration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresponse_headers,\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    212\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    213\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m     response\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    218\u001b[0m )\n",
      "\u001b[0;31mConnectionError\u001b[0m: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x1308e3ad0>: Failed to establish a new connection: [Errno 61] Connection refused))"
     ]
    }
   ],
   "source": [
    "#Index Mapping for githubissues\n",
    "\n",
    "index_mapping= {\n",
    "    \"properties\": {\n",
    "      \"GitHub_Issue_vector\": {\n",
    "          \"type\": \"dense_vector\",\n",
    "          \"dims\": 1536,\n",
    "          \"index\": \"true\",\n",
    "          \"similarity\": \"cosine\"\n",
    "      },\n",
    "     \"_type\": {\"type\": \"text\"}, \n",
    "     \"_repo\":{\"type\":\"text\"},   \n",
    "     \"_issueNumber\": {\"type\": \"long\"},    \n",
    "     \"_title\": {\"type\": \"text\"},\n",
    "     \"_createdAt\": {\"type\": \"date\"},\n",
    "     \"_closedAt\": {\"type\": \"date\"},\n",
    "     \"_state\": {\"type\": \"text\"},\n",
    "     \"_body\": {\"type\": \"text\"}\n",
    "   }\n",
    "}\n",
    "\n",
    "if es.indices.exists(index=\"github_issues\"):\n",
    "    es.indices.delete(index=\"github_issues\")\n",
    "\n",
    "es.indices.create(index=\"github_issues\", body={\"mappings\": index_mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dca088-74bc-4d7f-914f-a1d6d382a86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aaa748c-0660-46ae-a0cc-9571ba1c5b8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     batch_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(batch_start \u001b[38;5;241m+\u001b[39m batch_size, end)\n\u001b[1;32m     26\u001b[0m     batch_dataframe \u001b[38;5;241m=\u001b[39m df_Issues\u001b[38;5;241m.\u001b[39miloc[batch_start:batch_end]\n\u001b[0;32m---> 27\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dataframe_to_bulk_actions(df_Issues\u001b[38;5;241m.\u001b[39miloc[start:end]))\n\u001b[1;32m     29\u001b[0m success, failed \u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mbulk(es, actions)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuccess\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records into Elasticsearch. Failed records: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m, in \u001b[0;36mdataframe_to_bulk_actions\u001b[0;34m(df_Issues)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataframe_to_bulk_actions\u001b[39m(df_Issues):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df_Issues\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m {\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithub_issues\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m----> 8\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_type\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_repo\u001b[39m\u001b[38;5;124m\"\u001b[39m:row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_repo\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_issueNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_issueNumber\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     11\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_title\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_title\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     12\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_createdAt\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_createdAt\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     13\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_closedAt\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_closedAt\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_state\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     15\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_body\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_body\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     16\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGitHub_Issue_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGitHub_Issue_vector\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m             }\n\u001b[1;32m     18\u001b[0m         }\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '_type'"
     ]
    }
   ],
   "source": [
    "# Bulk indexing for githubissues\n",
    "\n",
    "def dataframe_to_bulk_actions(df_Issues):\n",
    "    for index, row in df_Issues.iterrows():\n",
    "        yield {\n",
    "            \"_index\": 'github_issues',\n",
    "            \"_source\": {\n",
    "                \"_type\": row['_type'],\n",
    "                \"_repo\":row['_repo'],\n",
    "                \"_issueNumber\": row['_issueNumber'],\n",
    "                \"_title\": row['_title'],\n",
    "                \"_createdAt\": row['_createdAt'],\n",
    "                \"_closedAt\": row['_closedAt'],\n",
    "                \"_state\": row['_state'],\n",
    "                \"_body\": row['_body'],\n",
    "                \"GitHub_Issue_vector\": row['GitHub_Issue_vector']\n",
    "            }\n",
    "        }\n",
    "\n",
    "start = 0\n",
    "end = len(df_Issues)\n",
    "batch_size = 500\n",
    "\n",
    "for batch_start in range(start, end, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, end)\n",
    "    batch_dataframe = df_Issues.iloc[batch_start:batch_end]\n",
    "    actions = list(dataframe_to_bulk_actions(df_Issues.iloc[start:end]))\n",
    "    \n",
    "success, failed = helpers.bulk(es, actions)\n",
    "print(f\"Inserted {success} records into Elasticsearch. Failed records: {failed}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad5509",
   "metadata": {},
   "source": [
    "#Bar Chart to plot issues by day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cac75e1-947c-40c7-bc53-d6159b9becaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'_createdAt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '_createdAt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Add a new column 'day_of_week' to the dataframe\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df_Issues[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_Issues[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_createdAt\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday_name()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Group by repository and day of the week, then count the issues\u001b[39;00m\n\u001b[1;32m      8\u001b[0m issues_by_day \u001b[38;5;241m=\u001b[39m df_Issues\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_repo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '_createdAt'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for analytics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add a new column 'day_of_week' to the dataframe\n",
    "df_Issues['day_of_week'] = pd.to_datetime(df_Issues['_createdAt']).dt.day_name()\n",
    "\n",
    "# Group by repository and day of the week, then count the issues\n",
    "issues_by_day = df_Issues.groupby(['_repo', 'day_of_week']).size().reset_index(name='count')\n",
    "\n",
    "# Sort the days of the week for proper visualization\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "issues_by_day['day_of_week'] = pd.Categorical(issues_by_day['day_of_week'], categories=day_order, ordered=True)\n",
    "\n",
    "# Plot bar chart for each repo\n",
    "for repo in repos:\n",
    "    repo_issues = issues_by_day[issues_by_day['_repo'] == repo]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(repo_issues['day_of_week'], repo_issues['count'], color='skyblue')\n",
    "    plt.title(f\"Issues by Day of the Week for Repo: {repo}\", fontsize=16)\n",
    "    plt.xlabel(\"Day of the Week\", fontsize=14)\n",
    "    plt.ylabel(\"Number of Issues\", fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e179d7",
   "metadata": {},
   "source": [
    "Top 5 most similar issues using vector embeddings and semantic search\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f854fe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 similar issues for repo: langchain\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/psr2hs7d1t1gbb8mkpb__0gm0000gn/T/ipykernel_3285/1473559807.py:20: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  results = es.search(index=\"github_issues\", body=query, size=1000)\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x2a13b1df0>: Failed to establish a new connection: [Errno 61] Connection refused))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    200\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m    202\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[1;32m    203\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elastic_transport/_node/_http_urllib3.py:167\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    165\u001b[0m     body_to_send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    168\u001b[0m     method,\n\u001b[1;32m    169\u001b[0m     target,\n\u001b[1;32m    170\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody_to_send,\n\u001b[1;32m    171\u001b[0m     retries\u001b[38;5;241m=\u001b[39mRetry(\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    172\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    174\u001b[0m )\n\u001b[1;32m    175\u001b[0m response_headers \u001b[38;5;241m=\u001b[39m HttpHeaders(response\u001b[38;5;241m.\u001b[39mheaders)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[1;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    845\u001b[0m )\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/util/retry.py:449\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m error:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# Disabled, indicate to re-raise the error.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[1;32m    451\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    496\u001b[0m         method,\n\u001b[1;32m    497\u001b[0m         url,\n\u001b[1;32m    498\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    499\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    500\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    501\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    502\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    503\u001b[0m         enforce_content_length\u001b[38;5;241m=\u001b[39menforce_content_length,\n\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:441\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:279\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:214\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x2a3f35040>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m repo \u001b[38;5;129;01min\u001b[39;00m repos:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTop 5 similar issues for repo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     similar \u001b[38;5;241m=\u001b[39m find_similar_issues(repo)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m issue_title, top_similar \u001b[38;5;129;01min\u001b[39;00m similar:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIssue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00missue_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 20\u001b[0m, in \u001b[0;36mfind_similar_issues\u001b[0;34m(repo_name, top_n)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_similar_issues\u001b[39m(repo_name, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Retrieve issues for the given repository\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     query \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_title\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGitHub_Issue_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m     }\n\u001b[0;32m---> 20\u001b[0m     results \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39msearch(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgithub_issues\u001b[39m\u001b[38;5;124m\"\u001b[39m, body\u001b[38;5;241m=\u001b[39mquery, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Build a list of issues and their embeddings\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     issues \u001b[38;5;241m=\u001b[39m [(issue[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_title\u001b[39m\u001b[38;5;124m'\u001b[39m], issue[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGitHub_Issue_vector\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m issue \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m api(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/__init__.py:4149\u001b[0m, in \u001b[0;36mElasticsearch.search\u001b[0;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, force_synthetic_source, from_, highlight, human, ignore_throttled, ignore_unavailable, include_named_queries_score, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, retriever, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version, body)\u001b[0m\n\u001b[1;32m   4147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4148\u001b[0m     __headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 4149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_request(  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m   4150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4151\u001b[0m     __path,\n\u001b[1;32m   4152\u001b[0m     params\u001b[38;5;241m=\u001b[39m__query,\n\u001b[1;32m   4153\u001b[0m     headers\u001b[38;5;241m=\u001b[39m__headers,\n\u001b[1;32m   4154\u001b[0m     body\u001b[38;5;241m=\u001b[39m__body,\n\u001b[1;32m   4155\u001b[0m     endpoint_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4156\u001b[0m     path_parts\u001b[38;5;241m=\u001b[39m__path_parts,\n\u001b[1;32m   4157\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_request(\n\u001b[1;32m    272\u001b[0m             method,\n\u001b[1;32m    273\u001b[0m             path,\n\u001b[1;32m    274\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    275\u001b[0m             headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    276\u001b[0m             body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    277\u001b[0m             otel_span\u001b[38;5;241m=\u001b[39motel_span,\n\u001b[1;32m    278\u001b[0m         )\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elasticsearch/_sync/client/_base.py:316\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     target \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m--> 316\u001b[0m meta, resp_body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[1;32m    317\u001b[0m     method,\n\u001b[1;32m    318\u001b[0m     target,\n\u001b[1;32m    319\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[1;32m    320\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    321\u001b[0m     request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_timeout,\n\u001b[1;32m    322\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_retries,\n\u001b[1;32m    323\u001b[0m     retry_on_status\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_on_status,\n\u001b[1;32m    324\u001b[0m     retry_on_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_on_timeout,\n\u001b[1;32m    325\u001b[0m     client_meta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_meta,\n\u001b[1;32m    326\u001b[0m     otel_span\u001b[38;5;241m=\u001b[39motel_span,\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m299\u001b[39m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m     )\n\u001b[1;32m    338\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elastic_transport/_transport.py:342\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta, otel_span)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     otel_span\u001b[38;5;241m.\u001b[39mset_node_metadata(node\u001b[38;5;241m.\u001b[39mhost, node\u001b[38;5;241m.\u001b[39mport, node\u001b[38;5;241m.\u001b[39mbase_url, target)\n\u001b[0;32m--> 342\u001b[0m     resp \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[1;32m    343\u001b[0m         method,\n\u001b[1;32m    344\u001b[0m         target,\n\u001b[1;32m    345\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest_body,\n\u001b[1;32m    346\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[1;32m    347\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [status:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m duration:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         )\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/elastic_transport/_node/_http_urllib3.py:202\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    194\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e), errors\u001b[38;5;241m=\u001b[39m(e,))\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    196\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    197\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m         exception\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    201\u001b[0m     )\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    204\u001b[0m meta \u001b[38;5;241m=\u001b[39m ApiResponseMeta(\n\u001b[1;32m    205\u001b[0m     node\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    206\u001b[0m     duration\u001b[38;5;241m=\u001b[39mduration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresponse_headers,\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    212\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    213\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m     response\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    218\u001b[0m )\n",
      "\u001b[0;31mConnectionError\u001b[0m: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x2a13b1df0>: Failed to establish a new connection: [Errno 61] Connection refused))"
     ]
    }
   ],
   "source": [
    "# Semantic search function for finding similar issues\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "# Fetch embeddings from Elasticsearch and find top 5 similar issues\n",
    "def find_similar_issues(repo_name, top_n=5):\n",
    "    # Retrieve issues for the given repository\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"_repo\": repo_name\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"_title\", \"GitHub_Issue_vector\"]\n",
    "    }\n",
    "    results = es.search(index=\"github_issues\", body=query, size=1000)\n",
    "    \n",
    "    # Build a list of issues and their embeddings\n",
    "    issues = [(issue['_source']['_title'], issue['_source']['GitHub_Issue_vector']) for issue in results['hits']['hits']]\n",
    "    \n",
    "    # Compute pairwise cosine similarity\n",
    "    similar_issues = []\n",
    "    for i, (title, vector) in enumerate(issues):\n",
    "        similarities = [(other_title, cosine_similarity(vector, other_vector))\n",
    "                        for other_title, other_vector in issues if title != other_title]\n",
    "        # Sort by similarity score and take the top N\n",
    "        top_similar = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        similar_issues.append((title, top_similar))\n",
    "    \n",
    "    return similar_issues\n",
    "\n",
    "# Get top 5 similar issues for each repo\n",
    "for repo in repos:\n",
    "    print(f\"\\nTop 5 similar issues for repo: {repo}\\n\")\n",
    "    similar = find_similar_issues(repo)\n",
    "    for issue_title, top_similar in similar:\n",
    "        print(f\"Issue: {issue_title}\")\n",
    "        for similar_title, score in top_similar:\n",
    "            print(f\"   - {similar_title} (Score: {score:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
